

============================== 2022-04-19 14:01:00.987334 | 97b258ad-fdd1-4f25-bf93-ac0420b93d56 ==============================
14:01:00.987334 [info ] [MainThread]: Running with dbt=1.0.4
14:01:00.987741 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, project_name=None, skip_profile_setup=False, defer=None, state=None, cls=<class 'dbt.task.init.InitTask'>, which='init', rpc_method=None)
14:01:00.987936 [debug] [MainThread]: Tracking: tracking
14:01:01.010378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111bcadc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111bcaeb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111bcad30>]}
14:01:01.011243 [info ] [MainThread]: Creating dbt configuration folder at /Users/amit/.dbt
14:01:09.075869 [debug] [MainThread]: Starter project path: /usr/local/Cellar/dbt-postgres/1.0.4/libexec/lib/python3.9/site-packages/dbt/include/starter_project


============================== 2022-04-19 14:01:29.250601 | dc60da8a-b94f-4860-97eb-f6dc1f3bf36b ==============================
14:01:29.250601 [info ] [MainThread]: Running with dbt=1.0.4
14:01:29.252017 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, project_name='demo_dbt', skip_profile_setup=False, defer=None, state=None, cls=<class 'dbt.task.init.InitTask'>, which='init', rpc_method=None)
14:01:29.252687 [debug] [MainThread]: Tracking: tracking
14:01:29.265393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11167bee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11167bfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11169c070>]}
14:01:29.266822 [info ] [MainThread]: A project called demo_dbt already exists here.
14:01:29.267178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11167bee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11169c040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11169c400>]}


============================== 2022-04-19 15:37:43.656324 | 3a5aa076-7d61-49a0-9776-be445fb73bf4 ==============================
15:37:43.656324 [info ] [MainThread]: Running with dbt=1.0.4
15:37:43.659481 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, config_dir=False, defer=None, state=None, cls=<class 'dbt.task.debug.DebugTask'>, which='debug', rpc_method=None)
15:37:43.659869 [debug] [MainThread]: Tracking: tracking
15:37:43.693790 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10412adf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10412afa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10412af70>]}
15:37:43.696760 [debug] [MainThread]: Executing "git --help"
15:37:43.729793 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
15:37:43.731005 [debug] [MainThread]: STDERR: "b''"
15:37:43.731603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10412af10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10412a730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10412a6d0>]}


============================== 2022-04-19 15:38:42.324630 | 2ae50846-b18a-46ac-acd7-97116d5d6422 ==============================
15:38:42.324630 [info ] [MainThread]: Running with dbt=1.0.4
15:38:42.325033 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, config_dir=False, defer=None, state=None, cls=<class 'dbt.task.debug.DebugTask'>, which='debug', rpc_method=None)
15:38:42.325254 [debug] [MainThread]: Tracking: do not track
15:38:42.713091 [debug] [MainThread]: Executing "git --help"
15:38:42.725399 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
15:38:42.725948 [debug] [MainThread]: STDERR: "b''"
15:38:42.738608 [debug] [MainThread]: Acquiring new postgres connection "debug"
15:38:42.739926 [debug] [MainThread]: Using postgres connection "debug"
15:38:42.740456 [debug] [MainThread]: On debug: select 1 as id
15:38:42.740765 [debug] [MainThread]: Opening a new connection, currently in state init
15:38:44.728817 [debug] [MainThread]: SQL status: SELECT 1 in 1.99 seconds
15:38:44.731558 [debug] [MainThread]: On debug: Close
15:38:44.733373 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-04-19 15:43:10.500676 | 6918585d-ada4-4509-9b46-7ac3bef42a15 ==============================
15:43:10.500676 [info ] [MainThread]: Running with dbt=1.0.4
15:43:10.501793 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, config_dir=False, defer=None, state=None, cls=<class 'dbt.task.debug.DebugTask'>, which='debug', rpc_method=None)
15:43:10.502195 [debug] [MainThread]: Tracking: do not track
15:43:10.624259 [debug] [MainThread]: Executing "git --help"
15:43:10.667383 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
15:43:10.668225 [debug] [MainThread]: STDERR: "b''"
15:43:10.674069 [debug] [MainThread]: Acquiring new postgres connection "debug"
15:43:10.675408 [debug] [MainThread]: Using postgres connection "debug"
15:43:10.675695 [debug] [MainThread]: On debug: select 1 as id
15:43:10.676063 [debug] [MainThread]: Opening a new connection, currently in state init
15:43:13.121991 [debug] [MainThread]: SQL status: SELECT 1 in 2.45 seconds
15:43:13.125183 [debug] [MainThread]: On debug: Close
15:43:13.126943 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-04-19 15:45:47.142516 | 7b396862-cee5-4c6f-a96e-10bde7bd7130 ==============================
15:45:47.142516 [info ] [MainThread]: Running with dbt=1.0.4
15:45:47.143719 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, config_dir=False, defer=None, state=None, cls=<class 'dbt.task.debug.DebugTask'>, which='debug', rpc_method=None)
15:45:47.144207 [debug] [MainThread]: Tracking: do not track
15:45:47.317164 [debug] [MainThread]: Executing "git --help"
15:45:47.341845 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
15:45:47.342956 [debug] [MainThread]: STDERR: "b''"
15:45:47.349635 [debug] [MainThread]: Acquiring new postgres connection "debug"
15:45:47.350848 [debug] [MainThread]: Using postgres connection "debug"
15:45:47.351126 [debug] [MainThread]: On debug: select 1 as id
15:45:47.351540 [debug] [MainThread]: Opening a new connection, currently in state init
15:45:49.174719 [debug] [MainThread]: SQL status: SELECT 1 in 1.82 seconds
15:45:49.177330 [debug] [MainThread]: On debug: Close
15:45:49.179211 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-04-19 15:47:15.575663 | 8f599999-da1f-4718-946b-2040188fff26 ==============================
15:47:15.575663 [info ] [MainThread]: Running with dbt=1.0.4
15:47:15.576862 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:47:15.577215 [debug] [MainThread]: Tracking: do not track
15:47:15.606694 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
15:47:15.668918 [debug] [MainThread]: Parsing macros/catalog.sql
15:47:15.674221 [debug] [MainThread]: Parsing macros/relations.sql
15:47:15.676286 [debug] [MainThread]: Parsing macros/adapters.sql
15:47:15.702295 [debug] [MainThread]: Parsing macros/materializations/snapshot_merge.sql
15:47:15.704157 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
15:47:15.714149 [debug] [MainThread]: Parsing macros/materializations/configs.sql
15:47:15.717756 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
15:47:15.719590 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
15:47:15.737184 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
15:47:15.751672 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
15:47:15.764727 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
15:47:15.769530 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
15:47:15.771415 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
15:47:15.773243 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
15:47:15.777734 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
15:47:15.790024 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
15:47:15.791625 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
15:47:15.802604 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
15:47:15.819669 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
15:47:15.830187 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
15:47:15.833535 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
15:47:15.841625 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
15:47:15.843393 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
15:47:15.846521 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
15:47:15.849627 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
15:47:15.856131 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
15:47:15.875317 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
15:47:15.876927 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
15:47:15.879498 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
15:47:15.881863 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
15:47:15.882909 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
15:47:15.883534 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
15:47:15.884396 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
15:47:15.885779 [debug] [MainThread]: Parsing macros/etc/statement.sql
15:47:15.890283 [debug] [MainThread]: Parsing macros/etc/datetime.sql
15:47:15.898843 [debug] [MainThread]: Parsing macros/adapters/schema.sql
15:47:15.901160 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
15:47:15.903920 [debug] [MainThread]: Parsing macros/adapters/relation.sql
15:47:15.914047 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
15:47:15.917501 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
15:47:15.922461 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
15:47:15.929968 [debug] [MainThread]: Parsing macros/adapters/columns.sql
15:47:15.940352 [debug] [MainThread]: Parsing tests/generic/builtin.sql
15:47:16.128230 [debug] [MainThread]: 1699: static parser successfully parsed staging/demo_eltool__customers.sql
15:47:16.140297 [debug] [MainThread]: 1699: static parser successfully parsed staging/demo_eltool__state.sql
15:47:16.142952 [debug] [MainThread]: 1699: static parser successfully parsed staging/demo_eltool__orders.sql
15:47:16.145725 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
15:47:16.148446 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
15:47:16.177861 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'stg_eltool__customers' in the 'models' section of file 'models/staging/stg_eltool.yml'
15:47:16.178886 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'stg_eltool__orders' in the 'models' section of file 'models/staging/stg_eltool.yml'
15:47:16.179967 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'stg_eltool__state' in the 'models' section of file 'models/staging/stg_eltool.yml'


============================== 2022-04-19 15:49:39.706719 | f0dd2e36-a40f-4688-b4c5-cea47ce2bf87 ==============================
15:49:39.706719 [info ] [MainThread]: Running with dbt=1.0.4
15:49:39.707725 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:49:39.708133 [debug] [MainThread]: Tracking: do not track
15:49:39.736647 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
15:49:39.780842 [debug] [MainThread]: Parsing macros/catalog.sql
15:49:39.785346 [debug] [MainThread]: Parsing macros/relations.sql
15:49:39.787219 [debug] [MainThread]: Parsing macros/adapters.sql
15:49:39.813408 [debug] [MainThread]: Parsing macros/materializations/snapshot_merge.sql
15:49:39.815396 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
15:49:39.820441 [debug] [MainThread]: Parsing macros/materializations/configs.sql
15:49:39.823253 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
15:49:39.825586 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
15:49:39.844589 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
15:49:39.859041 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
15:49:39.871705 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
15:49:39.876496 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
15:49:39.878326 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
15:49:39.880174 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
15:49:39.884615 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
15:49:39.897252 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
15:49:39.898889 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
15:49:39.910175 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
15:49:39.926894 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
15:49:39.934654 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
15:49:39.937558 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
15:49:39.944970 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
15:49:39.946311 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
15:49:39.949104 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
15:49:39.951445 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
15:49:39.957935 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
15:49:39.975164 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
15:49:39.976776 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
15:49:39.979230 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
15:49:39.980901 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
15:49:39.981847 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
15:49:39.982428 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
15:49:39.983137 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
15:49:39.984617 [debug] [MainThread]: Parsing macros/etc/statement.sql
15:49:39.989529 [debug] [MainThread]: Parsing macros/etc/datetime.sql
15:49:39.998259 [debug] [MainThread]: Parsing macros/adapters/schema.sql
15:49:40.000477 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
15:49:40.003205 [debug] [MainThread]: Parsing macros/adapters/relation.sql
15:49:40.012962 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
15:49:40.015976 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
15:49:40.020773 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
15:49:40.028511 [debug] [MainThread]: Parsing macros/adapters/columns.sql
15:49:40.038602 [debug] [MainThread]: Parsing tests/generic/builtin.sql
15:49:40.222509 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
15:49:40.235652 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
15:49:40.238313 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
15:49:40.241160 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
15:49:40.243873 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql


============================== 2022-04-19 15:52:02.406720 | 69cd7987-2211-42be-807c-72bf510b8f8d ==============================
15:52:02.406720 [info ] [MainThread]: Running with dbt=1.0.4
15:52:02.408067 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:52:02.408594 [debug] [MainThread]: Tracking: do not track
15:52:02.448136 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
15:52:02.497941 [debug] [MainThread]: Parsing macros/catalog.sql
15:52:02.503139 [debug] [MainThread]: Parsing macros/relations.sql
15:52:02.505428 [debug] [MainThread]: Parsing macros/adapters.sql
15:52:02.531697 [debug] [MainThread]: Parsing macros/materializations/snapshot_merge.sql
15:52:02.533458 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
15:52:02.537623 [debug] [MainThread]: Parsing macros/materializations/configs.sql
15:52:02.540222 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
15:52:02.541942 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
15:52:02.560908 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
15:52:02.573854 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
15:52:02.591946 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
15:52:02.596558 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
15:52:02.598369 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
15:52:02.600165 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
15:52:02.605338 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
15:52:02.617225 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
15:52:02.618863 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
15:52:02.629737 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
15:52:02.646499 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
15:52:02.654679 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
15:52:02.657612 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
15:52:02.665207 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
15:52:02.666633 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
15:52:02.669966 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
15:52:02.672474 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
15:52:02.678596 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
15:52:02.695919 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
15:52:02.697560 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
15:52:02.700016 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
15:52:02.702005 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
15:52:02.703011 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
15:52:02.703601 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
15:52:02.704475 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
15:52:02.705869 [debug] [MainThread]: Parsing macros/etc/statement.sql
15:52:02.710262 [debug] [MainThread]: Parsing macros/etc/datetime.sql
15:52:02.719042 [debug] [MainThread]: Parsing macros/adapters/schema.sql
15:52:02.721276 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
15:52:02.723956 [debug] [MainThread]: Parsing macros/adapters/relation.sql
15:52:02.733838 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
15:52:02.737230 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
15:52:02.741765 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
15:52:02.749277 [debug] [MainThread]: Parsing macros/adapters/columns.sql
15:52:02.759889 [debug] [MainThread]: Parsing tests/generic/builtin.sql
15:52:02.945536 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
15:52:02.956842 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
15:52:02.959233 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
15:52:02.961716 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
15:52:02.964066 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql


============================== 2022-04-19 15:54:11.856531 | ef9c8408-8f9a-42bf-bf87-e377bc950508 ==============================
15:54:11.856531 [info ] [MainThread]: Running with dbt=1.0.4
15:54:11.880517 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:54:11.880974 [debug] [MainThread]: Tracking: do not track
15:54:11.931385 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
15:54:12.042904 [debug] [MainThread]: Parsing macros/catalog.sql
15:54:12.050993 [debug] [MainThread]: Parsing macros/relations.sql
15:54:12.052821 [debug] [MainThread]: Parsing macros/adapters.sql
15:54:12.082632 [debug] [MainThread]: Parsing macros/materializations/snapshot_merge.sql
15:54:12.085107 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
15:54:12.090172 [debug] [MainThread]: Parsing macros/materializations/configs.sql
15:54:12.093084 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
15:54:12.095399 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
15:54:12.118566 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
15:54:12.137202 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
15:54:12.153517 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
15:54:12.160485 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
15:54:12.163280 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
15:54:12.165637 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
15:54:12.171755 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
15:54:12.188741 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
15:54:12.191099 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
15:54:12.205578 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
15:54:12.225812 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
15:54:12.234727 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
15:54:12.238392 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
15:54:12.246034 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
15:54:12.247458 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
15:54:12.250209 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
15:54:12.252552 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
15:54:12.259219 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
15:54:12.276440 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
15:54:12.277983 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
15:54:12.280476 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
15:54:12.282075 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
15:54:12.283061 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
15:54:12.283649 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
15:54:12.284367 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
15:54:12.285765 [debug] [MainThread]: Parsing macros/etc/statement.sql
15:54:12.290706 [debug] [MainThread]: Parsing macros/etc/datetime.sql
15:54:12.299486 [debug] [MainThread]: Parsing macros/adapters/schema.sql
15:54:12.301727 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
15:54:12.304493 [debug] [MainThread]: Parsing macros/adapters/relation.sql
15:54:12.314314 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
15:54:12.317272 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
15:54:12.322012 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
15:54:12.329839 [debug] [MainThread]: Parsing macros/adapters/columns.sql
15:54:12.339957 [debug] [MainThread]: Parsing tests/generic/builtin.sql
15:54:12.529369 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
15:54:12.540650 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
15:54:12.543030 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
15:54:12.545637 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
15:54:12.548050 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql


============================== 2022-04-19 15:55:24.129216 | c4ac69c0-fc5d-4fc8-bf0a-e85c3d9f5b63 ==============================
15:55:24.129216 [info ] [MainThread]: Running with dbt=1.0.4
15:55:24.130796 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
15:55:24.131233 [debug] [MainThread]: Tracking: do not track
15:55:24.160676 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
15:55:24.199896 [debug] [MainThread]: Parsing macros/catalog.sql
15:55:24.206453 [debug] [MainThread]: Parsing macros/relations.sql
15:55:24.208867 [debug] [MainThread]: Parsing macros/adapters.sql
15:55:24.234915 [debug] [MainThread]: Parsing macros/materializations/snapshot_merge.sql
15:55:24.236850 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
15:55:24.241172 [debug] [MainThread]: Parsing macros/materializations/configs.sql
15:55:24.243754 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
15:55:24.245681 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
15:55:24.263498 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
15:55:24.277729 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
15:55:24.290717 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
15:55:24.295688 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
15:55:24.298682 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
15:55:24.302483 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
15:55:24.307513 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
15:55:24.319612 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
15:55:24.321187 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
15:55:24.332410 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
15:55:24.348825 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
15:55:24.356777 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
15:55:24.359733 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
15:55:24.367161 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
15:55:24.368645 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
15:55:24.371384 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
15:55:24.373664 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
15:55:24.380295 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
15:55:24.400498 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
15:55:24.402125 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
15:55:24.404832 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
15:55:24.406576 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
15:55:24.407550 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
15:55:24.408124 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
15:55:24.408861 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
15:55:24.410232 [debug] [MainThread]: Parsing macros/etc/statement.sql
15:55:24.415018 [debug] [MainThread]: Parsing macros/etc/datetime.sql
15:55:24.424799 [debug] [MainThread]: Parsing macros/adapters/schema.sql
15:55:24.427536 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
15:55:24.431166 [debug] [MainThread]: Parsing macros/adapters/relation.sql
15:55:24.442612 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
15:55:24.446010 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
15:55:24.450744 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
15:55:24.458510 [debug] [MainThread]: Parsing macros/adapters/columns.sql
15:55:24.470329 [debug] [MainThread]: Parsing tests/generic/builtin.sql
15:55:24.653321 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
15:55:24.665277 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
15:55:24.667753 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
15:55:24.670806 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
15:55:24.673195 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql


============================== 2022-04-19 15:57:42.922682 | 775f43ff-93af-49cd-92e3-f7963e99b589 ==============================
15:57:42.922682 [info ] [MainThread]: Running with dbt=1.0.4
15:57:42.923884 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.snapshot.SnapshotTask'>, which='snapshot', rpc_method='snapshot')
15:57:42.924214 [debug] [MainThread]: Tracking: do not track
15:57:42.957121 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
15:57:43.013401 [debug] [MainThread]: Parsing macros/catalog.sql
15:57:43.018518 [debug] [MainThread]: Parsing macros/relations.sql
15:57:43.020756 [debug] [MainThread]: Parsing macros/adapters.sql
15:57:43.047945 [debug] [MainThread]: Parsing macros/materializations/snapshot_merge.sql
15:57:43.049948 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
15:57:43.054668 [debug] [MainThread]: Parsing macros/materializations/configs.sql
15:57:43.058070 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
15:57:43.059918 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
15:57:43.077383 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
15:57:43.090380 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
15:57:43.102821 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
15:57:43.107350 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
15:57:43.109145 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
15:57:43.110975 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
15:57:43.115889 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
15:57:43.127588 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
15:57:43.129230 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
15:57:43.140157 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
15:57:43.158395 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
15:57:43.167827 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
15:57:43.170902 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
15:57:43.178731 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
15:57:43.180247 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
15:57:43.183205 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
15:57:43.185640 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
15:57:43.191795 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
15:57:43.209131 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
15:57:43.210731 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
15:57:43.213575 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
15:57:43.215396 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
15:57:43.216328 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
15:57:43.216902 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
15:57:43.217650 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
15:57:43.219121 [debug] [MainThread]: Parsing macros/etc/statement.sql
15:57:43.223619 [debug] [MainThread]: Parsing macros/etc/datetime.sql
15:57:43.232359 [debug] [MainThread]: Parsing macros/adapters/schema.sql
15:57:43.234589 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
15:57:43.237322 [debug] [MainThread]: Parsing macros/adapters/relation.sql
15:57:43.247400 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
15:57:43.250627 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
15:57:43.255109 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
15:57:43.262515 [debug] [MainThread]: Parsing macros/adapters/columns.sql
15:57:43.272586 [debug] [MainThread]: Parsing tests/generic/builtin.sql
15:57:43.456585 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
15:57:43.468049 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
15:57:43.470414 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
15:57:43.472930 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
15:57:43.475246 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql


============================== 2022-04-19 15:59:59.169703 | 3ac7be30-9012-4297-93c7-09c6accf710c ==============================
15:59:59.169703 [info ] [MainThread]: Running with dbt=1.0.4
15:59:59.170877 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.snapshot.SnapshotTask'>, which='snapshot', rpc_method='snapshot')
15:59:59.171296 [debug] [MainThread]: Tracking: do not track
15:59:59.214585 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
15:59:59.262071 [debug] [MainThread]: Parsing macros/catalog.sql
15:59:59.267797 [debug] [MainThread]: Parsing macros/relations.sql
15:59:59.271171 [debug] [MainThread]: Parsing macros/adapters.sql
15:59:59.315619 [debug] [MainThread]: Parsing macros/materializations/snapshot_merge.sql
15:59:59.319234 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
15:59:59.325121 [debug] [MainThread]: Parsing macros/materializations/configs.sql
15:59:59.328497 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
15:59:59.330911 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
15:59:59.356609 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
15:59:59.374171 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
15:59:59.393315 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
15:59:59.400451 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
15:59:59.403075 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
15:59:59.405661 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
15:59:59.413218 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
15:59:59.431182 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
15:59:59.433418 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
15:59:59.449616 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
15:59:59.473953 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
15:59:59.487614 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
15:59:59.492460 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
15:59:59.503471 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
15:59:59.505410 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
15:59:59.509240 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
15:59:59.512679 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
15:59:59.522616 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
15:59:59.552340 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
15:59:59.554600 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
15:59:59.558441 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
15:59:59.560713 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
15:59:59.561981 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
15:59:59.562753 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
15:59:59.563738 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
15:59:59.565724 [debug] [MainThread]: Parsing macros/etc/statement.sql
15:59:59.572081 [debug] [MainThread]: Parsing macros/etc/datetime.sql
15:59:59.585230 [debug] [MainThread]: Parsing macros/adapters/schema.sql
15:59:59.588405 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
15:59:59.592460 [debug] [MainThread]: Parsing macros/adapters/relation.sql
15:59:59.606578 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
15:59:59.610866 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
15:59:59.617715 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
15:59:59.628932 [debug] [MainThread]: Parsing macros/adapters/columns.sql
15:59:59.643373 [debug] [MainThread]: Parsing tests/generic/builtin.sql
15:59:59.914745 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
15:59:59.930876 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
15:59:59.934502 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
15:59:59.937959 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
15:59:59.941314 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql


============================== 2022-04-19 16:00:43.732993 | a469f315-601a-4384-b1ca-6be09c2f65c0 ==============================
16:00:43.732993 [info ] [MainThread]: Running with dbt=1.0.4
16:00:43.733405 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, config_dir=False, defer=None, state=None, cls=<class 'dbt.task.debug.DebugTask'>, which='debug', rpc_method=None)
16:00:43.733627 [debug] [MainThread]: Tracking: do not track
16:00:43.817986 [debug] [MainThread]: Executing "git --help"
16:00:43.863899 [debug] [MainThread]: STDOUT: "b"usage: git [--version] [--help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
16:00:43.864602 [debug] [MainThread]: STDERR: "b''"
16:00:43.871456 [debug] [MainThread]: Acquiring new postgres connection "debug"
16:00:43.874453 [debug] [MainThread]: Using postgres connection "debug"
16:00:43.874879 [debug] [MainThread]: On debug: select 1 as id
16:00:43.875077 [debug] [MainThread]: Opening a new connection, currently in state init
16:00:45.849809 [debug] [MainThread]: SQL status: SELECT 1 in 1.97 seconds
16:00:45.852227 [debug] [MainThread]: On debug: Close
16:00:45.854392 [debug] [MainThread]: Connection 'debug' was properly closed.


============================== 2022-04-19 16:01:00.010632 | 0e0f6e60-4374-43d0-b2c6-a25a5c17c003 ==============================
16:01:00.010632 [info ] [MainThread]: Running with dbt=1.0.4
16:01:00.011449 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
16:01:00.011774 [debug] [MainThread]: Tracking: do not track
16:01:00.036270 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
16:01:00.060788 [debug] [MainThread]: Parsing macros/catalog.sql
16:01:00.064235 [debug] [MainThread]: Parsing macros/relations.sql
16:01:00.065708 [debug] [MainThread]: Parsing macros/adapters.sql
16:01:00.089345 [debug] [MainThread]: Parsing macros/materializations/snapshot_merge.sql
16:01:00.091096 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
16:01:00.095058 [debug] [MainThread]: Parsing macros/materializations/configs.sql
16:01:00.097380 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
16:01:00.099044 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
16:01:00.117405 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
16:01:00.133616 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
16:01:00.146397 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
16:01:00.151883 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
16:01:00.153809 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
16:01:00.155710 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
16:01:00.160065 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
16:01:00.171527 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
16:01:00.173042 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
16:01:00.185025 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
16:01:00.202252 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
16:01:00.210634 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
16:01:00.213773 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
16:01:00.222489 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
16:01:00.223936 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
16:01:00.226626 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
16:01:00.228898 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
16:01:00.234991 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
16:01:00.251900 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
16:01:00.253432 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
16:01:00.255857 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
16:01:00.257426 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
16:01:00.258312 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
16:01:00.258869 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
16:01:00.259564 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
16:01:00.261076 [debug] [MainThread]: Parsing macros/etc/statement.sql
16:01:00.265500 [debug] [MainThread]: Parsing macros/etc/datetime.sql
16:01:00.274067 [debug] [MainThread]: Parsing macros/adapters/schema.sql
16:01:00.276459 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
16:01:00.279145 [debug] [MainThread]: Parsing macros/adapters/relation.sql
16:01:00.289167 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
16:01:00.293636 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
16:01:00.298367 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
16:01:00.305738 [debug] [MainThread]: Parsing macros/adapters/columns.sql
16:01:00.315608 [debug] [MainThread]: Parsing tests/generic/builtin.sql
16:01:00.498253 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
16:01:00.509830 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
16:01:00.512180 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
16:01:00.514924 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
16:01:00.517573 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql


============================== 2022-04-19 16:03:37.384393 | c08f90d7-a6ab-4553-a017-d8a346d171e9 ==============================
16:03:37.384393 [info ] [MainThread]: Running with dbt=1.0.4
16:03:37.385716 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.snapshot.SnapshotTask'>, which='snapshot', rpc_method='snapshot')
16:03:37.386131 [debug] [MainThread]: Tracking: do not track
16:03:37.424465 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
16:03:37.487639 [debug] [MainThread]: Parsing macros/catalog.sql
16:03:37.493374 [debug] [MainThread]: Parsing macros/relations.sql
16:03:37.494920 [debug] [MainThread]: Parsing macros/adapters.sql
16:03:37.524327 [debug] [MainThread]: Parsing macros/materializations/snapshot_merge.sql
16:03:37.526089 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
16:03:37.530092 [debug] [MainThread]: Parsing macros/materializations/configs.sql
16:03:37.532453 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
16:03:37.534153 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
16:03:37.552997 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
16:03:37.565089 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
16:03:37.577762 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
16:03:37.582316 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
16:03:37.584620 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
16:03:37.586617 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
16:03:37.591125 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
16:03:37.602784 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
16:03:37.604374 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
16:03:37.615118 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
16:03:37.631568 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
16:03:37.639482 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
16:03:37.642392 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
16:03:37.650060 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
16:03:37.651725 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
16:03:37.654888 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
16:03:37.657422 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
16:03:37.663597 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
16:03:37.680550 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
16:03:37.682109 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
16:03:37.685066 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
16:03:37.686882 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
16:03:37.687802 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
16:03:37.688444 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
16:03:37.689216 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
16:03:37.690670 [debug] [MainThread]: Parsing macros/etc/statement.sql
16:03:37.695286 [debug] [MainThread]: Parsing macros/etc/datetime.sql
16:03:37.704173 [debug] [MainThread]: Parsing macros/adapters/schema.sql
16:03:37.706405 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
16:03:37.709196 [debug] [MainThread]: Parsing macros/adapters/relation.sql
16:03:37.719618 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
16:03:37.722731 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
16:03:37.727142 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
16:03:37.734767 [debug] [MainThread]: Parsing macros/adapters/columns.sql
16:03:37.744753 [debug] [MainThread]: Parsing tests/generic/builtin.sql
16:03:37.939628 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
16:03:37.951495 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
16:03:37.953961 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
16:03:37.957053 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
16:03:37.959599 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
16:03:38.119198 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 165 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
16:03:38.122066 [info ] [MainThread]: 
16:03:38.123251 [debug] [MainThread]: Acquiring new postgres connection "master"
16:03:38.124304 [debug] [ThreadPool]: Acquiring new postgres connection "list_dbt"
16:03:38.130733 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro list_schemas
16:03:38.130992 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
16:03:38.131182 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:03:39.849280 [debug] [ThreadPool]: On list_dbt: Close
16:03:39.850522 [debug] [MainThread]: Connection 'master' was properly closed.
16:03:39.850835 [debug] [MainThread]: Connection 'list_dbt' was properly closed.


============================== 2022-04-19 16:04:39.980202 | 6bdf4725-7cad-41bb-874e-09a5fa6b3e08 ==============================
16:04:39.980202 [info ] [MainThread]: Running with dbt=1.0.4
16:04:39.981503 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.snapshot.SnapshotTask'>, which='snapshot', rpc_method='snapshot')
16:04:39.982076 [debug] [MainThread]: Tracking: do not track
16:04:40.078593 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
16:04:40.079438 [debug] [MainThread]: Partial parsing: updated file: demo_dbt://snapshots/customers.sql
16:04:40.138325 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 165 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
16:04:40.142084 [info ] [MainThread]: 
16:04:40.142879 [debug] [MainThread]: Acquiring new postgres connection "master"
16:04:40.144047 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb"
16:04:40.154485 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb"
16:04:40.154743 [debug] [ThreadPool]: On list_brightacciondb: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_brightacciondb"} */

    select distinct nspname from pg_namespace
  
16:04:40.154905 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:04:42.082737 [debug] [ThreadPool]: SQL status: SELECT 8 in 1.93 seconds
16:04:42.085363 [debug] [ThreadPool]: On list_brightacciondb: Close
16:04:42.087324 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb_snapshots"
16:04:42.094570 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_snapshots"
16:04:42.094858 [debug] [ThreadPool]: On list_brightacciondb_snapshots: BEGIN
16:04:42.095039 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:04:43.791522 [debug] [ThreadPool]: SQL status: BEGIN in 1.7 seconds
16:04:43.792180 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_snapshots"
16:04:43.792586 [debug] [ThreadPool]: On list_brightacciondb_snapshots: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_brightacciondb_snapshots"} */
select
      'brightacciondb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'brightacciondb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
  
16:04:44.015204 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.22 seconds
16:04:44.017408 [debug] [ThreadPool]: On list_brightacciondb_snapshots: ROLLBACK
16:04:44.329687 [debug] [ThreadPool]: On list_brightacciondb_snapshots: Close
16:04:44.331218 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb_warehouse"
16:04:44.333871 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_warehouse"
16:04:44.334222 [debug] [ThreadPool]: On list_brightacciondb_warehouse: BEGIN
16:04:44.334461 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:04:46.078466 [debug] [ThreadPool]: SQL status: BEGIN in 1.74 seconds
16:04:46.078812 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_warehouse"
16:04:46.080145 [debug] [ThreadPool]: On list_brightacciondb_warehouse: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_brightacciondb_warehouse"} */
select
      'brightacciondb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'brightacciondb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
16:04:46.294187 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.21 seconds
16:04:46.295830 [debug] [ThreadPool]: On list_brightacciondb_warehouse: ROLLBACK
16:04:46.506820 [debug] [ThreadPool]: On list_brightacciondb_warehouse: Close
16:04:46.512430 [debug] [MainThread]: Using postgres connection "master"
16:04:46.512744 [debug] [MainThread]: On master: BEGIN
16:04:46.512930 [debug] [MainThread]: Opening a new connection, currently in state init
16:04:48.200959 [debug] [MainThread]: SQL status: BEGIN in 1.69 seconds
16:04:48.201677 [debug] [MainThread]: Using postgres connection "master"
16:04:48.201962 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
16:04:48.433640 [debug] [MainThread]: SQL status: SELECT 0 in 0.23 seconds
16:04:48.435829 [debug] [MainThread]: On master: ROLLBACK
16:04:48.645853 [debug] [MainThread]: Using postgres connection "master"
16:04:48.646652 [debug] [MainThread]: On master: BEGIN
16:04:49.065856 [debug] [MainThread]: SQL status: BEGIN in 0.42 seconds
16:04:49.066487 [debug] [MainThread]: On master: COMMIT
16:04:49.066818 [debug] [MainThread]: Using postgres connection "master"
16:04:49.067083 [debug] [MainThread]: On master: COMMIT
16:04:49.275850 [debug] [MainThread]: SQL status: COMMIT in 0.21 seconds
16:04:49.276504 [debug] [MainThread]: On master: Close
16:04:49.277351 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
16:04:49.277853 [info ] [MainThread]: 
16:04:49.310575 [debug] [Thread-1  ]: Began running node snapshot.demo_dbt.customers_snapshot
16:04:49.310974 [info ] [Thread-1  ]: 1 of 1 START snapshot snapshots.customers_snapshot.............................. [RUN]
16:04:49.311545 [debug] [Thread-1  ]: Acquiring new postgres connection "snapshot.demo_dbt.customers_snapshot"
16:04:49.311771 [debug] [Thread-1  ]: Began compiling node snapshot.demo_dbt.customers_snapshot
16:04:49.311967 [debug] [Thread-1  ]: Compiling snapshot.demo_dbt.customers_snapshot
16:04:49.315795 [debug] [Thread-1  ]: finished collecting timing info
16:04:49.316076 [debug] [Thread-1  ]: Began executing node snapshot.demo_dbt.customers_snapshot
16:04:49.341141 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
16:04:49.341410 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

    select count(*) from pg_namespace where nspname = 'snapshots'
  
16:04:49.341573 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:04:51.123225 [debug] [Thread-1  ]: SQL status: SELECT 1 in 1.78 seconds
16:04:51.159619 [debug] [Thread-1  ]: Writing runtime SQL for node "snapshot.demo_dbt.customers_snapshot"
16:04:51.160389 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
16:04:51.160571 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: BEGIN
16:04:51.371794 [debug] [Thread-1  ]: SQL status: BEGIN in 0.21 seconds
16:04:51.372391 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
16:04:51.372686 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

      

  create  table "brightacciondb"."snapshots"."customers_snapshot"
  as (
    

    select *,
        md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(datetime_updated as varchar ), '')
        ) as dbt_scd_id,
        datetime_updated as dbt_updated_at,
        datetime_updated as dbt_valid_from,
        nullif(datetime_updated, datetime_updated) as dbt_valid_to
    from (
        



select * from "brightacciondb"."warehouse"."customers"

    ) sbq



  );
  
16:04:51.607377 [debug] [Thread-1  ]: SQL status: SELECT 100 in 0.23 seconds
16:04:51.621575 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: COMMIT
16:04:51.621862 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
16:04:51.622049 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: COMMIT
16:04:51.833172 [debug] [Thread-1  ]: SQL status: COMMIT in 0.21 seconds
16:04:51.834353 [debug] [Thread-1  ]: finished collecting timing info
16:04:51.834708 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: Close
16:04:51.835715 [info ] [Thread-1  ]: 1 of 1 OK snapshotted snapshots.customers_snapshot.............................. [[32mSELECT 100[0m in 2.52s]
16:04:51.836298 [debug] [Thread-1  ]: Finished running node snapshot.demo_dbt.customers_snapshot
16:04:51.837769 [debug] [MainThread]: Acquiring new postgres connection "master"
16:04:51.838088 [debug] [MainThread]: Using postgres connection "master"
16:04:51.838312 [debug] [MainThread]: On master: BEGIN
16:04:51.838513 [debug] [MainThread]: Opening a new connection, currently in state closed
16:04:54.161536 [debug] [MainThread]: SQL status: BEGIN in 2.32 seconds
16:04:54.162139 [debug] [MainThread]: On master: COMMIT
16:04:54.162478 [debug] [MainThread]: Using postgres connection "master"
16:04:54.162736 [debug] [MainThread]: On master: COMMIT
16:04:54.389573 [debug] [MainThread]: SQL status: COMMIT in 0.23 seconds
16:04:54.390264 [debug] [MainThread]: On master: Close
16:04:54.391088 [info ] [MainThread]: 
16:04:54.391573 [info ] [MainThread]: Finished running 1 snapshot in 14.25s.
16:04:54.392123 [debug] [MainThread]: Connection 'master' was properly closed.
16:04:54.392422 [debug] [MainThread]: Connection 'snapshot.demo_dbt.customers_snapshot' was properly closed.
16:04:54.400429 [info ] [MainThread]: 
16:04:54.400805 [info ] [MainThread]: [32mCompleted successfully[0m
16:04:54.401233 [info ] [MainThread]: 
16:04:54.401540 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1


============================== 2022-04-19 16:05:08.164208 | 398d8325-cde4-42fa-b9ec-6301d5066baf ==============================
16:05:08.164208 [info ] [MainThread]: Running with dbt=1.0.4
16:05:08.164792 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
16:05:08.165211 [debug] [MainThread]: Tracking: do not track
16:05:08.213779 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
16:05:08.214094 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
16:05:08.228813 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 165 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
16:05:08.230658 [info ] [MainThread]: 
16:05:08.231296 [debug] [MainThread]: Acquiring new postgres connection "master"
16:05:08.232775 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb"
16:05:08.242006 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb"
16:05:08.242274 [debug] [ThreadPool]: On list_brightacciondb: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_brightacciondb"} */

    select distinct nspname from pg_namespace
  
16:05:08.242444 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:05:10.252203 [debug] [ThreadPool]: SQL status: SELECT 8 in 2.01 seconds
16:05:10.254837 [debug] [ThreadPool]: On list_brightacciondb: Close
16:05:10.256937 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb_snapshots"
16:05:10.264101 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_snapshots"
16:05:10.264401 [debug] [ThreadPool]: On list_brightacciondb_snapshots: BEGIN
16:05:10.264575 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:05:12.818534 [debug] [ThreadPool]: SQL status: BEGIN in 2.55 seconds
16:05:12.819245 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_snapshots"
16:05:12.819567 [debug] [ThreadPool]: On list_brightacciondb_snapshots: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_brightacciondb_snapshots"} */
select
      'brightacciondb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'brightacciondb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
  
16:05:13.070679 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.25 seconds
16:05:13.072443 [debug] [ThreadPool]: On list_brightacciondb_snapshots: ROLLBACK
16:05:13.286914 [debug] [ThreadPool]: On list_brightacciondb_snapshots: Close
16:05:13.288546 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb_warehouse"
16:05:13.291073 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_warehouse"
16:05:13.291337 [debug] [ThreadPool]: On list_brightacciondb_warehouse: BEGIN
16:05:13.291546 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:05:15.013611 [debug] [ThreadPool]: SQL status: BEGIN in 1.72 seconds
16:05:15.014190 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_warehouse"
16:05:15.014390 [debug] [ThreadPool]: On list_brightacciondb_warehouse: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_brightacciondb_warehouse"} */
select
      'brightacciondb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'brightacciondb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
16:05:15.254472 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.24 seconds
16:05:15.256738 [debug] [ThreadPool]: On list_brightacciondb_warehouse: ROLLBACK
16:05:15.467996 [debug] [ThreadPool]: On list_brightacciondb_warehouse: Close
16:05:15.475339 [debug] [MainThread]: Using postgres connection "master"
16:05:15.475678 [debug] [MainThread]: On master: BEGIN
16:05:15.475899 [debug] [MainThread]: Opening a new connection, currently in state init
16:05:17.595564 [debug] [MainThread]: SQL status: BEGIN in 2.12 seconds
16:05:17.596097 [debug] [MainThread]: Using postgres connection "master"
16:05:17.596391 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
16:05:17.814804 [debug] [MainThread]: SQL status: SELECT 0 in 0.22 seconds
16:05:17.816852 [debug] [MainThread]: On master: ROLLBACK
16:05:18.027816 [debug] [MainThread]: Using postgres connection "master"
16:05:18.028310 [debug] [MainThread]: On master: BEGIN
16:05:18.445807 [debug] [MainThread]: SQL status: BEGIN in 0.42 seconds
16:05:18.446453 [debug] [MainThread]: On master: COMMIT
16:05:18.446752 [debug] [MainThread]: Using postgres connection "master"
16:05:18.447011 [debug] [MainThread]: On master: COMMIT
16:05:18.656956 [debug] [MainThread]: SQL status: COMMIT in 0.21 seconds
16:05:18.657623 [debug] [MainThread]: On master: Close
16:05:18.658698 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
16:05:18.659479 [info ] [MainThread]: 
16:05:18.663861 [debug] [Thread-1  ]: Began running node model.demo_dbt.my_first_dbt_model
16:05:18.664296 [info ] [Thread-1  ]: 1 of 5 START table model warehouse.my_first_dbt_model........................... [RUN]
16:05:18.664946 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_dbt.my_first_dbt_model"
16:05:18.665190 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.my_first_dbt_model
16:05:18.665442 [debug] [Thread-1  ]: Compiling model.demo_dbt.my_first_dbt_model
16:05:18.669070 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.my_first_dbt_model"
16:05:18.669947 [debug] [Thread-1  ]: finished collecting timing info
16:05:18.670216 [debug] [Thread-1  ]: Began executing node model.demo_dbt.my_first_dbt_model
16:05:18.704132 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.my_first_dbt_model"
16:05:18.704915 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_first_dbt_model"
16:05:18.705144 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: BEGIN
16:05:18.705304 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:05:20.411591 [debug] [Thread-1  ]: SQL status: BEGIN in 1.71 seconds
16:05:20.412205 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_first_dbt_model"
16:05:20.412510 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_first_dbt_model"} */


  create  table "brightacciondb"."warehouse"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
16:05:20.633568 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.22 seconds
16:05:20.643664 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_first_dbt_model"
16:05:20.643979 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_first_dbt_model"} */
alter table "brightacciondb"."warehouse"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
16:05:20.857656 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.21 seconds
16:05:20.873471 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: COMMIT
16:05:20.874097 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_first_dbt_model"
16:05:20.874331 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: COMMIT
16:05:21.102456 [debug] [Thread-1  ]: SQL status: COMMIT in 0.23 seconds
16:05:21.109411 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_first_dbt_model"
16:05:21.109729 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_first_dbt_model"} */
drop table if exists "brightacciondb"."warehouse"."my_first_dbt_model__dbt_backup" cascade
16:05:21.322324 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.21 seconds
16:05:21.324466 [debug] [Thread-1  ]: finished collecting timing info
16:05:21.324823 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: Close
16:05:21.325802 [info ] [Thread-1  ]: 1 of 5 OK created table model warehouse.my_first_dbt_model...................... [[32mSELECT 2[0m in 2.66s]
16:05:21.326331 [debug] [Thread-1  ]: Finished running node model.demo_dbt.my_first_dbt_model
16:05:21.326628 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__customers
16:05:21.327105 [info ] [Thread-1  ]: 2 of 5 START view model warehouse.stg_eltool__customers......................... [RUN]
16:05:21.327813 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_dbt.stg_eltool__customers"
16:05:21.328084 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__customers
16:05:21.328450 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__customers
16:05:21.331362 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__customers"
16:05:21.332137 [debug] [Thread-1  ]: finished collecting timing info
16:05:21.332391 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__customers
16:05:21.351191 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.stg_eltool__customers"
16:05:21.351836 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__customers"
16:05:21.352015 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: BEGIN
16:05:21.352159 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:05:23.040231 [debug] [Thread-1  ]: SQL status: BEGIN in 1.69 seconds
16:05:23.040741 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__customers"
16:05:23.041096 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__customers"} */

  create view "brightacciondb"."warehouse"."stg_eltool__customers__dbt_tmp" as (
    with source as (
    select *
    from "brightacciondb"."snapshots"."customers_snapshot"
), renamed as (
    select customer_id,
        zipcode,
        city,
        state_code,
        datetime_created::TIMESTAMP AS datetime_created,
        datetime_updated::TIMESTAMP AS datetime_updated,
        dbt_valid_from,
        dbt_valid_to
    from source
)
select *
from renamed
  );
16:05:23.256839 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.22 seconds
16:05:23.261055 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__customers"
16:05:23.261336 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__customers"} */
alter table "brightacciondb"."warehouse"."stg_eltool__customers__dbt_tmp" rename to "stg_eltool__customers"
16:05:23.476472 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.21 seconds
16:05:23.478924 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: COMMIT
16:05:23.479253 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__customers"
16:05:23.479515 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: COMMIT
16:05:23.691214 [debug] [Thread-1  ]: SQL status: COMMIT in 0.21 seconds
16:05:23.694136 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__customers"
16:05:23.694470 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__customers"} */
drop view if exists "brightacciondb"."warehouse"."stg_eltool__customers__dbt_backup" cascade
16:05:23.907222 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.21 seconds
16:05:23.909121 [debug] [Thread-1  ]: finished collecting timing info
16:05:23.909453 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: Close
16:05:23.910618 [info ] [Thread-1  ]: 2 of 5 OK created view model warehouse.stg_eltool__customers.................... [[32mCREATE VIEW[0m in 2.58s]
16:05:23.911113 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__customers
16:05:23.911562 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__orders
16:05:23.912057 [info ] [Thread-1  ]: 3 of 5 START view model warehouse.stg_eltool__orders............................ [RUN]
16:05:23.912685 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_dbt.stg_eltool__orders"
16:05:23.912926 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__orders
16:05:23.913146 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__orders
16:05:23.916041 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__orders"
16:05:23.916592 [debug] [Thread-1  ]: finished collecting timing info
16:05:23.916802 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__orders
16:05:23.919438 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.stg_eltool__orders"
16:05:23.920090 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__orders"
16:05:23.920289 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: BEGIN
16:05:23.920453 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:05:25.642915 [debug] [Thread-1  ]: SQL status: BEGIN in 1.72 seconds
16:05:25.643558 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__orders"
16:05:25.643852 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__orders"} */

  create view "brightacciondb"."warehouse"."stg_eltool__orders__dbt_tmp" as (
    with source as (
    select *
    from "brightacciondb"."warehouse"."orders"
),
renamed as (
    select order_id,
        cust_id AS customer_id,
        order_status,
        order_purchase_timestamp::TIMESTAMP,
        order_approved_at::TIMESTAMP,
        order_delivered_carrier_date::TIMESTAMP,
        order_delivered_customer_date::TIMESTAMP,
        order_estimated_delivery_date::TIMESTAMP
        from source
)
select *
from renamed
  );
16:05:25.863434 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.22 seconds
16:05:25.867025 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__orders"
16:05:25.867331 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__orders"} */
alter table "brightacciondb"."warehouse"."stg_eltool__orders__dbt_tmp" rename to "stg_eltool__orders"
16:05:26.078789 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.21 seconds
16:05:26.081220 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: COMMIT
16:05:26.081555 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__orders"
16:05:26.081827 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: COMMIT
16:05:26.295386 [debug] [Thread-1  ]: SQL status: COMMIT in 0.21 seconds
16:05:26.298044 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__orders"
16:05:26.298305 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__orders"} */
drop view if exists "brightacciondb"."warehouse"."stg_eltool__orders__dbt_backup" cascade
16:05:26.624197 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.33 seconds
16:05:26.626340 [debug] [Thread-1  ]: finished collecting timing info
16:05:26.626759 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: Close
16:05:26.628310 [info ] [Thread-1  ]: 3 of 5 OK created view model warehouse.stg_eltool__orders....................... [[32mCREATE VIEW[0m in 2.72s]
16:05:26.629260 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__orders
16:05:26.630327 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__state
16:05:26.630960 [info ] [Thread-1  ]: 4 of 5 START view model warehouse.stg_eltool__state............................. [RUN]
16:05:26.632087 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_dbt.stg_eltool__state"
16:05:26.632396 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__state
16:05:26.632671 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__state
16:05:26.636962 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__state"
16:05:26.637517 [debug] [Thread-1  ]: finished collecting timing info
16:05:26.637728 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__state
16:05:26.639963 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.stg_eltool__state"
16:05:26.640448 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__state"
16:05:26.640675 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: BEGIN
16:05:26.640838 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:05:28.347066 [debug] [Thread-1  ]: SQL status: BEGIN in 1.71 seconds
16:05:28.347448 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__state"
16:05:28.347766 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__state"} */

  create view "brightacciondb"."warehouse"."stg_eltool__state__dbt_tmp" as (
    with source as (
    select *
    from "brightacciondb"."warehouse"."state"
),
renamed as (
    select state_identifier::INT AS state_id,
        state_code::VARCHAR(2) AS state_code,
        st_name::VARCHAR(30) AS state_name
    from source
)
select *
from renamed
  );
16:05:28.570100 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.22 seconds
16:05:28.573955 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__state"
16:05:28.574261 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__state"} */
alter table "brightacciondb"."warehouse"."stg_eltool__state__dbt_tmp" rename to "stg_eltool__state"
16:05:28.785909 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.21 seconds
16:05:28.788482 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: COMMIT
16:05:28.788790 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__state"
16:05:28.789052 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: COMMIT
16:05:29.002830 [debug] [Thread-1  ]: SQL status: COMMIT in 0.21 seconds
16:05:29.005806 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__state"
16:05:29.006149 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__state"} */
drop view if exists "brightacciondb"."warehouse"."stg_eltool__state__dbt_backup" cascade
16:05:29.220970 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.21 seconds
16:05:29.223672 [debug] [Thread-1  ]: finished collecting timing info
16:05:29.224078 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: Close
16:05:29.225045 [info ] [Thread-1  ]: 4 of 5 OK created view model warehouse.stg_eltool__state........................ [[32mCREATE VIEW[0m in 2.59s]
16:05:29.225497 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__state
16:05:29.225835 [debug] [Thread-1  ]: Began running node model.demo_dbt.my_second_dbt_model
16:05:29.226259 [info ] [Thread-1  ]: 5 of 5 START view model warehouse.my_second_dbt_model........................... [RUN]
16:05:29.226856 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_dbt.my_second_dbt_model"
16:05:29.227090 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.my_second_dbt_model
16:05:29.227309 [debug] [Thread-1  ]: Compiling model.demo_dbt.my_second_dbt_model
16:05:29.230053 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.my_second_dbt_model"
16:05:29.230646 [debug] [Thread-1  ]: finished collecting timing info
16:05:29.230918 [debug] [Thread-1  ]: Began executing node model.demo_dbt.my_second_dbt_model
16:05:29.233461 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.my_second_dbt_model"
16:05:29.233981 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_second_dbt_model"
16:05:29.234171 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: BEGIN
16:05:29.234333 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:05:30.943840 [debug] [Thread-1  ]: SQL status: BEGIN in 1.71 seconds
16:05:30.944247 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_second_dbt_model"
16:05:30.944598 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_second_dbt_model"} */

  create view "brightacciondb"."warehouse"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "brightacciondb"."warehouse"."my_first_dbt_model"
where id = 1
  );
16:05:31.163397 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.22 seconds
16:05:31.167218 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_second_dbt_model"
16:05:31.167529 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_second_dbt_model"} */
alter table "brightacciondb"."warehouse"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
16:05:31.380849 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.21 seconds
16:05:31.383530 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: COMMIT
16:05:31.383935 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_second_dbt_model"
16:05:31.384207 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: COMMIT
16:05:31.598706 [debug] [Thread-1  ]: SQL status: COMMIT in 0.21 seconds
16:05:31.601453 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_second_dbt_model"
16:05:31.601792 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_second_dbt_model"} */
drop view if exists "brightacciondb"."warehouse"."my_second_dbt_model__dbt_backup" cascade
16:05:31.811412 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.21 seconds
16:05:31.813691 [debug] [Thread-1  ]: finished collecting timing info
16:05:31.814086 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: Close
16:05:31.814893 [info ] [Thread-1  ]: 5 of 5 OK created view model warehouse.my_second_dbt_model...................... [[32mCREATE VIEW[0m in 2.59s]
16:05:31.815444 [debug] [Thread-1  ]: Finished running node model.demo_dbt.my_second_dbt_model
16:05:31.816933 [debug] [MainThread]: Acquiring new postgres connection "master"
16:05:31.817336 [debug] [MainThread]: Using postgres connection "master"
16:05:31.817642 [debug] [MainThread]: On master: BEGIN
16:05:31.817880 [debug] [MainThread]: Opening a new connection, currently in state closed
16:05:33.611601 [debug] [MainThread]: SQL status: BEGIN in 1.79 seconds
16:05:33.612243 [debug] [MainThread]: On master: COMMIT
16:05:33.612539 [debug] [MainThread]: Using postgres connection "master"
16:05:33.612798 [debug] [MainThread]: On master: COMMIT
16:05:33.935660 [debug] [MainThread]: SQL status: COMMIT in 0.32 seconds
16:05:33.936524 [debug] [MainThread]: On master: Close
16:05:33.937526 [info ] [MainThread]: 
16:05:33.938133 [info ] [MainThread]: Finished running 1 table model, 4 view models in 25.71s.
16:05:33.938598 [debug] [MainThread]: Connection 'master' was properly closed.
16:05:33.938873 [debug] [MainThread]: Connection 'model.demo_dbt.my_second_dbt_model' was properly closed.
16:05:33.947417 [info ] [MainThread]: 
16:05:33.947994 [info ] [MainThread]: [32mCompleted successfully[0m
16:05:33.948748 [info ] [MainThread]: 
16:05:33.949280 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5


============================== 2022-04-19 16:05:42.286541 | 9385c75e-cd09-44fa-a329-011f49dbf6d1 ==============================
16:05:42.286541 [info ] [MainThread]: Running with dbt=1.0.4
16:05:42.287168 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, store_failures=False, indirect_selection='eager', threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
16:05:42.287494 [debug] [MainThread]: Tracking: do not track
16:05:42.341657 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
16:05:42.341982 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
16:05:42.355424 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 165 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
16:05:42.357351 [info ] [MainThread]: 
16:05:42.357969 [debug] [MainThread]: Acquiring new postgres connection "master"
16:05:42.359075 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb_snapshots"
16:05:42.368067 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_snapshots"
16:05:42.368298 [debug] [ThreadPool]: On list_brightacciondb_snapshots: BEGIN
16:05:42.368459 [debug] [ThreadPool]: Opening a new connection, currently in state init
16:05:44.110088 [debug] [ThreadPool]: SQL status: BEGIN in 1.74 seconds
16:05:44.110694 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_snapshots"
16:05:44.110982 [debug] [ThreadPool]: On list_brightacciondb_snapshots: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_brightacciondb_snapshots"} */
select
      'brightacciondb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'brightacciondb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
  
16:05:44.344393 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.23 seconds
16:05:44.347159 [debug] [ThreadPool]: On list_brightacciondb_snapshots: ROLLBACK
16:05:44.562791 [debug] [ThreadPool]: On list_brightacciondb_snapshots: Close
16:05:44.564246 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb_warehouse"
16:05:44.566992 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_warehouse"
16:05:44.567418 [debug] [ThreadPool]: On list_brightacciondb_warehouse: BEGIN
16:05:44.567643 [debug] [ThreadPool]: Opening a new connection, currently in state closed
16:05:46.370579 [debug] [ThreadPool]: SQL status: BEGIN in 1.8 seconds
16:05:46.371180 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_warehouse"
16:05:46.371826 [debug] [ThreadPool]: On list_brightacciondb_warehouse: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_brightacciondb_warehouse"} */
select
      'brightacciondb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'brightacciondb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
16:05:46.593458 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.22 seconds
16:05:46.596189 [debug] [ThreadPool]: On list_brightacciondb_warehouse: ROLLBACK
16:05:46.804853 [debug] [ThreadPool]: On list_brightacciondb_warehouse: Close
16:05:46.811645 [debug] [MainThread]: Using postgres connection "master"
16:05:46.811975 [debug] [MainThread]: On master: BEGIN
16:05:46.812193 [debug] [MainThread]: Opening a new connection, currently in state init
16:05:48.509872 [debug] [MainThread]: SQL status: BEGIN in 1.7 seconds
16:05:48.510203 [debug] [MainThread]: Using postgres connection "master"
16:05:48.510387 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
16:05:48.740946 [debug] [MainThread]: SQL status: SELECT 4 in 0.23 seconds
16:05:48.743429 [debug] [MainThread]: On master: ROLLBACK
16:05:48.953159 [debug] [MainThread]: Using postgres connection "master"
16:05:48.953841 [debug] [MainThread]: On master: BEGIN
16:05:49.464013 [debug] [MainThread]: SQL status: BEGIN in 0.51 seconds
16:05:49.464447 [debug] [MainThread]: On master: COMMIT
16:05:49.464769 [debug] [MainThread]: Using postgres connection "master"
16:05:49.464984 [debug] [MainThread]: On master: COMMIT
16:05:49.675790 [debug] [MainThread]: SQL status: COMMIT in 0.21 seconds
16:05:49.676531 [debug] [MainThread]: On master: Close
16:05:49.677371 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
16:05:49.677918 [info ] [MainThread]: 
16:05:49.685715 [debug] [Thread-1  ]: Began running node test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710
16:05:49.686072 [info ] [Thread-1  ]: 1 of 9 START test not_null_my_first_dbt_model_id................................ [RUN]
16:05:49.686762 [debug] [Thread-1  ]: Acquiring new postgres connection "test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
16:05:49.687027 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710
16:05:49.687297 [debug] [Thread-1  ]: Compiling test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710
16:05:49.700266 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
16:05:49.700905 [debug] [Thread-1  ]: finished collecting timing info
16:05:49.701109 [debug] [Thread-1  ]: Began executing node test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710
16:05:49.717499 [debug] [Thread-1  ]: Writing runtime SQL for node "test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
16:05:49.718148 [debug] [Thread-1  ]: Using postgres connection "test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
16:05:49.718431 [debug] [Thread-1  ]: On test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
16:05:49.718594 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:05:51.631590 [debug] [Thread-1  ]: SQL status: BEGIN in 1.91 seconds
16:05:51.633357 [debug] [Thread-1  ]: Using postgres connection "test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
16:05:51.633712 [debug] [Thread-1  ]: On test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from "brightacciondb"."warehouse"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
16:05:51.845530 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.21 seconds
16:05:51.866157 [debug] [Thread-1  ]: finished collecting timing info
16:05:51.866933 [debug] [Thread-1  ]: On test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
16:05:52.077312 [debug] [Thread-1  ]: On test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710: Close
16:05:52.078474 [error] [Thread-1  ]: 1 of 9 FAIL 1 not_null_my_first_dbt_model_id.................................... [[31mFAIL 1[0m in 2.39s]
16:05:52.079151 [debug] [Thread-1  ]: Finished running node test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710
16:05:52.079506 [debug] [Thread-1  ]: Began running node test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778
16:05:52.079948 [info ] [Thread-1  ]: 2 of 9 START test not_null_my_second_dbt_model_id............................... [RUN]
16:05:52.080657 [debug] [Thread-1  ]: Acquiring new postgres connection "test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778"
16:05:52.081102 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778
16:05:52.081365 [debug] [Thread-1  ]: Compiling test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778
16:05:52.086255 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778"
16:05:52.086848 [debug] [Thread-1  ]: finished collecting timing info
16:05:52.087058 [debug] [Thread-1  ]: Began executing node test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778
16:05:52.088894 [debug] [Thread-1  ]: Writing runtime SQL for node "test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778"
16:05:52.089446 [debug] [Thread-1  ]: Using postgres connection "test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778"
16:05:52.089766 [debug] [Thread-1  ]: On test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778: BEGIN
16:05:52.090034 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:05:54.484491 [debug] [Thread-1  ]: SQL status: BEGIN in 2.39 seconds
16:05:54.484973 [debug] [Thread-1  ]: Using postgres connection "test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778"
16:05:54.485237 [debug] [Thread-1  ]: On test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from "brightacciondb"."warehouse"."my_second_dbt_model"
where id is null



      
    ) dbt_internal_test
16:05:54.699482 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.21 seconds
16:05:54.703357 [debug] [Thread-1  ]: finished collecting timing info
16:05:54.704135 [debug] [Thread-1  ]: On test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778: ROLLBACK
16:05:55.103232 [debug] [Thread-1  ]: On test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
16:05:55.105461 [info ] [Thread-1  ]: 2 of 9 PASS not_null_my_second_dbt_model_id..................................... [[32mPASS[0m in 3.03s]
16:05:55.106449 [debug] [Thread-1  ]: Finished running node test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778
16:05:55.106941 [debug] [Thread-1  ]: Began running node test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df
16:05:55.107316 [info ] [Thread-1  ]: 3 of 9 START test not_null_stg_eltool__customers_customer_id.................... [RUN]
16:05:55.107935 [debug] [Thread-1  ]: Acquiring new postgres connection "test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df"
16:05:55.108177 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df
16:05:55.108399 [debug] [Thread-1  ]: Compiling test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df
16:05:55.113068 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df"
16:05:55.113750 [debug] [Thread-1  ]: finished collecting timing info
16:05:55.113954 [debug] [Thread-1  ]: Began executing node test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df
16:05:55.115973 [debug] [Thread-1  ]: Writing runtime SQL for node "test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df"
16:05:55.116634 [debug] [Thread-1  ]: Using postgres connection "test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df"
16:05:55.116843 [debug] [Thread-1  ]: On test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df: BEGIN
16:05:55.117018 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:05:56.865893 [debug] [Thread-1  ]: SQL status: BEGIN in 1.75 seconds
16:05:56.866454 [debug] [Thread-1  ]: Using postgres connection "test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df"
16:05:56.866799 [debug] [Thread-1  ]: On test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from "brightacciondb"."warehouse"."stg_eltool__customers"
where customer_id is null



      
    ) dbt_internal_test
16:05:57.080391 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.21 seconds
16:05:57.082128 [debug] [Thread-1  ]: finished collecting timing info
16:05:57.082376 [debug] [Thread-1  ]: On test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df: ROLLBACK
16:05:57.295454 [debug] [Thread-1  ]: On test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df: Close
16:05:57.297251 [info ] [Thread-1  ]: 3 of 9 PASS not_null_stg_eltool__customers_customer_id.......................... [[32mPASS[0m in 2.19s]
16:05:57.298155 [debug] [Thread-1  ]: Finished running node test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df
16:05:57.299029 [debug] [Thread-1  ]: Began running node test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6
16:05:57.299392 [info ] [Thread-1  ]: 4 of 9 START test source_not_null_warehouse_customers_customer_id............... [RUN]
16:05:57.300028 [debug] [Thread-1  ]: Acquiring new postgres connection "test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6"
16:05:57.300243 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6
16:05:57.300442 [debug] [Thread-1  ]: Compiling test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6
16:05:57.304765 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6"
16:05:57.305445 [debug] [Thread-1  ]: finished collecting timing info
16:05:57.305743 [debug] [Thread-1  ]: Began executing node test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6
16:05:57.308220 [debug] [Thread-1  ]: Writing runtime SQL for node "test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6"
16:05:57.308984 [debug] [Thread-1  ]: Using postgres connection "test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6"
16:05:57.309185 [debug] [Thread-1  ]: On test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6: BEGIN
16:05:57.309359 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:05:59.024821 [debug] [Thread-1  ]: SQL status: BEGIN in 1.72 seconds
16:05:59.025149 [debug] [Thread-1  ]: Using postgres connection "test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6"
16:05:59.025569 [debug] [Thread-1  ]: On test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from "brightacciondb"."warehouse"."customers"
where customer_id is null



      
    ) dbt_internal_test
16:05:59.239650 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.21 seconds
16:05:59.241864 [debug] [Thread-1  ]: finished collecting timing info
16:05:59.242170 [debug] [Thread-1  ]: On test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6: ROLLBACK
16:05:59.453482 [debug] [Thread-1  ]: On test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6: Close
16:05:59.454369 [info ] [Thread-1  ]: 4 of 9 PASS source_not_null_warehouse_customers_customer_id..................... [[32mPASS[0m in 2.15s]
16:05:59.454798 [debug] [Thread-1  ]: Finished running node test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6
16:05:59.455068 [debug] [Thread-1  ]: Began running node test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76
16:05:59.455354 [info ] [Thread-1  ]: 5 of 9 START test source_not_null_warehouse_orders_order_id..................... [RUN]
16:05:59.455832 [debug] [Thread-1  ]: Acquiring new postgres connection "test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76"
16:05:59.456425 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76
16:05:59.456709 [debug] [Thread-1  ]: Compiling test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76
16:05:59.461380 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76"
16:05:59.461978 [debug] [Thread-1  ]: finished collecting timing info
16:05:59.462188 [debug] [Thread-1  ]: Began executing node test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76
16:05:59.465752 [debug] [Thread-1  ]: Writing runtime SQL for node "test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76"
16:05:59.466587 [debug] [Thread-1  ]: Using postgres connection "test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76"
16:05:59.466799 [debug] [Thread-1  ]: On test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76: BEGIN
16:05:59.466959 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:06:01.319743 [debug] [Thread-1  ]: SQL status: BEGIN in 1.85 seconds
16:06:01.320257 [debug] [Thread-1  ]: Using postgres connection "test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76"
16:06:01.320481 [debug] [Thread-1  ]: On test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from "brightacciondb"."warehouse"."orders"
where order_id is null



      
    ) dbt_internal_test
16:06:02.016859 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.7 seconds
16:06:02.019189 [debug] [Thread-1  ]: finished collecting timing info
16:06:02.019575 [debug] [Thread-1  ]: On test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76: ROLLBACK
16:06:02.231493 [debug] [Thread-1  ]: On test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76: Close
16:06:02.232775 [info ] [Thread-1  ]: 5 of 9 PASS source_not_null_warehouse_orders_order_id........................... [[32mPASS[0m in 2.78s]
16:06:02.233192 [debug] [Thread-1  ]: Finished running node test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76
16:06:02.233520 [debug] [Thread-1  ]: Began running node test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2
16:06:02.233866 [info ] [Thread-1  ]: 6 of 9 START test source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_ [RUN]
16:06:02.234442 [debug] [Thread-1  ]: Acquiring new postgres connection "test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2"
16:06:02.234667 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2
16:06:02.234856 [debug] [Thread-1  ]: Compiling test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2
16:06:02.244772 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2"
16:06:02.245629 [debug] [Thread-1  ]: finished collecting timing info
16:06:02.245893 [debug] [Thread-1  ]: Began executing node test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2
16:06:02.249127 [debug] [Thread-1  ]: Writing runtime SQL for node "test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2"
16:06:02.249702 [debug] [Thread-1  ]: Using postgres connection "test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2"
16:06:02.249897 [debug] [Thread-1  ]: On test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2: BEGIN
16:06:02.250041 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:06:03.970480 [debug] [Thread-1  ]: SQL status: BEGIN in 1.72 seconds
16:06:03.971319 [debug] [Thread-1  ]: Using postgres connection "test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2"
16:06:03.971613 [debug] [Thread-1  ]: On test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select cust_id as from_field
    from "brightacciondb"."warehouse"."orders"
    where cust_id is not null
),

parent as (
    select customer_id as to_field
    from "brightacciondb"."warehouse"."customers"
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
16:06:04.183084 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.21 seconds
16:06:04.185888 [debug] [Thread-1  ]: finished collecting timing info
16:06:04.186771 [debug] [Thread-1  ]: On test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2: ROLLBACK
16:06:04.401169 [debug] [Thread-1  ]: On test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2: Close
16:06:04.402591 [info ] [Thread-1  ]: 6 of 9 PASS source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_ [[32mPASS[0m in 2.17s]
16:06:04.403162 [debug] [Thread-1  ]: Finished running node test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2
16:06:04.403480 [debug] [Thread-1  ]: Began running node test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f
16:06:04.403859 [info ] [Thread-1  ]: 7 of 9 START test source_unique_warehouse_orders_order_id....................... [RUN]
16:06:04.404621 [debug] [Thread-1  ]: Acquiring new postgres connection "test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f"
16:06:04.404867 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f
16:06:04.405087 [debug] [Thread-1  ]: Compiling test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f
16:06:04.414157 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f"
16:06:04.414827 [debug] [Thread-1  ]: finished collecting timing info
16:06:04.415137 [debug] [Thread-1  ]: Began executing node test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f
16:06:04.419255 [debug] [Thread-1  ]: Writing runtime SQL for node "test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f"
16:06:04.419824 [debug] [Thread-1  ]: Using postgres connection "test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f"
16:06:04.419994 [debug] [Thread-1  ]: On test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f: BEGIN
16:06:04.420132 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:06:06.226280 [debug] [Thread-1  ]: SQL status: BEGIN in 1.81 seconds
16:06:06.226585 [debug] [Thread-1  ]: Using postgres connection "test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f"
16:06:06.226764 [debug] [Thread-1  ]: On test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from "brightacciondb"."warehouse"."orders"
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
16:06:06.457166 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.23 seconds
16:06:06.458792 [debug] [Thread-1  ]: finished collecting timing info
16:06:06.459074 [debug] [Thread-1  ]: On test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f: ROLLBACK
16:06:06.669734 [debug] [Thread-1  ]: On test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f: Close
16:06:06.671167 [info ] [Thread-1  ]: 7 of 9 PASS source_unique_warehouse_orders_order_id............................. [[32mPASS[0m in 2.27s]
16:06:06.672458 [debug] [Thread-1  ]: Finished running node test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f
16:06:06.672872 [debug] [Thread-1  ]: Began running node test.demo_dbt.unique_my_first_dbt_model_id.16e066b321
16:06:06.673500 [info ] [Thread-1  ]: 8 of 9 START test unique_my_first_dbt_model_id.................................. [RUN]
16:06:06.674319 [debug] [Thread-1  ]: Acquiring new postgres connection "test.demo_dbt.unique_my_first_dbt_model_id.16e066b321"
16:06:06.680416 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.unique_my_first_dbt_model_id.16e066b321
16:06:06.680949 [debug] [Thread-1  ]: Compiling test.demo_dbt.unique_my_first_dbt_model_id.16e066b321
16:06:06.689040 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.unique_my_first_dbt_model_id.16e066b321"
16:06:06.690151 [debug] [Thread-1  ]: finished collecting timing info
16:06:06.690515 [debug] [Thread-1  ]: Began executing node test.demo_dbt.unique_my_first_dbt_model_id.16e066b321
16:06:06.694265 [debug] [Thread-1  ]: Writing runtime SQL for node "test.demo_dbt.unique_my_first_dbt_model_id.16e066b321"
16:06:06.695703 [debug] [Thread-1  ]: Using postgres connection "test.demo_dbt.unique_my_first_dbt_model_id.16e066b321"
16:06:06.696068 [debug] [Thread-1  ]: On test.demo_dbt.unique_my_first_dbt_model_id.16e066b321: BEGIN
16:06:06.696334 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:06:08.486018 [debug] [Thread-1  ]: SQL status: BEGIN in 1.79 seconds
16:06:08.486849 [debug] [Thread-1  ]: Using postgres connection "test.demo_dbt.unique_my_first_dbt_model_id.16e066b321"
16:06:08.487137 [debug] [Thread-1  ]: On test.demo_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "test.demo_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "brightacciondb"."warehouse"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
16:06:08.695857 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.21 seconds
16:06:08.697617 [debug] [Thread-1  ]: finished collecting timing info
16:06:08.697902 [debug] [Thread-1  ]: On test.demo_dbt.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
16:06:09.130018 [debug] [Thread-1  ]: On test.demo_dbt.unique_my_first_dbt_model_id.16e066b321: Close
16:06:09.130762 [info ] [Thread-1  ]: 8 of 9 PASS unique_my_first_dbt_model_id........................................ [[32mPASS[0m in 2.46s]
16:06:09.131265 [debug] [Thread-1  ]: Finished running node test.demo_dbt.unique_my_first_dbt_model_id.16e066b321
16:06:09.131568 [debug] [Thread-1  ]: Began running node test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493
16:06:09.131902 [info ] [Thread-1  ]: 9 of 9 START test unique_my_second_dbt_model_id................................. [RUN]
16:06:09.132549 [debug] [Thread-1  ]: Acquiring new postgres connection "test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493"
16:06:09.132766 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493
16:06:09.132954 [debug] [Thread-1  ]: Compiling test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493
16:06:09.136917 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493"
16:06:09.137543 [debug] [Thread-1  ]: finished collecting timing info
16:06:09.137732 [debug] [Thread-1  ]: Began executing node test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493
16:06:09.139432 [debug] [Thread-1  ]: Writing runtime SQL for node "test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493"
16:06:09.139902 [debug] [Thread-1  ]: Using postgres connection "test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493"
16:06:09.140070 [debug] [Thread-1  ]: On test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493: BEGIN
16:06:09.140213 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
16:06:10.865750 [debug] [Thread-1  ]: SQL status: BEGIN in 1.73 seconds
16:06:10.866535 [debug] [Thread-1  ]: Using postgres connection "test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493"
16:06:10.868916 [debug] [Thread-1  ]: On test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "brightacciondb"."warehouse"."my_second_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
16:06:11.148046 [debug] [Thread-1  ]: SQL status: SELECT 1 in 0.28 seconds
16:06:11.150267 [debug] [Thread-1  ]: finished collecting timing info
16:06:11.150582 [debug] [Thread-1  ]: On test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493: ROLLBACK
16:06:11.364754 [debug] [Thread-1  ]: On test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
16:06:11.365868 [info ] [Thread-1  ]: 9 of 9 PASS unique_my_second_dbt_model_id....................................... [[32mPASS[0m in 2.23s]
16:06:11.366575 [debug] [Thread-1  ]: Finished running node test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493
16:06:11.368090 [debug] [MainThread]: Acquiring new postgres connection "master"
16:06:11.368401 [debug] [MainThread]: Using postgres connection "master"
16:06:11.368619 [debug] [MainThread]: On master: BEGIN
16:06:11.368819 [debug] [MainThread]: Opening a new connection, currently in state closed
16:06:13.243558 [debug] [MainThread]: SQL status: BEGIN in 1.87 seconds
16:06:13.248012 [debug] [MainThread]: On master: COMMIT
16:06:13.248766 [debug] [MainThread]: Using postgres connection "master"
16:06:13.249188 [debug] [MainThread]: On master: COMMIT
16:06:13.463817 [debug] [MainThread]: SQL status: COMMIT in 0.21 seconds
16:06:13.464436 [debug] [MainThread]: On master: Close
16:06:13.465979 [info ] [MainThread]: 
16:06:13.466478 [info ] [MainThread]: Finished running 9 tests in 31.11s.
16:06:13.467222 [debug] [MainThread]: Connection 'master' was properly closed.
16:06:13.467715 [debug] [MainThread]: Connection 'test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
16:06:13.482540 [info ] [MainThread]: 
16:06:13.483048 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
16:06:13.483814 [info ] [MainThread]: 
16:06:13.484256 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
16:06:13.484922 [error] [MainThread]:   Got 1 result, configured to fail if != 0
16:06:13.485350 [info ] [MainThread]: 
16:06:13.485855 [info ] [MainThread]:   compiled SQL at target/compiled/demo_dbt/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
16:06:13.486353 [info ] [MainThread]: 
16:06:13.486784 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=1 SKIP=0 TOTAL=9


============================== 2022-06-29 11:16:29.058142 | c3c10bde-cb4d-4c22-9fe7-9f7824b1c76f ==============================
11:16:29.058142 [info ] [MainThread]: Running with dbt=1.0.4
11:16:29.059791 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.snapshot.SnapshotTask'>, which='snapshot', rpc_method='snapshot')
11:16:29.060452 [debug] [MainThread]: Tracking: do not track
11:16:29.126362 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
11:16:29.174697 [debug] [MainThread]: Parsing macros/catalog.sql
11:16:29.180682 [debug] [MainThread]: Parsing macros/relations.sql
11:16:29.182532 [debug] [MainThread]: Parsing macros/adapters.sql
11:16:29.209098 [debug] [MainThread]: Parsing macros/materializations/snapshot_merge.sql
11:16:29.210949 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
11:16:29.214801 [debug] [MainThread]: Parsing macros/materializations/configs.sql
11:16:29.217403 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
11:16:29.219212 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
11:16:29.236971 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
11:16:29.248741 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
11:16:29.260882 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
11:16:29.265919 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
11:16:29.268787 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
11:16:29.270697 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
11:16:29.275575 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
11:16:29.287058 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
11:16:29.288605 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
11:16:29.298818 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
11:16:29.315240 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
11:16:29.323416 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
11:16:29.326340 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
11:16:29.333579 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
11:16:29.335033 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
11:16:29.337881 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
11:16:29.340207 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
11:16:29.346542 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
11:16:29.363757 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
11:16:29.365367 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
11:16:29.368000 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
11:16:29.369916 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
11:16:29.370864 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
11:16:29.371625 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
11:16:29.372379 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
11:16:29.373758 [debug] [MainThread]: Parsing macros/etc/statement.sql
11:16:29.378347 [debug] [MainThread]: Parsing macros/etc/datetime.sql
11:16:29.386837 [debug] [MainThread]: Parsing macros/adapters/schema.sql
11:16:29.389070 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
11:16:29.391754 [debug] [MainThread]: Parsing macros/adapters/relation.sql
11:16:29.401476 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
11:16:29.404893 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
11:16:29.409808 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
11:16:29.417677 [debug] [MainThread]: Parsing macros/adapters/columns.sql
11:16:29.428091 [debug] [MainThread]: Parsing tests/generic/builtin.sql
11:16:29.615280 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
11:16:29.628596 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
11:16:29.631094 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
11:16:29.633437 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
11:16:29.636452 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
11:16:29.796042 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 165 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
11:16:29.797734 [info ] [MainThread]: 
11:16:29.798365 [debug] [MainThread]: Acquiring new postgres connection "master"
11:16:29.799083 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb"
11:16:29.809215 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb"
11:16:29.809500 [debug] [ThreadPool]: On list_brightacciondb: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_brightacciondb"} */

    select distinct nspname from pg_namespace
  
11:16:29.809670 [debug] [ThreadPool]: Opening a new connection, currently in state init
11:16:32.265924 [debug] [ThreadPool]: SQL status: SELECT 8 in 2.46 seconds
11:16:32.269034 [debug] [ThreadPool]: On list_brightacciondb: Close
11:16:32.272918 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb_warehouse"
11:16:32.280271 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_warehouse"
11:16:32.280563 [debug] [ThreadPool]: On list_brightacciondb_warehouse: BEGIN
11:16:32.280744 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:16:34.054890 [debug] [ThreadPool]: SQL status: BEGIN in 1.77 seconds
11:16:34.055332 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_warehouse"
11:16:34.055615 [debug] [ThreadPool]: On list_brightacciondb_warehouse: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_brightacciondb_warehouse"} */
select
      'brightacciondb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'brightacciondb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
11:16:34.286163 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.23 seconds
11:16:34.288691 [debug] [ThreadPool]: On list_brightacciondb_warehouse: ROLLBACK
11:16:34.512048 [debug] [ThreadPool]: On list_brightacciondb_warehouse: Close
11:16:34.513752 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb_snapshots"
11:16:34.517768 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_snapshots"
11:16:34.518358 [debug] [ThreadPool]: On list_brightacciondb_snapshots: BEGIN
11:16:34.519083 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:16:36.632064 [debug] [ThreadPool]: SQL status: BEGIN in 2.11 seconds
11:16:36.632488 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_snapshots"
11:16:36.632765 [debug] [ThreadPool]: On list_brightacciondb_snapshots: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_brightacciondb_snapshots"} */
select
      'brightacciondb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'brightacciondb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
  
11:16:36.870221 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.24 seconds
11:16:36.874029 [debug] [ThreadPool]: On list_brightacciondb_snapshots: ROLLBACK
11:16:37.098947 [debug] [ThreadPool]: On list_brightacciondb_snapshots: Close
11:16:37.105057 [debug] [MainThread]: Using postgres connection "master"
11:16:37.105396 [debug] [MainThread]: On master: BEGIN
11:16:37.105621 [debug] [MainThread]: Opening a new connection, currently in state init
11:16:38.914654 [debug] [MainThread]: SQL status: BEGIN in 1.81 seconds
11:16:38.915146 [debug] [MainThread]: Using postgres connection "master"
11:16:38.915495 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
11:16:39.171810 [debug] [MainThread]: SQL status: SELECT 4 in 0.26 seconds
11:16:39.174345 [debug] [MainThread]: On master: ROLLBACK
11:16:39.396944 [debug] [MainThread]: Using postgres connection "master"
11:16:39.397436 [debug] [MainThread]: On master: BEGIN
11:16:39.845844 [debug] [MainThread]: SQL status: BEGIN in 0.45 seconds
11:16:39.846437 [debug] [MainThread]: On master: COMMIT
11:16:39.846889 [debug] [MainThread]: Using postgres connection "master"
11:16:39.847365 [debug] [MainThread]: On master: COMMIT
11:16:40.071840 [debug] [MainThread]: SQL status: COMMIT in 0.22 seconds
11:16:40.072533 [debug] [MainThread]: On master: Close
11:16:40.073369 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
11:16:40.073870 [info ] [MainThread]: 
11:16:40.115108 [debug] [Thread-1  ]: Began running node snapshot.demo_dbt.customers_snapshot
11:16:40.115626 [info ] [Thread-1  ]: 1 of 1 START snapshot snapshots.customers_snapshot.............................. [RUN]
11:16:40.116666 [debug] [Thread-1  ]: Acquiring new postgres connection "snapshot.demo_dbt.customers_snapshot"
11:16:40.116946 [debug] [Thread-1  ]: Began compiling node snapshot.demo_dbt.customers_snapshot
11:16:40.117166 [debug] [Thread-1  ]: Compiling snapshot.demo_dbt.customers_snapshot
11:16:40.121330 [debug] [Thread-1  ]: finished collecting timing info
11:16:40.121777 [debug] [Thread-1  ]: Began executing node snapshot.demo_dbt.customers_snapshot
11:16:40.149822 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
11:16:40.150106 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

    select count(*) from pg_namespace where nspname = 'snapshots'
  
11:16:40.150274 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:16:41.945791 [debug] [Thread-1  ]: SQL status: SELECT 1 in 1.8 seconds
11:16:41.975317 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
11:16:41.975698 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: BEGIN
11:16:42.201809 [debug] [Thread-1  ]: SQL status: BEGIN in 0.23 seconds
11:16:42.202164 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
11:16:42.202457 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "brightacciondb".INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot'
        
        and table_schema = 'snapshots'
        
      order by ordinal_position

  
11:16:42.449843 [debug] [Thread-1  ]: SQL status: SELECT 10 in 0.25 seconds
11:16:42.478686 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
11:16:42.478979 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

        

  create temporary table "customers_snapshot__dbt_tmp164642467833"
  as (
    with snapshot_query as (

        



select * from "brightacciondb"."warehouse"."customers"


    ),

    snapshotted_data as (

        select *,
            customer_id as dbt_unique_key

        from "brightacciondb"."snapshots"."customers_snapshot"
        where dbt_valid_to is null

    ),

    insertions_source_data as (

        select
            *,
            customer_id as dbt_unique_key,
            datetime_updated as dbt_updated_at,
            datetime_updated as dbt_valid_from,
            nullif(datetime_updated, datetime_updated) as dbt_valid_to,
            md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(datetime_updated as varchar ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select
            *,
            customer_id as dbt_unique_key,
            datetime_updated as dbt_updated_at,
            datetime_updated as dbt_valid_from,
            datetime_updated as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where snapshotted_data.dbt_unique_key is null
           or (
                snapshotted_data.dbt_unique_key is not null
            and (
                (snapshotted_data.dbt_valid_from < source_data.datetime_updated)
            )
        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where (
            (snapshotted_data.dbt_valid_from < source_data.datetime_updated)
        )
    )

    select * from insertions
    union all
    select * from updates

  );
    
11:16:42.738089 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.26 seconds
11:16:42.742308 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
11:16:42.742717 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot__dbt_tmp164642467833'
        
      order by ordinal_position

  
11:16:42.970756 [debug] [Thread-1  ]: SQL status: SELECT 12 in 0.23 seconds
11:16:42.976136 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
11:16:42.976460 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "brightacciondb".INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot'
        
        and table_schema = 'snapshots'
        
      order by ordinal_position

  
11:16:43.202772 [debug] [Thread-1  ]: SQL status: SELECT 10 in 0.23 seconds
11:16:43.207096 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
11:16:43.207403 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot__dbt_tmp164642467833'
        
      order by ordinal_position

  
11:16:43.435075 [debug] [Thread-1  ]: SQL status: SELECT 12 in 0.23 seconds
11:16:43.439990 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
11:16:43.440258 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "brightacciondb".INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot'
        
        and table_schema = 'snapshots'
        
      order by ordinal_position

  
11:16:43.670130 [debug] [Thread-1  ]: SQL status: SELECT 10 in 0.23 seconds
11:16:43.680181 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
11:16:43.680577 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot__dbt_tmp164642467833'
        
      order by ordinal_position

  
11:16:43.909921 [debug] [Thread-1  ]: SQL status: SELECT 12 in 0.23 seconds
11:16:43.921593 [debug] [Thread-1  ]: Writing runtime SQL for node "snapshot.demo_dbt.customers_snapshot"
11:16:43.923907 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
11:16:43.924370 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

      update "brightacciondb"."snapshots"."customers_snapshot"
    set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to
    from "customers_snapshot__dbt_tmp164642467833" as DBT_INTERNAL_SOURCE
    where DBT_INTERNAL_SOURCE.dbt_scd_id::text = "brightacciondb"."snapshots"."customers_snapshot".dbt_scd_id::text
      and DBT_INTERNAL_SOURCE.dbt_change_type::text in ('update'::text, 'delete'::text)
      and "brightacciondb"."snapshots"."customers_snapshot".dbt_valid_to is null;

    insert into "brightacciondb"."snapshots"."customers_snapshot" ("customer_id", "zipcode", "city", "state_code", "datetime_created", "datetime_updated", "dbt_updated_at", "dbt_valid_from", "dbt_valid_to", "dbt_scd_id")
    select DBT_INTERNAL_SOURCE."customer_id",DBT_INTERNAL_SOURCE."zipcode",DBT_INTERNAL_SOURCE."city",DBT_INTERNAL_SOURCE."state_code",DBT_INTERNAL_SOURCE."datetime_created",DBT_INTERNAL_SOURCE."datetime_updated",DBT_INTERNAL_SOURCE."dbt_updated_at",DBT_INTERNAL_SOURCE."dbt_valid_from",DBT_INTERNAL_SOURCE."dbt_valid_to",DBT_INTERNAL_SOURCE."dbt_scd_id"
    from "customers_snapshot__dbt_tmp164642467833" as DBT_INTERNAL_SOURCE
    where DBT_INTERNAL_SOURCE.dbt_change_type::text = 'insert'::text;

  
11:16:44.151725 [debug] [Thread-1  ]: SQL status: INSERT 0 0 in 0.23 seconds
11:16:44.161066 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: COMMIT
11:16:44.161406 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
11:16:44.161621 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: COMMIT
11:16:44.386981 [debug] [Thread-1  ]: SQL status: COMMIT in 0.23 seconds
11:16:44.390312 [debug] [Thread-1  ]: finished collecting timing info
11:16:44.390603 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: Close
11:16:44.391382 [info ] [Thread-1  ]: 1 of 1 OK snapshotted snapshots.customers_snapshot.............................. [[32mINSERT 0 0[0m in 4.27s]
11:16:44.391857 [debug] [Thread-1  ]: Finished running node snapshot.demo_dbt.customers_snapshot
11:16:44.395777 [debug] [MainThread]: Acquiring new postgres connection "master"
11:16:44.396157 [debug] [MainThread]: Using postgres connection "master"
11:16:44.396380 [debug] [MainThread]: On master: BEGIN
11:16:44.396580 [debug] [MainThread]: Opening a new connection, currently in state closed
11:16:46.198843 [debug] [MainThread]: SQL status: BEGIN in 1.8 seconds
11:16:46.199310 [debug] [MainThread]: On master: COMMIT
11:16:46.199601 [debug] [MainThread]: Using postgres connection "master"
11:16:46.199859 [debug] [MainThread]: On master: COMMIT
11:16:46.425490 [debug] [MainThread]: SQL status: COMMIT in 0.23 seconds
11:16:46.426185 [debug] [MainThread]: On master: Close
11:16:46.427026 [info ] [MainThread]: 
11:16:46.427513 [info ] [MainThread]: Finished running 1 snapshot in 16.63s.
11:16:46.428254 [debug] [MainThread]: Connection 'master' was properly closed.
11:16:46.428637 [debug] [MainThread]: Connection 'snapshot.demo_dbt.customers_snapshot' was properly closed.
11:16:46.438817 [info ] [MainThread]: 
11:16:46.439290 [info ] [MainThread]: [32mCompleted successfully[0m
11:16:46.439705 [info ] [MainThread]: 
11:16:46.440075 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1


============================== 2022-06-29 11:18:20.688483 | 1fe7d15c-c5e8-445d-831d-9108ec08cbba ==============================
11:18:20.688483 [info ] [MainThread]: Running with dbt=1.0.4
11:18:20.689081 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
11:18:20.689575 [debug] [MainThread]: Tracking: do not track
11:18:20.766124 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
11:18:20.766604 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
11:18:20.784929 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 165 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
11:18:20.787621 [info ] [MainThread]: 
11:18:20.788725 [debug] [MainThread]: Acquiring new postgres connection "master"
11:18:20.790504 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb"
11:18:20.801192 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb"
11:18:20.801490 [debug] [ThreadPool]: On list_brightacciondb: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_brightacciondb"} */

    select distinct nspname from pg_namespace
  
11:18:20.801695 [debug] [ThreadPool]: Opening a new connection, currently in state init
11:18:22.691278 [debug] [ThreadPool]: SQL status: SELECT 10 in 1.89 seconds
11:18:22.693907 [debug] [ThreadPool]: On list_brightacciondb: Close
11:18:22.695765 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb_snapshots"
11:18:22.703288 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_snapshots"
11:18:22.703576 [debug] [ThreadPool]: On list_brightacciondb_snapshots: BEGIN
11:18:22.703756 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:18:24.508028 [debug] [ThreadPool]: SQL status: BEGIN in 1.8 seconds
11:18:24.508521 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_snapshots"
11:18:24.508872 [debug] [ThreadPool]: On list_brightacciondb_snapshots: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_brightacciondb_snapshots"} */
select
      'brightacciondb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'brightacciondb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
  
11:18:24.735410 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.23 seconds
11:18:24.738196 [debug] [ThreadPool]: On list_brightacciondb_snapshots: ROLLBACK
11:18:24.961984 [debug] [ThreadPool]: On list_brightacciondb_snapshots: Close
11:18:24.963084 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb_warehouse"
11:18:24.965268 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_warehouse"
11:18:24.965527 [debug] [ThreadPool]: On list_brightacciondb_warehouse: BEGIN
11:18:24.965735 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:18:26.731346 [debug] [ThreadPool]: SQL status: BEGIN in 1.77 seconds
11:18:26.732022 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_warehouse"
11:18:26.732329 [debug] [ThreadPool]: On list_brightacciondb_warehouse: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_brightacciondb_warehouse"} */
select
      'brightacciondb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'brightacciondb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
11:18:26.955266 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.22 seconds
11:18:26.957725 [debug] [ThreadPool]: On list_brightacciondb_warehouse: ROLLBACK
11:18:27.177493 [debug] [ThreadPool]: On list_brightacciondb_warehouse: Close
11:18:27.183767 [debug] [MainThread]: Using postgres connection "master"
11:18:27.184099 [debug] [MainThread]: On master: BEGIN
11:18:27.184319 [debug] [MainThread]: Opening a new connection, currently in state init
11:18:29.003341 [debug] [MainThread]: SQL status: BEGIN in 1.82 seconds
11:18:29.004053 [debug] [MainThread]: Using postgres connection "master"
11:18:29.004349 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
11:18:29.249849 [debug] [MainThread]: SQL status: SELECT 4 in 0.25 seconds
11:18:29.252323 [debug] [MainThread]: On master: ROLLBACK
11:18:29.477570 [debug] [MainThread]: Using postgres connection "master"
11:18:29.478153 [debug] [MainThread]: On master: BEGIN
11:18:29.930020 [debug] [MainThread]: SQL status: BEGIN in 0.45 seconds
11:18:29.930545 [debug] [MainThread]: On master: COMMIT
11:18:29.930910 [debug] [MainThread]: Using postgres connection "master"
11:18:29.931173 [debug] [MainThread]: On master: COMMIT
11:18:30.157733 [debug] [MainThread]: SQL status: COMMIT in 0.23 seconds
11:18:30.158498 [debug] [MainThread]: On master: Close
11:18:30.159567 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
11:18:30.160130 [info ] [MainThread]: 
11:18:30.164584 [debug] [Thread-1  ]: Began running node model.demo_dbt.my_first_dbt_model
11:18:30.165087 [info ] [Thread-1  ]: 1 of 5 START table model warehouse.my_first_dbt_model........................... [RUN]
11:18:30.165765 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_dbt.my_first_dbt_model"
11:18:30.166025 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.my_first_dbt_model
11:18:30.166283 [debug] [Thread-1  ]: Compiling model.demo_dbt.my_first_dbt_model
11:18:30.169893 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.my_first_dbt_model"
11:18:30.172883 [debug] [Thread-1  ]: finished collecting timing info
11:18:30.173271 [debug] [Thread-1  ]: Began executing node model.demo_dbt.my_first_dbt_model
11:18:30.202635 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.my_first_dbt_model"
11:18:30.203276 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_first_dbt_model"
11:18:30.203468 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: BEGIN
11:18:30.203615 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:18:32.026158 [debug] [Thread-1  ]: SQL status: BEGIN in 1.82 seconds
11:18:32.026588 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_first_dbt_model"
11:18:32.026872 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_first_dbt_model"} */


  create  table "brightacciondb"."warehouse"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
11:18:32.254596 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.23 seconds
11:18:32.264021 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_first_dbt_model"
11:18:32.264363 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_first_dbt_model"} */
alter table "brightacciondb"."warehouse"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
11:18:32.489421 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.22 seconds
11:18:32.494097 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_first_dbt_model"
11:18:32.494423 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_first_dbt_model"} */
alter table "brightacciondb"."warehouse"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
11:18:32.720360 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.23 seconds
11:18:32.735375 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: COMMIT
11:18:32.735709 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_first_dbt_model"
11:18:32.735894 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: COMMIT
11:18:32.960783 [debug] [Thread-1  ]: SQL status: COMMIT in 0.22 seconds
11:18:32.967638 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_first_dbt_model"
11:18:32.967963 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_first_dbt_model"} */
drop table if exists "brightacciondb"."warehouse"."my_first_dbt_model__dbt_backup" cascade
11:18:33.194541 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.23 seconds
11:18:33.197502 [debug] [Thread-1  ]: finished collecting timing info
11:18:33.197990 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: Close
11:18:33.198976 [info ] [Thread-1  ]: 1 of 5 OK created table model warehouse.my_first_dbt_model...................... [[32mSELECT 2[0m in 3.03s]
11:18:33.199581 [debug] [Thread-1  ]: Finished running node model.demo_dbt.my_first_dbt_model
11:18:33.199885 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__customers
11:18:33.200262 [info ] [Thread-1  ]: 2 of 5 START view model warehouse.stg_eltool__customers......................... [RUN]
11:18:33.200931 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_dbt.stg_eltool__customers"
11:18:33.201201 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__customers
11:18:33.201460 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__customers
11:18:33.204474 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__customers"
11:18:33.205049 [debug] [Thread-1  ]: finished collecting timing info
11:18:33.205254 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__customers
11:18:33.222070 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.stg_eltool__customers"
11:18:33.223209 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__customers"
11:18:33.223533 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: BEGIN
11:18:33.223775 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:18:34.992170 [debug] [Thread-1  ]: SQL status: BEGIN in 1.77 seconds
11:18:34.992932 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__customers"
11:18:34.993218 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__customers"} */

  create view "brightacciondb"."warehouse"."stg_eltool__customers__dbt_tmp" as (
    with source as (
    select *
    from "brightacciondb"."snapshots"."customers_snapshot"
), renamed as (
    select customer_id,
        zipcode,
        city,
        state_code,
        datetime_created::TIMESTAMP AS datetime_created,
        datetime_updated::TIMESTAMP AS datetime_updated,
        dbt_valid_from,
        dbt_valid_to
    from source
)
select *
from renamed
  );
11:18:35.233660 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.24 seconds
11:18:35.237775 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__customers"
11:18:35.238056 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__customers"} */
alter table "brightacciondb"."warehouse"."stg_eltool__customers" rename to "stg_eltool__customers__dbt_backup"
11:18:35.460341 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.22 seconds
11:18:35.463705 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__customers"
11:18:35.464029 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__customers"} */
alter table "brightacciondb"."warehouse"."stg_eltool__customers__dbt_tmp" rename to "stg_eltool__customers"
11:18:35.685177 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.22 seconds
11:18:35.688123 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: COMMIT
11:18:35.688499 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__customers"
11:18:35.688772 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: COMMIT
11:18:35.909271 [debug] [Thread-1  ]: SQL status: COMMIT in 0.22 seconds
11:18:35.911555 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__customers"
11:18:35.911829 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__customers"} */
drop view if exists "brightacciondb"."warehouse"."stg_eltool__customers__dbt_backup" cascade
11:18:36.134856 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.22 seconds
11:18:36.136928 [debug] [Thread-1  ]: finished collecting timing info
11:18:36.137315 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: Close
11:18:36.138147 [info ] [Thread-1  ]: 2 of 5 OK created view model warehouse.stg_eltool__customers.................... [[32mCREATE VIEW[0m in 2.94s]
11:18:36.138601 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__customers
11:18:36.138944 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__orders
11:18:36.139372 [info ] [Thread-1  ]: 3 of 5 START view model warehouse.stg_eltool__orders............................ [RUN]
11:18:36.140005 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_dbt.stg_eltool__orders"
11:18:36.140261 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__orders
11:18:36.140485 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__orders
11:18:36.143479 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__orders"
11:18:36.144176 [debug] [Thread-1  ]: finished collecting timing info
11:18:36.144606 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__orders
11:18:36.147191 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.stg_eltool__orders"
11:18:36.147798 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__orders"
11:18:36.148002 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: BEGIN
11:18:36.148171 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:18:37.955007 [debug] [Thread-1  ]: SQL status: BEGIN in 1.81 seconds
11:18:37.955632 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__orders"
11:18:37.955908 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__orders"} */

  create view "brightacciondb"."warehouse"."stg_eltool__orders__dbt_tmp" as (
    with source as (
    select *
    from "brightacciondb"."warehouse"."orders"
),
renamed as (
    select order_id,
        cust_id AS customer_id,
        order_status,
        order_purchase_timestamp::TIMESTAMP,
        order_approved_at::TIMESTAMP,
        order_delivered_carrier_date::TIMESTAMP,
        order_delivered_customer_date::TIMESTAMP,
        order_estimated_delivery_date::TIMESTAMP
        from source
)
select *
from renamed
  );
11:18:38.182261 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.23 seconds
11:18:38.187869 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__orders"
11:18:38.188193 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__orders"} */
alter table "brightacciondb"."warehouse"."stg_eltool__orders" rename to "stg_eltool__orders__dbt_backup"
11:18:38.415920 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.23 seconds
11:18:38.418593 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__orders"
11:18:38.418836 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__orders"} */
alter table "brightacciondb"."warehouse"."stg_eltool__orders__dbt_tmp" rename to "stg_eltool__orders"
11:18:38.652742 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.23 seconds
11:18:38.655870 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: COMMIT
11:18:38.656217 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__orders"
11:18:38.656465 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: COMMIT
11:18:38.882721 [debug] [Thread-1  ]: SQL status: COMMIT in 0.23 seconds
11:18:38.885341 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__orders"
11:18:38.885633 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__orders"} */
drop view if exists "brightacciondb"."warehouse"."stg_eltool__orders__dbt_backup" cascade
11:18:39.111150 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.23 seconds
11:18:39.113087 [debug] [Thread-1  ]: finished collecting timing info
11:18:39.113446 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: Close
11:18:39.114617 [info ] [Thread-1  ]: 3 of 5 OK created view model warehouse.stg_eltool__orders....................... [[32mCREATE VIEW[0m in 2.97s]
11:18:39.115584 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__orders
11:18:39.116120 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__state
11:18:39.116788 [info ] [Thread-1  ]: 4 of 5 START view model warehouse.stg_eltool__state............................. [RUN]
11:18:39.117559 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_dbt.stg_eltool__state"
11:18:39.117825 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__state
11:18:39.118065 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__state
11:18:39.121145 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__state"
11:18:39.121828 [debug] [Thread-1  ]: finished collecting timing info
11:18:39.122097 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__state
11:18:39.124603 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.stg_eltool__state"
11:18:39.125221 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__state"
11:18:39.125433 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: BEGIN
11:18:39.125606 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:18:40.924156 [debug] [Thread-1  ]: SQL status: BEGIN in 1.8 seconds
11:18:40.924646 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__state"
11:18:40.924866 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__state"} */

  create view "brightacciondb"."warehouse"."stg_eltool__state__dbt_tmp" as (
    with source as (
    select *
    from "brightacciondb"."warehouse"."state"
),
renamed as (
    select state_identifier::INT AS state_id,
        state_code::VARCHAR(2) AS state_code,
        st_name::VARCHAR(30) AS state_name
    from source
)
select *
from renamed
  );
11:18:41.151134 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.23 seconds
11:18:41.154089 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__state"
11:18:41.154347 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__state"} */
alter table "brightacciondb"."warehouse"."stg_eltool__state" rename to "stg_eltool__state__dbt_backup"
11:18:41.378651 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.22 seconds
11:18:41.381952 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__state"
11:18:41.382214 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__state"} */
alter table "brightacciondb"."warehouse"."stg_eltool__state__dbt_tmp" rename to "stg_eltool__state"
11:18:41.607327 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.22 seconds
11:18:41.608982 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: COMMIT
11:18:41.609228 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__state"
11:18:41.609423 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: COMMIT
11:18:41.833638 [debug] [Thread-1  ]: SQL status: COMMIT in 0.22 seconds
11:18:41.836586 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__state"
11:18:41.836899 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__state"} */
drop view if exists "brightacciondb"."warehouse"."stg_eltool__state__dbt_backup" cascade
11:18:42.062418 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.23 seconds
11:18:42.065245 [debug] [Thread-1  ]: finished collecting timing info
11:18:42.065647 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: Close
11:18:42.066461 [info ] [Thread-1  ]: 4 of 5 OK created view model warehouse.stg_eltool__state........................ [[32mCREATE VIEW[0m in 2.95s]
11:18:42.067087 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__state
11:18:42.067653 [debug] [Thread-1  ]: Began running node model.demo_dbt.my_second_dbt_model
11:18:42.068355 [info ] [Thread-1  ]: 5 of 5 START view model warehouse.my_second_dbt_model........................... [RUN]
11:18:42.069089 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_dbt.my_second_dbt_model"
11:18:42.069356 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.my_second_dbt_model
11:18:42.069597 [debug] [Thread-1  ]: Compiling model.demo_dbt.my_second_dbt_model
11:18:42.072708 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.my_second_dbt_model"
11:18:42.073368 [debug] [Thread-1  ]: finished collecting timing info
11:18:42.073818 [debug] [Thread-1  ]: Began executing node model.demo_dbt.my_second_dbt_model
11:18:42.076300 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.my_second_dbt_model"
11:18:42.076862 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_second_dbt_model"
11:18:42.077053 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: BEGIN
11:18:42.077218 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:18:43.878841 [debug] [Thread-1  ]: SQL status: BEGIN in 1.8 seconds
11:18:43.879265 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_second_dbt_model"
11:18:43.879483 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_second_dbt_model"} */

  create view "brightacciondb"."warehouse"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "brightacciondb"."warehouse"."my_first_dbt_model"
where id = 1
  );
11:18:44.105263 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.23 seconds
11:18:44.108618 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_second_dbt_model"
11:18:44.108902 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_second_dbt_model"} */
alter table "brightacciondb"."warehouse"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
11:18:44.334269 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.23 seconds
11:18:44.336659 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: COMMIT
11:18:44.337033 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_second_dbt_model"
11:18:44.337352 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: COMMIT
11:18:44.562987 [debug] [Thread-1  ]: SQL status: COMMIT in 0.23 seconds
11:18:44.565693 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_second_dbt_model"
11:18:44.565996 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_second_dbt_model"} */
drop view if exists "brightacciondb"."warehouse"."my_second_dbt_model__dbt_backup" cascade
11:18:44.791063 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.22 seconds
11:18:44.793325 [debug] [Thread-1  ]: finished collecting timing info
11:18:44.793649 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: Close
11:18:44.794530 [info ] [Thread-1  ]: 5 of 5 OK created view model warehouse.my_second_dbt_model...................... [[32mCREATE VIEW[0m in 2.73s]
11:18:44.795104 [debug] [Thread-1  ]: Finished running node model.demo_dbt.my_second_dbt_model
11:18:44.796514 [debug] [MainThread]: Acquiring new postgres connection "master"
11:18:44.796845 [debug] [MainThread]: Using postgres connection "master"
11:18:44.797089 [debug] [MainThread]: On master: BEGIN
11:18:44.797292 [debug] [MainThread]: Opening a new connection, currently in state closed
11:18:46.583220 [debug] [MainThread]: SQL status: BEGIN in 1.79 seconds
11:18:46.584088 [debug] [MainThread]: On master: COMMIT
11:18:46.586294 [debug] [MainThread]: Using postgres connection "master"
11:18:46.586763 [debug] [MainThread]: On master: COMMIT
11:18:46.807348 [debug] [MainThread]: SQL status: COMMIT in 0.22 seconds
11:18:46.808191 [debug] [MainThread]: On master: Close
11:18:46.809163 [info ] [MainThread]: 
11:18:46.809592 [info ] [MainThread]: Finished running 1 table model, 4 view models in 26.02s.
11:18:46.810041 [debug] [MainThread]: Connection 'master' was properly closed.
11:18:46.810496 [debug] [MainThread]: Connection 'model.demo_dbt.my_second_dbt_model' was properly closed.
11:18:46.817274 [info ] [MainThread]: 
11:18:46.817665 [info ] [MainThread]: [32mCompleted successfully[0m
11:18:46.818083 [info ] [MainThread]: 
11:18:46.818454 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5


============================== 2022-06-29 11:32:03.955315 | f5a17601-ff56-4583-811d-ab99b5a7deeb ==============================
11:32:03.955315 [info ] [MainThread]: Running with dbt=1.0.4
11:32:03.956248 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.snapshot.SnapshotTask'>, which='snapshot', rpc_method='snapshot')
11:32:03.956844 [debug] [MainThread]: Tracking: do not track
11:32:03.991552 [info ] [MainThread]: Unable to do partial parsing because profile has changed
11:32:04.035116 [debug] [MainThread]: Parsing macros/catalog.sql
11:32:04.040201 [debug] [MainThread]: Parsing macros/relations.sql
11:32:04.042250 [debug] [MainThread]: Parsing macros/adapters.sql
11:32:04.069416 [debug] [MainThread]: Parsing macros/materializations/snapshot_merge.sql
11:32:04.071220 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
11:32:04.076376 [debug] [MainThread]: Parsing macros/materializations/configs.sql
11:32:04.081145 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
11:32:04.084683 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
11:32:04.110051 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
11:32:04.125785 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
11:32:04.141470 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
11:32:04.146205 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
11:32:04.148050 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
11:32:04.149899 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
11:32:04.154377 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
11:32:04.166540 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
11:32:04.168101 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
11:32:04.178369 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
11:32:04.194744 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
11:32:04.202902 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
11:32:04.205798 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
11:32:04.213020 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
11:32:04.214335 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
11:32:04.216969 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
11:32:04.219231 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
11:32:04.225546 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
11:32:04.242563 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
11:32:04.244184 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
11:32:04.246663 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
11:32:04.248236 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
11:32:04.249521 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
11:32:04.250576 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
11:32:04.251569 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
11:32:04.253343 [debug] [MainThread]: Parsing macros/etc/statement.sql
11:32:04.259651 [debug] [MainThread]: Parsing macros/etc/datetime.sql
11:32:04.269022 [debug] [MainThread]: Parsing macros/adapters/schema.sql
11:32:04.271258 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
11:32:04.274012 [debug] [MainThread]: Parsing macros/adapters/relation.sql
11:32:04.283607 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
11:32:04.286748 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
11:32:04.291493 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
11:32:04.299347 [debug] [MainThread]: Parsing macros/adapters/columns.sql
11:32:04.309897 [debug] [MainThread]: Parsing tests/generic/builtin.sql
11:32:04.523448 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
11:32:04.535296 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
11:32:04.537565 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
11:32:04.539994 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
11:32:04.542280 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
11:32:04.683294 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 165 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
11:32:04.685016 [info ] [MainThread]: 
11:32:04.685554 [debug] [MainThread]: Acquiring new postgres connection "master"
11:32:04.686245 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb"
11:32:04.695877 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb"
11:32:04.696123 [debug] [ThreadPool]: On list_brightacciondb: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_brightacciondb"} */

    select distinct nspname from pg_namespace
  
11:32:04.696289 [debug] [ThreadPool]: Opening a new connection, currently in state init
11:32:06.597676 [debug] [ThreadPool]: SQL status: SELECT 10 in 1.9 seconds
11:32:06.600153 [debug] [ThreadPool]: On list_brightacciondb: Close
11:32:06.601961 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb_warehouse"
11:32:06.608732 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_warehouse"
11:32:06.609002 [debug] [ThreadPool]: On list_brightacciondb_warehouse: BEGIN
11:32:06.609184 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:32:08.415613 [debug] [ThreadPool]: SQL status: BEGIN in 1.81 seconds
11:32:08.416084 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_warehouse"
11:32:08.416437 [debug] [ThreadPool]: On list_brightacciondb_warehouse: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_brightacciondb_warehouse"} */
select
      'brightacciondb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'brightacciondb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
11:32:08.646243 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.23 seconds
11:32:08.648229 [debug] [ThreadPool]: On list_brightacciondb_warehouse: ROLLBACK
11:32:08.872810 [debug] [ThreadPool]: On list_brightacciondb_warehouse: Close
11:32:08.874063 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb_snapshots"
11:32:08.876783 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_snapshots"
11:32:08.877066 [debug] [ThreadPool]: On list_brightacciondb_snapshots: BEGIN
11:32:08.877274 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:32:10.702822 [debug] [ThreadPool]: SQL status: BEGIN in 1.83 seconds
11:32:10.703431 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_snapshots"
11:32:10.703680 [debug] [ThreadPool]: On list_brightacciondb_snapshots: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_brightacciondb_snapshots"} */
select
      'brightacciondb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'brightacciondb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
  
11:32:10.931441 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.23 seconds
11:32:10.933875 [debug] [ThreadPool]: On list_brightacciondb_snapshots: ROLLBACK
11:32:11.159846 [debug] [ThreadPool]: On list_brightacciondb_snapshots: Close
11:32:11.166030 [debug] [MainThread]: Using postgres connection "master"
11:32:11.166404 [debug] [MainThread]: On master: BEGIN
11:32:11.166635 [debug] [MainThread]: Opening a new connection, currently in state init
11:32:12.965769 [debug] [MainThread]: SQL status: BEGIN in 1.8 seconds
11:32:12.966236 [debug] [MainThread]: Using postgres connection "master"
11:32:12.966594 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
11:32:13.209260 [debug] [MainThread]: SQL status: SELECT 4 in 0.24 seconds
11:32:13.211737 [debug] [MainThread]: On master: ROLLBACK
11:32:13.436512 [debug] [MainThread]: Using postgres connection "master"
11:32:13.437307 [debug] [MainThread]: On master: BEGIN
11:32:13.885476 [debug] [MainThread]: SQL status: BEGIN in 0.45 seconds
11:32:13.886003 [debug] [MainThread]: On master: COMMIT
11:32:13.886374 [debug] [MainThread]: Using postgres connection "master"
11:32:13.886635 [debug] [MainThread]: On master: COMMIT
11:32:14.110355 [debug] [MainThread]: SQL status: COMMIT in 0.22 seconds
11:32:14.110911 [debug] [MainThread]: On master: Close
11:32:14.111876 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
11:32:14.112395 [info ] [MainThread]: 
11:32:14.120723 [debug] [Thread-1  ]: Began running node snapshot.demo_dbt.customers_snapshot
11:32:14.121198 [info ] [Thread-1  ]: 1 of 1 START snapshot snapshots.customers_snapshot.............................. [RUN]
11:32:14.121837 [debug] [Thread-1  ]: Acquiring new postgres connection "snapshot.demo_dbt.customers_snapshot"
11:32:14.122083 [debug] [Thread-1  ]: Began compiling node snapshot.demo_dbt.customers_snapshot
11:32:14.122321 [debug] [Thread-1  ]: Compiling snapshot.demo_dbt.customers_snapshot
11:32:14.125544 [debug] [Thread-1  ]: finished collecting timing info
11:32:14.125811 [debug] [Thread-1  ]: Began executing node snapshot.demo_dbt.customers_snapshot
11:32:14.152390 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
11:32:14.152684 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

    select count(*) from pg_namespace where nspname = 'snapshots'
  
11:32:14.152860 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:32:15.952902 [debug] [Thread-1  ]: SQL status: SELECT 1 in 1.8 seconds
11:32:15.985804 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
11:32:15.986070 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: BEGIN
11:32:16.205556 [debug] [Thread-1  ]: SQL status: BEGIN in 0.22 seconds
11:32:16.206036 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
11:32:16.206424 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "brightacciondb".INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot'
        
        and table_schema = 'snapshots'
        
      order by ordinal_position

  
11:32:16.431594 [debug] [Thread-1  ]: SQL status: SELECT 10 in 0.22 seconds
11:32:16.459866 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
11:32:16.460163 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

        

  create temporary table "customers_snapshot__dbt_tmp170216449652"
  as (
    with snapshot_query as (

        



select * from "brightacciondb"."warehouse"."customers"


    ),

    snapshotted_data as (

        select *,
            customer_id as dbt_unique_key

        from "brightacciondb"."snapshots"."customers_snapshot"
        where dbt_valid_to is null

    ),

    insertions_source_data as (

        select
            *,
            customer_id as dbt_unique_key,
            datetime_updated as dbt_updated_at,
            datetime_updated as dbt_valid_from,
            nullif(datetime_updated, datetime_updated) as dbt_valid_to,
            md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(datetime_updated as varchar ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select
            *,
            customer_id as dbt_unique_key,
            datetime_updated as dbt_updated_at,
            datetime_updated as dbt_valid_from,
            datetime_updated as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where snapshotted_data.dbt_unique_key is null
           or (
                snapshotted_data.dbt_unique_key is not null
            and (
                (snapshotted_data.dbt_valid_from < source_data.datetime_updated)
            )
        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where (
            (snapshotted_data.dbt_valid_from < source_data.datetime_updated)
        )
    )

    select * from insertions
    union all
    select * from updates

  );
    
11:32:16.686281 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.23 seconds
11:32:16.690416 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
11:32:16.690704 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot__dbt_tmp170216449652'
        
      order by ordinal_position

  
11:32:16.915100 [debug] [Thread-1  ]: SQL status: SELECT 12 in 0.22 seconds
11:32:16.920008 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
11:32:16.920319 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "brightacciondb".INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot'
        
        and table_schema = 'snapshots'
        
      order by ordinal_position

  
11:32:17.146376 [debug] [Thread-1  ]: SQL status: SELECT 10 in 0.23 seconds
11:32:17.150834 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
11:32:17.151203 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot__dbt_tmp170216449652'
        
      order by ordinal_position

  
11:32:17.374726 [debug] [Thread-1  ]: SQL status: SELECT 12 in 0.22 seconds
11:32:17.379909 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
11:32:17.380283 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "brightacciondb".INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot'
        
        and table_schema = 'snapshots'
        
      order by ordinal_position

  
11:32:17.601505 [debug] [Thread-1  ]: SQL status: SELECT 10 in 0.22 seconds
11:32:17.612175 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
11:32:17.612459 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot__dbt_tmp170216449652'
        
      order by ordinal_position

  
11:32:17.836461 [debug] [Thread-1  ]: SQL status: SELECT 12 in 0.22 seconds
11:32:17.846981 [debug] [Thread-1  ]: Writing runtime SQL for node "snapshot.demo_dbt.customers_snapshot"
11:32:17.847718 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
11:32:17.847937 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

      update "brightacciondb"."snapshots"."customers_snapshot"
    set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to
    from "customers_snapshot__dbt_tmp170216449652" as DBT_INTERNAL_SOURCE
    where DBT_INTERNAL_SOURCE.dbt_scd_id::text = "brightacciondb"."snapshots"."customers_snapshot".dbt_scd_id::text
      and DBT_INTERNAL_SOURCE.dbt_change_type::text in ('update'::text, 'delete'::text)
      and "brightacciondb"."snapshots"."customers_snapshot".dbt_valid_to is null;

    insert into "brightacciondb"."snapshots"."customers_snapshot" ("customer_id", "zipcode", "city", "state_code", "datetime_created", "datetime_updated", "dbt_updated_at", "dbt_valid_from", "dbt_valid_to", "dbt_scd_id")
    select DBT_INTERNAL_SOURCE."customer_id",DBT_INTERNAL_SOURCE."zipcode",DBT_INTERNAL_SOURCE."city",DBT_INTERNAL_SOURCE."state_code",DBT_INTERNAL_SOURCE."datetime_created",DBT_INTERNAL_SOURCE."datetime_updated",DBT_INTERNAL_SOURCE."dbt_updated_at",DBT_INTERNAL_SOURCE."dbt_valid_from",DBT_INTERNAL_SOURCE."dbt_valid_to",DBT_INTERNAL_SOURCE."dbt_scd_id"
    from "customers_snapshot__dbt_tmp170216449652" as DBT_INTERNAL_SOURCE
    where DBT_INTERNAL_SOURCE.dbt_change_type::text = 'insert'::text;

  
11:32:18.068640 [debug] [Thread-1  ]: SQL status: INSERT 0 0 in 0.22 seconds
11:32:18.078217 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: COMMIT
11:32:18.078512 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt.customers_snapshot"
11:32:18.078774 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: COMMIT
11:32:18.298649 [debug] [Thread-1  ]: SQL status: COMMIT in 0.22 seconds
11:32:18.303453 [debug] [Thread-1  ]: finished collecting timing info
11:32:18.303799 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: Close
11:32:18.304710 [info ] [Thread-1  ]: 1 of 1 OK snapshotted snapshots.customers_snapshot.............................. [[32mINSERT 0 0[0m in 4.18s]
11:32:18.305331 [debug] [Thread-1  ]: Finished running node snapshot.demo_dbt.customers_snapshot
11:32:18.307872 [debug] [MainThread]: Acquiring new postgres connection "master"
11:32:18.308240 [debug] [MainThread]: Using postgres connection "master"
11:32:18.308466 [debug] [MainThread]: On master: BEGIN
11:32:18.308665 [debug] [MainThread]: Opening a new connection, currently in state closed
11:32:20.121432 [debug] [MainThread]: SQL status: BEGIN in 1.81 seconds
11:32:20.122066 [debug] [MainThread]: On master: COMMIT
11:32:20.122372 [debug] [MainThread]: Using postgres connection "master"
11:32:20.122628 [debug] [MainThread]: On master: COMMIT
11:32:20.347125 [debug] [MainThread]: SQL status: COMMIT in 0.22 seconds
11:32:20.347658 [debug] [MainThread]: On master: Close
11:32:20.348560 [info ] [MainThread]: 
11:32:20.349086 [info ] [MainThread]: Finished running 1 snapshot in 15.66s.
11:32:20.349702 [debug] [MainThread]: Connection 'master' was properly closed.
11:32:20.350050 [debug] [MainThread]: Connection 'snapshot.demo_dbt.customers_snapshot' was properly closed.
11:32:20.358094 [info ] [MainThread]: 
11:32:20.358479 [info ] [MainThread]: [32mCompleted successfully[0m
11:32:20.358975 [info ] [MainThread]: 
11:32:20.359304 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1


============================== 2022-06-29 11:32:30.927526 | 86cf14c3-2d69-485c-a222-4a7d4118e746 ==============================
11:32:30.927526 [info ] [MainThread]: Running with dbt=1.0.4
11:32:30.928157 [debug] [MainThread]: running dbt with arguments Namespace(record_timing_info=None, debug=None, log_format=None, write_json=None, use_colors=None, printer_width=None, warn_error=None, version_check=None, partial_parse=None, single_threaded=False, use_experimental_parser=None, static_parser=None, profiles_dir='/Users/amit/.dbt', send_anonymous_usage_stats=None, fail_fast=None, event_buffer_size=None, project_dir=None, profile=None, target=None, vars='{}', log_cache_events=False, threads=None, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
11:32:30.928423 [debug] [MainThread]: Tracking: do not track
11:32:30.980058 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
11:32:30.980392 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
11:32:30.993270 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 165 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
11:32:30.995173 [info ] [MainThread]: 
11:32:30.995769 [debug] [MainThread]: Acquiring new postgres connection "master"
11:32:30.996820 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb"
11:32:31.006934 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb"
11:32:31.007210 [debug] [ThreadPool]: On list_brightacciondb: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_brightacciondb"} */

    select distinct nspname from pg_namespace
  
11:32:31.007379 [debug] [ThreadPool]: Opening a new connection, currently in state init
11:32:32.830845 [debug] [ThreadPool]: SQL status: SELECT 10 in 1.82 seconds
11:32:32.833529 [debug] [ThreadPool]: On list_brightacciondb: Close
11:32:32.835986 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb_snapshots"
11:32:32.843262 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_snapshots"
11:32:32.843544 [debug] [ThreadPool]: On list_brightacciondb_snapshots: BEGIN
11:32:32.843726 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:32:34.642438 [debug] [ThreadPool]: SQL status: BEGIN in 1.8 seconds
11:32:34.642859 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_snapshots"
11:32:34.643183 [debug] [ThreadPool]: On list_brightacciondb_snapshots: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_brightacciondb_snapshots"} */
select
      'brightacciondb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'brightacciondb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
  
11:32:34.870652 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.23 seconds
11:32:34.873266 [debug] [ThreadPool]: On list_brightacciondb_snapshots: ROLLBACK
11:32:35.097007 [debug] [ThreadPool]: On list_brightacciondb_snapshots: Close
11:32:35.097987 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb_warehouse"
11:32:35.099811 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_warehouse"
11:32:35.100052 [debug] [ThreadPool]: On list_brightacciondb_warehouse: BEGIN
11:32:35.100225 [debug] [ThreadPool]: Opening a new connection, currently in state closed
11:32:36.912318 [debug] [ThreadPool]: SQL status: BEGIN in 1.81 seconds
11:32:36.912632 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_warehouse"
11:32:36.912873 [debug] [ThreadPool]: On list_brightacciondb_warehouse: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_brightacciondb_warehouse"} */
select
      'brightacciondb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'brightacciondb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
11:32:37.142167 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.23 seconds
11:32:37.144609 [debug] [ThreadPool]: On list_brightacciondb_warehouse: ROLLBACK
11:32:37.369526 [debug] [ThreadPool]: On list_brightacciondb_warehouse: Close
11:32:37.376209 [debug] [MainThread]: Using postgres connection "master"
11:32:37.376546 [debug] [MainThread]: On master: BEGIN
11:32:37.376765 [debug] [MainThread]: Opening a new connection, currently in state init
11:32:39.263116 [debug] [MainThread]: SQL status: BEGIN in 1.89 seconds
11:32:39.263534 [debug] [MainThread]: Using postgres connection "master"
11:32:39.263804 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
11:32:39.508916 [debug] [MainThread]: SQL status: SELECT 4 in 0.24 seconds
11:32:39.511240 [debug] [MainThread]: On master: ROLLBACK
11:32:39.735635 [debug] [MainThread]: Using postgres connection "master"
11:32:39.736098 [debug] [MainThread]: On master: BEGIN
11:32:40.184642 [debug] [MainThread]: SQL status: BEGIN in 0.45 seconds
11:32:40.185034 [debug] [MainThread]: On master: COMMIT
11:32:40.185242 [debug] [MainThread]: Using postgres connection "master"
11:32:40.185411 [debug] [MainThread]: On master: COMMIT
11:32:40.409867 [debug] [MainThread]: SQL status: COMMIT in 0.22 seconds
11:32:40.410464 [debug] [MainThread]: On master: Close
11:32:40.411480 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
11:32:40.411985 [info ] [MainThread]: 
11:32:40.416301 [debug] [Thread-1  ]: Began running node model.demo_dbt.my_first_dbt_model
11:32:40.416755 [info ] [Thread-1  ]: 1 of 5 START table model warehouse.my_first_dbt_model........................... [RUN]
11:32:40.417483 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_dbt.my_first_dbt_model"
11:32:40.417760 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.my_first_dbt_model
11:32:40.418035 [debug] [Thread-1  ]: Compiling model.demo_dbt.my_first_dbt_model
11:32:40.421971 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.my_first_dbt_model"
11:32:40.422592 [debug] [Thread-1  ]: finished collecting timing info
11:32:40.422809 [debug] [Thread-1  ]: Began executing node model.demo_dbt.my_first_dbt_model
11:32:40.450031 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.my_first_dbt_model"
11:32:40.450627 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_first_dbt_model"
11:32:40.450814 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: BEGIN
11:32:40.450960 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:32:42.216370 [debug] [Thread-1  ]: SQL status: BEGIN in 1.77 seconds
11:32:42.216710 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_first_dbt_model"
11:32:42.216924 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_first_dbt_model"} */


  create  table "brightacciondb"."warehouse"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
11:32:42.438708 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.22 seconds
11:32:42.450826 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_first_dbt_model"
11:32:42.451292 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_first_dbt_model"} */
alter table "brightacciondb"."warehouse"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
11:32:42.671850 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.22 seconds
11:32:42.675594 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_first_dbt_model"
11:32:42.675942 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_first_dbt_model"} */
alter table "brightacciondb"."warehouse"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
11:32:42.895852 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.22 seconds
11:32:42.911823 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: COMMIT
11:32:42.912179 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_first_dbt_model"
11:32:42.912392 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: COMMIT
11:32:43.131727 [debug] [Thread-1  ]: SQL status: COMMIT in 0.22 seconds
11:32:43.138667 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_first_dbt_model"
11:32:43.138998 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_first_dbt_model"} */
drop table if exists "brightacciondb"."warehouse"."my_first_dbt_model__dbt_backup" cascade
11:32:43.360185 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.22 seconds
11:32:43.362672 [debug] [Thread-1  ]: finished collecting timing info
11:32:43.363092 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: Close
11:32:43.364201 [info ] [Thread-1  ]: 1 of 5 OK created table model warehouse.my_first_dbt_model...................... [[32mSELECT 2[0m in 2.95s]
11:32:43.364689 [debug] [Thread-1  ]: Finished running node model.demo_dbt.my_first_dbt_model
11:32:43.365075 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__customers
11:32:43.365651 [info ] [Thread-1  ]: 2 of 5 START view model warehouse.stg_eltool__customers......................... [RUN]
11:32:43.366296 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_dbt.stg_eltool__customers"
11:32:43.366551 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__customers
11:32:43.366775 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__customers
11:32:43.369713 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__customers"
11:32:43.370432 [debug] [Thread-1  ]: finished collecting timing info
11:32:43.370646 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__customers
11:32:43.388640 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.stg_eltool__customers"
11:32:43.389268 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__customers"
11:32:43.389473 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: BEGIN
11:32:43.389623 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:32:45.182572 [debug] [Thread-1  ]: SQL status: BEGIN in 1.79 seconds
11:32:45.183198 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__customers"
11:32:45.183506 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__customers"} */

  create view "brightacciondb"."warehouse"."stg_eltool__customers__dbt_tmp" as (
    with source as (
    select *
    from "brightacciondb"."snapshots"."customers_snapshot"
), renamed as (
    select customer_id,
        zipcode,
        city,
        state_code,
        datetime_created::TIMESTAMP AS datetime_created,
        datetime_updated::TIMESTAMP AS datetime_updated,
        dbt_valid_from,
        dbt_valid_to
    from source
)
select *
from renamed
  );
11:32:45.418606 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.23 seconds
11:32:45.421926 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__customers"
11:32:45.422350 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__customers"} */
alter table "brightacciondb"."warehouse"."stg_eltool__customers" rename to "stg_eltool__customers__dbt_backup"
11:32:45.647003 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.22 seconds
11:32:45.650840 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__customers"
11:32:45.651166 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__customers"} */
alter table "brightacciondb"."warehouse"."stg_eltool__customers__dbt_tmp" rename to "stg_eltool__customers"
11:32:45.875331 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.22 seconds
11:32:45.877952 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: COMMIT
11:32:45.878312 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__customers"
11:32:45.878523 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: COMMIT
11:32:46.101923 [debug] [Thread-1  ]: SQL status: COMMIT in 0.22 seconds
11:32:46.104601 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__customers"
11:32:46.104932 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__customers"} */
drop view if exists "brightacciondb"."warehouse"."stg_eltool__customers__dbt_backup" cascade
11:32:46.330153 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.22 seconds
11:32:46.332990 [debug] [Thread-1  ]: finished collecting timing info
11:32:46.333362 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: Close
11:32:46.334168 [info ] [Thread-1  ]: 2 of 5 OK created view model warehouse.stg_eltool__customers.................... [[32mCREATE VIEW[0m in 2.97s]
11:32:46.334730 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__customers
11:32:46.335049 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__orders
11:32:46.335492 [info ] [Thread-1  ]: 3 of 5 START view model warehouse.stg_eltool__orders............................ [RUN]
11:32:46.336129 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_dbt.stg_eltool__orders"
11:32:46.336386 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__orders
11:32:46.336613 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__orders
11:32:46.339662 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__orders"
11:32:46.342563 [debug] [Thread-1  ]: finished collecting timing info
11:32:46.342939 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__orders
11:32:46.345736 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.stg_eltool__orders"
11:32:46.346275 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__orders"
11:32:46.346466 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: BEGIN
11:32:46.346633 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:32:48.178035 [debug] [Thread-1  ]: SQL status: BEGIN in 1.83 seconds
11:32:48.178483 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__orders"
11:32:48.178752 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__orders"} */

  create view "brightacciondb"."warehouse"."stg_eltool__orders__dbt_tmp" as (
    with source as (
    select *
    from "brightacciondb"."warehouse"."orders"
),
renamed as (
    select order_id,
        cust_id AS customer_id,
        order_status,
        order_purchase_timestamp::TIMESTAMP,
        order_approved_at::TIMESTAMP,
        order_delivered_carrier_date::TIMESTAMP,
        order_delivered_customer_date::TIMESTAMP,
        order_estimated_delivery_date::TIMESTAMP
        from source
)
select *
from renamed
  );
11:32:48.889093 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.71 seconds
11:32:48.894214 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__orders"
11:32:48.894532 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__orders"} */
alter table "brightacciondb"."warehouse"."stg_eltool__orders" rename to "stg_eltool__orders__dbt_backup"
11:32:49.174755 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.28 seconds
11:32:49.178173 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__orders"
11:32:49.178464 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__orders"} */
alter table "brightacciondb"."warehouse"."stg_eltool__orders__dbt_tmp" rename to "stg_eltool__orders"
11:32:49.473412 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.29 seconds
11:32:49.475921 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: COMMIT
11:32:49.476230 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__orders"
11:32:49.476445 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: COMMIT
11:32:49.787650 [debug] [Thread-1  ]: SQL status: COMMIT in 0.31 seconds
11:32:49.790259 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__orders"
11:32:49.790553 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__orders"} */
drop view if exists "brightacciondb"."warehouse"."stg_eltool__orders__dbt_backup" cascade
11:32:50.016359 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.23 seconds
11:32:50.018524 [debug] [Thread-1  ]: finished collecting timing info
11:32:50.018874 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: Close
11:32:50.020209 [info ] [Thread-1  ]: 3 of 5 OK created view model warehouse.stg_eltool__orders....................... [[32mCREATE VIEW[0m in 3.68s]
11:32:50.021130 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__orders
11:32:50.021474 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__state
11:32:50.021998 [info ] [Thread-1  ]: 4 of 5 START view model warehouse.stg_eltool__state............................. [RUN]
11:32:50.022720 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_dbt.stg_eltool__state"
11:32:50.023002 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__state
11:32:50.023232 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__state
11:32:50.026274 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__state"
11:32:50.027078 [debug] [Thread-1  ]: finished collecting timing info
11:32:50.027350 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__state
11:32:50.029873 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.stg_eltool__state"
11:32:50.030423 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__state"
11:32:50.030626 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: BEGIN
11:32:50.030793 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:32:51.830442 [debug] [Thread-1  ]: SQL status: BEGIN in 1.8 seconds
11:32:51.831108 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__state"
11:32:51.831430 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__state"} */

  create view "brightacciondb"."warehouse"."stg_eltool__state__dbt_tmp" as (
    with source as (
    select *
    from "brightacciondb"."warehouse"."state"
),
renamed as (
    select state_identifier::INT AS state_id,
        state_code::VARCHAR(2) AS state_code,
        st_name::VARCHAR(30) AS state_name
    from source
)
select *
from renamed
  );
11:32:52.063171 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.23 seconds
11:32:52.067172 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__state"
11:32:52.067461 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__state"} */
alter table "brightacciondb"."warehouse"."stg_eltool__state" rename to "stg_eltool__state__dbt_backup"
11:32:52.291497 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.22 seconds
11:32:52.294937 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__state"
11:32:52.295218 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__state"} */
alter table "brightacciondb"."warehouse"."stg_eltool__state__dbt_tmp" rename to "stg_eltool__state"
11:32:52.519879 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.22 seconds
11:32:52.522766 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: COMMIT
11:32:52.523105 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__state"
11:32:52.523318 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: COMMIT
11:32:52.747995 [debug] [Thread-1  ]: SQL status: COMMIT in 0.22 seconds
11:32:52.750671 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.stg_eltool__state"
11:32:52.750971 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__state"} */
drop view if exists "brightacciondb"."warehouse"."stg_eltool__state__dbt_backup" cascade
11:32:52.975542 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.22 seconds
11:32:52.978950 [debug] [Thread-1  ]: finished collecting timing info
11:32:52.979339 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: Close
11:32:52.980327 [info ] [Thread-1  ]: 4 of 5 OK created view model warehouse.stg_eltool__state........................ [[32mCREATE VIEW[0m in 2.96s]
11:32:52.980911 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__state
11:32:52.981262 [debug] [Thread-1  ]: Began running node model.demo_dbt.my_second_dbt_model
11:32:52.981693 [info ] [Thread-1  ]: 5 of 5 START view model warehouse.my_second_dbt_model........................... [RUN]
11:32:52.982303 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_dbt.my_second_dbt_model"
11:32:52.982538 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.my_second_dbt_model
11:32:52.982758 [debug] [Thread-1  ]: Compiling model.demo_dbt.my_second_dbt_model
11:32:52.985530 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.my_second_dbt_model"
11:32:52.986117 [debug] [Thread-1  ]: finished collecting timing info
11:32:52.986446 [debug] [Thread-1  ]: Began executing node model.demo_dbt.my_second_dbt_model
11:32:52.989218 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.my_second_dbt_model"
11:32:52.989831 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_second_dbt_model"
11:32:52.990041 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: BEGIN
11:32:52.990206 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
11:32:54.796361 [debug] [Thread-1  ]: SQL status: BEGIN in 1.81 seconds
11:32:54.796788 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_second_dbt_model"
11:32:54.797067 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_second_dbt_model"} */

  create view "brightacciondb"."warehouse"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "brightacciondb"."warehouse"."my_first_dbt_model"
where id = 1
  );
11:32:55.022757 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.23 seconds
11:32:55.026990 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_second_dbt_model"
11:32:55.027328 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_second_dbt_model"} */
alter table "brightacciondb"."warehouse"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
11:32:55.252076 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.22 seconds
11:32:55.254543 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: COMMIT
11:32:55.254925 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_second_dbt_model"
11:32:55.255193 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: COMMIT
11:32:55.480482 [debug] [Thread-1  ]: SQL status: COMMIT in 0.22 seconds
11:32:55.483566 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt.my_second_dbt_model"
11:32:55.483976 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.0.4", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_second_dbt_model"} */
drop view if exists "brightacciondb"."warehouse"."my_second_dbt_model__dbt_backup" cascade
11:32:55.708751 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.22 seconds
11:32:55.711049 [debug] [Thread-1  ]: finished collecting timing info
11:32:55.711924 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: Close
11:32:55.713601 [info ] [Thread-1  ]: 5 of 5 OK created view model warehouse.my_second_dbt_model...................... [[32mCREATE VIEW[0m in 2.73s]
11:32:55.714159 [debug] [Thread-1  ]: Finished running node model.demo_dbt.my_second_dbt_model
11:32:55.715587 [debug] [MainThread]: Acquiring new postgres connection "master"
11:32:55.715920 [debug] [MainThread]: Using postgres connection "master"
11:32:55.716150 [debug] [MainThread]: On master: BEGIN
11:32:55.716401 [debug] [MainThread]: Opening a new connection, currently in state closed
11:32:57.490745 [debug] [MainThread]: SQL status: BEGIN in 1.77 seconds
11:32:57.491553 [debug] [MainThread]: On master: COMMIT
11:32:57.491937 [debug] [MainThread]: Using postgres connection "master"
11:32:57.492348 [debug] [MainThread]: On master: COMMIT
11:32:57.711832 [debug] [MainThread]: SQL status: COMMIT in 0.22 seconds
11:32:57.712371 [debug] [MainThread]: On master: Close
11:32:57.713264 [info ] [MainThread]: 
11:32:57.713766 [info ] [MainThread]: Finished running 1 table model, 4 view models in 26.72s.
11:32:57.714332 [debug] [MainThread]: Connection 'master' was properly closed.
11:32:57.714664 [debug] [MainThread]: Connection 'model.demo_dbt.my_second_dbt_model' was properly closed.
11:32:57.721523 [info ] [MainThread]: 
11:32:57.721955 [info ] [MainThread]: [32mCompleted successfully[0m
11:32:57.722349 [info ] [MainThread]: 
11:32:57.722765 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5


============================== 2022-06-29 11:52:19.847994 | 312bbc68-4a15-4475-b5b1-c243a2e7add0 ==============================
11:52:19.848010 [info ] [MainThread]: Running with dbt=1.1.1
11:52:19.947949 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
11:52:19.948644 [debug] [MainThread]: Tracking: do not track
11:52:20.004327 [info ] [MainThread]: Unable to do partial parsing because of a dbt version mismatch. Saved manifest version: 1.0.4. Current version: 1.1.1.
11:52:20.069100 [debug] [MainThread]: Parsing macros/catalog.sql
11:52:20.072525 [debug] [MainThread]: Parsing macros/adapters.sql
11:52:20.125080 [debug] [MainThread]: Parsing macros/materializations/merge.sql
11:52:20.130412 [debug] [MainThread]: Parsing macros/materializations/seed.sql
11:52:20.136887 [debug] [MainThread]: Parsing macros/materializations/view.sql
11:52:20.138737 [debug] [MainThread]: Parsing macros/materializations/table.sql
11:52:20.146677 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
11:52:20.160263 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
11:52:20.161661 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
11:52:20.166664 [debug] [MainThread]: Parsing macros/materializations/configs.sql
11:52:20.169579 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
11:52:20.171612 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
11:52:20.192316 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
11:52:20.208726 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
11:52:20.222425 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
11:52:20.230602 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
11:52:20.233114 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
11:52:20.235260 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
11:52:20.240947 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
11:52:20.261765 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
11:52:20.263657 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
11:52:20.276193 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
11:52:20.294701 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
11:52:20.304481 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
11:52:20.308027 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
11:52:20.316808 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
11:52:20.318532 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
11:52:20.321798 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
11:52:20.324601 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
11:52:20.332647 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
11:52:20.352401 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
11:52:20.354595 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
11:52:20.357624 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
11:52:20.359766 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
11:52:20.360878 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
11:52:20.361917 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
11:52:20.362737 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
11:52:20.364607 [debug] [MainThread]: Parsing macros/etc/statement.sql
11:52:20.369979 [debug] [MainThread]: Parsing macros/etc/datetime.sql
11:52:20.380260 [debug] [MainThread]: Parsing macros/adapters/schema.sql
11:52:20.382951 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
11:52:20.386316 [debug] [MainThread]: Parsing macros/adapters/relation.sql
11:52:20.398557 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
11:52:20.402287 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
11:52:20.408200 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
11:52:20.417315 [debug] [MainThread]: Parsing macros/adapters/columns.sql
11:52:20.429225 [debug] [MainThread]: Parsing tests/generic/builtin.sql
11:52:20.689213 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
11:52:20.703114 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
11:52:20.705909 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
11:52:20.708780 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
11:52:20.712349 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
11:52:20.848426 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
11:52:20.850268 [info ] [MainThread]: 
11:52:20.850811 [debug] [MainThread]: Acquiring new snowflake connection "master"
11:52:20.851555 [debug] [ThreadPool]: Acquiring new snowflake connection "list_brightacciondb"
11:52:20.867302 [debug] [ThreadPool]: Using snowflake connection "list_brightacciondb"
11:52:20.867552 [debug] [ThreadPool]: On list_brightacciondb: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_brightacciondb"} */

    show terse schemas in database brightacciondb
    limit 10000
11:52:20.867741 [debug] [ThreadPool]: Opening a new connection, currently in state init
11:52:26.989415 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a54548-0004-250c-0000-001445077f3d
11:52:26.989791 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
11:52:26.990245 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_schemas
11:52:26.990540 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
11:52:26.990923 [debug] [ThreadPool]: On list_brightacciondb: Close
11:52:27.462501 [debug] [MainThread]: Connection 'master' was properly closed.
11:52:27.462818 [debug] [MainThread]: Connection 'list_brightacciondb' was properly closed.


============================== 2022-06-29 12:02:07.825602 | e34689ea-4ab2-4e26-97d1-2c898c37790b ==============================
12:02:07.825630 [info ] [MainThread]: Running with dbt=1.1.1
12:02:07.826441 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
12:02:07.826655 [debug] [MainThread]: Tracking: do not track
12:02:07.944195 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:02:07.944941 [debug] [MainThread]: Partial parsing: updated file: demo_dbt://snapshots/customers.sql


============================== 2022-06-29 12:02:31.480634 | e32872f9-17ca-49e8-b07d-4f3ec9a318de ==============================
12:02:31.480650 [info ] [MainThread]: Running with dbt=1.1.1
12:02:31.481636 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
12:02:31.482189 [debug] [MainThread]: Tracking: do not track
12:02:31.582469 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:02:31.583530 [debug] [MainThread]: Partial parsing: updated file: demo_dbt://snapshots/customers.sql
12:02:31.689773 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
12:02:31.692246 [info ] [MainThread]: 
12:02:31.692875 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:02:31.694694 [debug] [ThreadPool]: Acquiring new snowflake connection "list_MY_DATABASE"
12:02:31.711670 [debug] [ThreadPool]: Using snowflake connection "list_MY_DATABASE"
12:02:31.711963 [debug] [ThreadPool]: On list_MY_DATABASE: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_MY_DATABASE"} */

    show terse schemas in database MY_DATABASE
    limit 10000
12:02:31.712186 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:02:33.968880 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 2.26 seconds
12:02:33.971302 [debug] [ThreadPool]: On list_MY_DATABASE: Close
12:02:34.441279 [debug] [ThreadPool]: Acquiring new snowflake connection "create_MY_DATABASE_snapshots"
12:02:34.441801 [debug] [ThreadPool]: Acquiring new snowflake connection "create_MY_DATABASE_snapshots"
12:02:34.442063 [debug] [ThreadPool]: Creating schema "_ReferenceKey(database='my_database', schema='snapshots', identifier=None)"
12:02:34.447617 [debug] [ThreadPool]: Using snowflake connection "create_MY_DATABASE_snapshots"
12:02:34.447831 [debug] [ThreadPool]: On create_MY_DATABASE_snapshots: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "create_MY_DATABASE_snapshots"} */
create schema if not exists MY_DATABASE.snapshots
12:02:34.447980 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:02:35.826224 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.38 seconds
12:02:35.828046 [debug] [ThreadPool]: On create_MY_DATABASE_snapshots: Close
12:02:36.306600 [debug] [ThreadPool]: Acquiring new snowflake connection "list_MY_DATABASE_snapshots"
12:02:36.315684 [debug] [ThreadPool]: Using snowflake connection "list_MY_DATABASE_snapshots"
12:02:36.315950 [debug] [ThreadPool]: On list_MY_DATABASE_snapshots: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_MY_DATABASE_snapshots"} */

    show terse objects in MY_DATABASE.snapshots
12:02:36.316129 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:02:37.902427 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1.59 seconds
12:02:37.904553 [debug] [ThreadPool]: On list_MY_DATABASE_snapshots: Close
12:02:38.590157 [debug] [ThreadPool]: Acquiring new snowflake connection "list_MY_DATABASE_MYSCHEMA"
12:02:38.592901 [debug] [ThreadPool]: Using snowflake connection "list_MY_DATABASE_MYSCHEMA"
12:02:38.594366 [debug] [ThreadPool]: On list_MY_DATABASE_MYSCHEMA: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_MY_DATABASE_MYSCHEMA"} */

    show terse objects in MY_DATABASE.MYSCHEMA
12:02:38.594651 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:02:39.976389 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.38 seconds
12:02:39.979010 [debug] [ThreadPool]: On list_MY_DATABASE_MYSCHEMA: Close
12:02:40.461027 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:02:40.461876 [info ] [MainThread]: 
12:02:40.468487 [debug] [Thread-1  ]: Began running node snapshot.demo_dbt.customers_snapshot
12:02:40.469063 [info ] [Thread-1  ]: 1 of 1 START snapshot snapshots.customers_snapshot ............................. [RUN]
12:02:40.469715 [debug] [Thread-1  ]: Acquiring new snowflake connection "snapshot.demo_dbt.customers_snapshot"
12:02:40.470046 [debug] [Thread-1  ]: Began compiling node snapshot.demo_dbt.customers_snapshot
12:02:40.470285 [debug] [Thread-1  ]: Compiling snapshot.demo_dbt.customers_snapshot
12:02:40.474887 [debug] [Thread-1  ]: finished collecting timing info
12:02:40.475141 [debug] [Thread-1  ]: Began executing node snapshot.demo_dbt.customers_snapshot
12:02:40.545222 [debug] [Thread-1  ]: Writing runtime SQL for node "snapshot.demo_dbt.customers_snapshot"
12:02:40.548180 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
12:02:40.548510 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

      

      create or replace transient table MY_DATABASE.snapshots.customers_snapshot  as
      (

    select *,
        md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(datetime_updated as varchar ), '')
        ) as dbt_scd_id,
        datetime_updated as dbt_updated_at,
        datetime_updated as dbt_valid_from,
        nullif(datetime_updated, datetime_updated) as dbt_valid_to
    from (
        



select * from MY_DATABASE.warehouse.customers

    ) sbq



      );
12:02:40.548749 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:02:42.287210 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a54552-0004-250c-0000-001445077fc5
12:02:42.290772 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 002003 (02000): SQL compilation error:
Schema 'MY_DATABASE.WAREHOUSE' does not exist or not authorized.
12:02:42.291926 [debug] [Thread-1  ]: finished collecting timing info
12:02:42.296290 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: Close
12:02:42.779491 [debug] [Thread-1  ]: Database Error in snapshot customers_snapshot (snapshots/customers.sql)
  002003 (02000): SQL compilation error:
  Schema 'MY_DATABASE.WAREHOUSE' does not exist or not authorized.
  compiled SQL at target/run/demo_dbt/snapshots/customers.sql
12:02:42.780285 [error] [Thread-1  ]: 1 of 1 ERROR snapshotting snapshots.customers_snapshot ......................... [[31mERROR[0m in 2.31s]
12:02:42.781057 [debug] [Thread-1  ]: Finished running node snapshot.demo_dbt.customers_snapshot
12:02:42.834950 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:02:42.835989 [info ] [MainThread]: 
12:02:42.836817 [info ] [MainThread]: Finished running 1 snapshot in 11.14s.
12:02:42.837340 [debug] [MainThread]: Connection 'master' was properly closed.
12:02:42.837611 [debug] [MainThread]: Connection 'snapshot.demo_dbt.customers_snapshot' was properly closed.
12:02:42.846710 [info ] [MainThread]: 
12:02:42.847341 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:02:42.847834 [info ] [MainThread]: 
12:02:42.848190 [error] [MainThread]: [33mDatabase Error in snapshot customers_snapshot (snapshots/customers.sql)[0m
12:02:42.848608 [error] [MainThread]:   002003 (02000): SQL compilation error:
12:02:42.848968 [error] [MainThread]:   Schema 'MY_DATABASE.WAREHOUSE' does not exist or not authorized.
12:02:42.849226 [error] [MainThread]:   compiled SQL at target/run/demo_dbt/snapshots/customers.sql
12:02:42.849496 [info ] [MainThread]: 
12:02:42.849769 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1


============================== 2022-06-29 12:03:14.299517 | bd6079b1-c7cc-42d4-a3f5-6b54eeee33eb ==============================
12:03:14.299531 [info ] [MainThread]: Running with dbt=1.1.1
12:03:14.300519 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
12:03:14.300835 [debug] [MainThread]: Tracking: do not track
12:03:14.387452 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:03:14.387995 [debug] [MainThread]: Partial parsing: updated file: demo_dbt://snapshots/customers.sql


============================== 2022-06-29 12:05:54.798555 | a27b9dcb-3e9e-4302-aeb0-aa05e5891edb ==============================
12:05:54.798581 [info ] [MainThread]: Running with dbt=1.1.1
12:05:54.799895 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
12:05:54.800129 [debug] [MainThread]: Tracking: do not track
12:05:54.877553 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:05:54.878113 [debug] [MainThread]: Partial parsing: updated file: demo_dbt://snapshots/customers.sql


============================== 2022-06-29 12:07:57.815459 | 6bd8bd4b-c466-4d57-9b2d-62a54108b419 ==============================
12:07:57.815489 [info ] [MainThread]: Running with dbt=1.1.1
12:07:57.822954 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
12:07:57.823517 [debug] [MainThread]: Tracking: do not track
12:07:57.975579 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:07:57.976158 [debug] [MainThread]: Partial parsing: updated file: demo_dbt://snapshots/customers.sql


============================== 2022-06-29 12:08:39.350273 | 6fed89e0-4e45-43b4-9434-86231d493bd5 ==============================
12:08:39.350299 [info ] [MainThread]: Running with dbt=1.1.1
12:08:39.356304 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
12:08:39.356605 [debug] [MainThread]: Tracking: do not track
12:08:39.420229 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:08:39.420951 [debug] [MainThread]: Partial parsing: updated file: demo_dbt://snapshots/customers.sql


============================== 2022-06-29 12:09:06.639685 | b893e683-9373-4115-b10b-3cfe8381d0a6 ==============================
12:09:06.639699 [info ] [MainThread]: Running with dbt=1.1.1
12:09:06.640631 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
12:09:06.640845 [debug] [MainThread]: Tracking: do not track
12:09:06.713660 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:09:06.714225 [debug] [MainThread]: Partial parsing: updated file: demo_dbt://snapshots/customers.sql


============================== 2022-06-29 12:10:35.762576 | 6e4df657-8256-47ef-a71d-9e6ea5099e34 ==============================
12:10:35.762591 [info ] [MainThread]: Running with dbt=1.1.1
12:10:35.763170 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
12:10:35.763430 [debug] [MainThread]: Tracking: do not track
12:10:35.792800 [info ] [MainThread]: Unable to do partial parsing because profile has changed
12:10:35.823933 [debug] [MainThread]: Parsing macros/catalog.sql
12:10:35.827339 [debug] [MainThread]: Parsing macros/adapters.sql
12:10:35.877300 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:10:35.883240 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:10:35.889567 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:10:35.891219 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:10:35.894993 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:10:35.906068 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:10:35.907454 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:10:35.915319 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:10:35.918510 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:10:35.920547 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:10:35.941458 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:10:35.957406 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:10:35.970848 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:10:35.976241 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:10:35.978352 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:10:35.981067 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:10:35.986805 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:10:36.007311 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:10:36.009156 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:10:36.021862 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:10:36.040402 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:10:36.050358 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:10:36.054120 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:10:36.062611 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:10:36.064199 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:10:36.067381 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:10:36.070104 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:10:36.077572 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:10:36.098007 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:10:36.099981 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:10:36.102943 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:10:36.104973 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:10:36.106030 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:10:36.107009 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:10:36.107826 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:10:36.109776 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:10:36.116180 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:10:36.127112 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:10:36.130012 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:10:36.133280 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:10:36.145368 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:10:36.149438 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:10:36.155241 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:10:36.163927 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:10:36.177001 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:10:36.451279 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
12:10:36.464988 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
12:10:36.468235 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
12:10:36.471882 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
12:10:36.475424 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql


============================== 2022-06-29 12:11:42.602084 | 8454f699-545e-434e-ace0-5d8a3264b745 ==============================
12:11:42.602098 [info ] [MainThread]: Running with dbt=1.1.1
12:11:42.603187 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
12:11:42.603492 [debug] [MainThread]: Tracking: do not track
12:11:42.630086 [info ] [MainThread]: Unable to do partial parsing because profile has changed
12:11:42.652412 [debug] [MainThread]: Parsing macros/catalog.sql
12:11:42.655389 [debug] [MainThread]: Parsing macros/adapters.sql
12:11:42.705628 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:11:42.711525 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:11:42.718997 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:11:42.721171 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:11:42.725326 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:11:42.741538 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:11:42.743506 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:11:42.748500 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:11:42.751262 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:11:42.753279 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:11:42.774510 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:11:42.791622 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:11:42.805707 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:11:42.811613 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:11:42.814203 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:11:42.817211 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:11:42.823771 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:11:42.847501 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:11:42.849496 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:11:42.863489 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:11:42.883024 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:11:42.892318 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:11:42.895759 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:11:42.904510 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:11:42.906176 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:11:42.909748 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:11:42.912718 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:11:42.920387 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:11:42.940624 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:11:42.942773 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:11:42.946085 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:11:42.948002 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:11:42.949040 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:11:42.950000 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:11:42.950827 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:11:42.952681 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:11:42.958132 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:11:42.968555 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:11:42.971279 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:11:42.974719 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:11:42.987968 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:11:42.991495 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:11:42.996898 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:11:43.006516 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:11:43.019384 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:11:43.293562 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
12:11:43.307160 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
12:11:43.310275 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
12:11:43.313325 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
12:11:43.316657 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql


============================== 2022-06-29 12:14:41.369897 | 1f14c69a-9c9b-460b-bf41-7eab52e61eda ==============================
12:14:41.369916 [info ] [MainThread]: Running with dbt=1.1.1
12:14:41.371108 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
12:14:41.371365 [debug] [MainThread]: Tracking: do not track
12:14:41.395966 [info ] [MainThread]: Unable to do partial parsing because profile has changed
12:14:41.440046 [debug] [MainThread]: Parsing macros/catalog.sql
12:14:41.443295 [debug] [MainThread]: Parsing macros/adapters.sql
12:14:41.495243 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:14:41.501460 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:14:41.508319 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:14:41.509982 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:14:41.513787 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:14:41.525347 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:14:41.526670 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:14:41.531485 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:14:41.534386 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:14:41.536516 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:14:41.557435 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:14:41.573363 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:14:41.587439 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:14:41.593604 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:14:41.596227 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:14:41.598686 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:14:41.604126 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:14:41.624314 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:14:41.626222 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:14:41.639122 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:14:41.658374 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:14:41.667694 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:14:41.671194 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:14:41.679863 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:14:41.681550 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:14:41.684855 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:14:41.687677 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:14:41.695753 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:14:41.715793 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:14:41.717655 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:14:41.720591 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:14:41.722630 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:14:41.724144 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:14:41.725184 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:14:41.726107 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:14:41.728365 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:14:41.736213 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:14:41.746915 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:14:41.749892 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:14:41.753619 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:14:41.767458 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:14:41.771681 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:14:41.779391 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:14:41.789445 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:14:41.801882 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:14:42.065053 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
12:14:42.084894 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
12:14:42.087942 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
12:14:42.090843 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
12:14:42.094032 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql


============================== 2022-06-29 12:23:30.385824 | f6b9624c-0c48-4af5-bce9-f8306ee8891b ==============================
12:23:30.385841 [info ] [MainThread]: Running with dbt=1.1.1
12:23:30.386897 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
12:23:30.387271 [debug] [MainThread]: Tracking: do not track
12:23:30.419895 [info ] [MainThread]: Unable to do partial parsing because profile has changed
12:23:30.477818 [debug] [MainThread]: Parsing macros/catalog.sql
12:23:30.480977 [debug] [MainThread]: Parsing macros/adapters.sql
12:23:30.537829 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:23:30.542946 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:23:30.550428 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:23:30.552950 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:23:30.556965 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:23:30.569284 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:23:30.570533 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:23:30.575619 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:23:30.579566 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:23:30.581798 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:23:30.604437 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:23:30.620690 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:23:30.634779 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:23:30.640438 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:23:30.642616 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:23:30.644853 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:23:30.650922 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:23:30.672221 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:23:30.674349 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:23:30.688937 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:23:30.714342 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:23:30.724215 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:23:30.728618 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:23:30.738233 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:23:30.739922 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:23:30.743326 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:23:30.746077 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:23:30.754596 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:23:30.774802 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:23:30.776647 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:23:30.779750 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:23:30.781866 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:23:30.783661 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:23:30.784880 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:23:30.785737 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:23:30.787661 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:23:30.793675 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:23:30.804003 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:23:30.806676 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:23:30.810102 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:23:30.823990 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:23:30.827805 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:23:30.833440 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:23:30.842974 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:23:30.855491 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:23:31.138415 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
12:23:31.152291 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
12:23:31.155363 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
12:23:31.158540 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
12:23:31.161709 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql


============================== 2022-06-29 12:29:25.246679 | 48f81a01-c7aa-4206-9f5e-6d88e0712b0e ==============================
12:29:25.246694 [info ] [MainThread]: Running with dbt=1.1.1
12:29:25.247566 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
12:29:25.247856 [debug] [MainThread]: Tracking: do not track
12:29:25.277747 [info ] [MainThread]: Unable to do partial parsing because profile has changed
12:29:25.320527 [debug] [MainThread]: Parsing macros/catalog.sql
12:29:25.323511 [debug] [MainThread]: Parsing macros/adapters.sql
12:29:25.389544 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:29:25.394482 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:29:25.401674 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:29:25.403327 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:29:25.407272 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:29:25.419085 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:29:25.420289 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:29:25.425535 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:29:25.428712 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:29:25.430687 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:29:25.453066 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:29:25.469895 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:29:25.485418 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:29:25.497305 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:29:25.501134 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:29:25.503716 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:29:25.509835 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:29:25.531093 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:29:25.533029 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:29:25.546462 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:29:25.566131 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:29:25.575596 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:29:25.579829 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:29:25.588992 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:29:25.590616 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:29:25.594111 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:29:25.597255 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:29:25.605235 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:29:25.626339 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:29:25.628439 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:29:25.631403 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:29:25.633705 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:29:25.634785 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:29:25.635764 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:29:25.636606 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:29:25.638478 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:29:25.645177 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:29:25.655777 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:29:25.658557 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:29:25.661879 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:29:25.674316 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:29:25.678466 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:29:25.684353 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:29:25.693222 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:29:25.705954 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:29:25.984471 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
12:29:26.005555 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
12:29:26.008486 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
12:29:26.012136 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
12:29:26.015596 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql


============================== 2022-06-29 12:30:15.973779 | 09442ce2-6079-4365-b6fd-8b22f3c594f6 ==============================
12:30:15.973798 [info ] [MainThread]: Running with dbt=1.1.1
12:30:15.974981 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
12:30:15.975304 [debug] [MainThread]: Tracking: do not track
12:30:16.005182 [info ] [MainThread]: Unable to do partial parsing because profile has changed
12:30:16.041180 [debug] [MainThread]: Parsing macros/catalog.sql
12:30:16.045427 [debug] [MainThread]: Parsing macros/adapters.sql
12:30:16.122710 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:30:16.133013 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:30:16.140395 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:30:16.142521 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:30:16.147062 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:30:16.160528 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:30:16.161866 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:30:16.168283 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:30:16.172782 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:30:16.175153 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:30:16.200227 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:30:16.218585 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:30:16.236930 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:30:16.246162 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:30:16.248742 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:30:16.251316 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:30:16.258410 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:30:16.279447 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:30:16.281329 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:30:16.294922 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:30:16.314281 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:30:16.325213 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:30:16.329319 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:30:16.338469 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:30:16.340130 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:30:16.343491 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:30:16.346414 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:30:16.355059 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:30:16.375778 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:30:16.377735 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:30:16.380826 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:30:16.383023 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:30:16.384572 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:30:16.385618 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:30:16.386791 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:30:16.388763 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:30:16.394503 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:30:16.404961 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:30:16.407863 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:30:16.411157 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:30:16.430148 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:30:16.435009 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:30:16.440806 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:30:16.451225 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:30:16.464377 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:30:16.752532 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
12:30:16.766708 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
12:30:16.769408 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
12:30:16.772103 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
12:30:16.775297 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql


============================== 2022-06-29 12:30:38.143702 | 1d882329-f86f-4d2d-b304-d9888bcfcad6 ==============================
12:30:38.143717 [info ] [MainThread]: Running with dbt=1.1.1
12:30:38.144598 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
12:30:38.144899 [debug] [MainThread]: Tracking: do not track
12:30:38.169323 [info ] [MainThread]: Unable to do partial parsing because profile has changed
12:30:38.220217 [debug] [MainThread]: Parsing macros/catalog.sql
12:30:38.224852 [debug] [MainThread]: Parsing macros/adapters.sql
12:30:38.297094 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:30:38.304677 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:30:38.316904 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:30:38.319601 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:30:38.324219 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:30:38.338468 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:30:38.340216 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:30:38.345995 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:30:38.348796 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:30:38.350905 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:30:38.372155 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:30:38.388252 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:30:38.402378 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:30:38.409168 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:30:38.411544 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:30:38.414126 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:30:38.420345 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:30:38.444712 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:30:38.446571 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:30:38.459456 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:30:38.480990 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:30:38.493449 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:30:38.496945 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:30:38.505879 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:30:38.507875 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:30:38.511461 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:30:38.514796 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:30:38.523515 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:30:38.548324 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:30:38.550124 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:30:38.553286 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:30:38.555172 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:30:38.556461 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:30:38.557453 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:30:38.558562 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:30:38.561834 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:30:38.567890 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:30:38.580034 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:30:38.582793 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:30:38.586278 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:30:38.598242 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:30:38.602018 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:30:38.608421 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:30:38.617865 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:30:38.632118 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:30:38.923719 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
12:30:38.938827 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
12:30:38.942612 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
12:30:38.945587 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
12:30:38.948955 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql


============================== 2022-06-29 12:31:22.193356 | dc9cc3fd-087d-41c9-868c-649e5118dcfd ==============================
12:31:22.193372 [info ] [MainThread]: Running with dbt=1.1.1
12:31:22.194591 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
12:31:22.194957 [debug] [MainThread]: Tracking: do not track
12:31:22.236233 [info ] [MainThread]: Unable to do partial parsing because profile has changed
12:31:22.286252 [debug] [MainThread]: Parsing macros/catalog.sql
12:31:22.289776 [debug] [MainThread]: Parsing macros/adapters.sql
12:31:22.346241 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:31:22.351193 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:31:22.358209 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:31:22.359991 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:31:22.364266 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:31:22.375129 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:31:22.376461 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:31:22.382326 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:31:22.385128 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:31:22.387258 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:31:22.408095 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:31:22.424604 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:31:22.438080 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:31:22.444284 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:31:22.446575 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:31:22.448852 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:31:22.454297 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:31:22.474615 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:31:22.477009 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:31:22.490752 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:31:22.510653 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:31:22.520737 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:31:22.524425 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:31:22.533493 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:31:22.535154 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:31:22.538619 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:31:22.541364 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:31:22.550066 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:31:22.571642 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:31:22.573573 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:31:22.577002 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:31:22.578981 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:31:22.580012 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:31:22.581195 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:31:22.582022 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:31:22.583871 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:31:22.589561 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:31:22.600568 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:31:22.603239 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:31:22.606563 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:31:22.620474 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:31:22.623968 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:31:22.629368 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:31:22.638161 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:31:22.650891 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:31:22.927170 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
12:31:22.940522 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
12:31:22.943831 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
12:31:22.947038 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
12:31:22.950453 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql


============================== 2022-06-29 12:35:14.392546 | 5f0facbc-73f4-478f-aa97-ffee02b5fa53 ==============================
12:35:14.392565 [info ] [MainThread]: Running with dbt=1.1.1
12:35:14.414987 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
12:35:14.415357 [debug] [MainThread]: Tracking: do not track
12:35:14.479373 [info ] [MainThread]: Unable to do partial parsing because profile has changed
12:35:14.624164 [debug] [MainThread]: Parsing macros/catalog.sql
12:35:14.627751 [debug] [MainThread]: Parsing macros/adapters.sql
12:35:14.675476 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:35:14.680416 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:35:14.687035 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:35:14.688687 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:35:14.693122 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:35:14.707676 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:35:14.709118 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:35:14.714050 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:35:14.716884 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:35:14.718895 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:35:14.740842 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:35:14.756722 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:35:14.772014 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:35:14.777711 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:35:14.780392 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:35:14.782570 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:35:14.788134 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:35:14.808607 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:35:14.810495 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:35:14.824255 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:35:14.843144 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:35:14.852601 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:35:14.856187 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:35:14.866349 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:35:14.868028 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:35:14.871388 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:35:14.874178 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:35:14.883408 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:35:14.910640 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:35:14.912519 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:35:14.915601 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:35:14.917566 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:35:14.918634 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:35:14.919611 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:35:14.920486 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:35:14.922321 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:35:14.928294 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:35:14.939226 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:35:14.942082 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:35:14.946446 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:35:14.958582 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:35:14.963394 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:35:14.968989 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:35:14.977848 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:35:14.991325 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:35:15.264085 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
12:35:15.279186 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
12:35:15.282785 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
12:35:15.286297 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
12:35:15.289917 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:35:15.440270 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
12:35:15.442179 [info ] [MainThread]: 
12:35:15.442743 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:35:15.443516 [debug] [ThreadPool]: Acquiring new snowflake connection "list_brightacciondb"
12:35:15.458569 [debug] [ThreadPool]: Using snowflake connection "list_brightacciondb"
12:35:15.458810 [debug] [ThreadPool]: On list_brightacciondb: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_brightacciondb"} */

    show terse schemas in database brightacciondb
    limit 10000
12:35:15.458975 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:35:17.480404 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a54573-0004-250b-0000-00144507a0a5
12:35:17.480830 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
12:35:17.481280 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_schemas
12:35:17.481484 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
12:35:17.481857 [debug] [ThreadPool]: On list_brightacciondb: Close
12:35:17.955829 [debug] [MainThread]: Connection 'master' was properly closed.
12:35:17.956140 [debug] [MainThread]: Connection 'list_brightacciondb' was properly closed.


============================== 2022-06-29 12:36:40.676161 | a59771e2-ea34-4511-b554-521c651569c4 ==============================
12:36:40.676181 [info ] [MainThread]: Running with dbt=1.1.1
12:36:40.677300 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
12:36:40.677579 [debug] [MainThread]: Tracking: do not track
12:36:40.738485 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:36:40.738982 [debug] [MainThread]: Partial parsing: updated file: demo_dbt://snapshots/customers.sql
12:36:40.796077 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
12:36:40.798118 [info ] [MainThread]: 
12:36:40.798773 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:36:40.799722 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database"
12:36:40.820822 [debug] [ThreadPool]: Using snowflake connection "list_my_database"
12:36:40.821249 [debug] [ThreadPool]: On list_my_database: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database"} */

    show terse schemas in database my_database
    limit 10000
12:36:40.821613 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:36:42.605974 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.78 seconds
12:36:42.608326 [debug] [ThreadPool]: On list_my_database: Close
12:36:43.081572 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database_myschemas"
12:36:43.091141 [debug] [ThreadPool]: Using snowflake connection "list_my_database_myschemas"
12:36:43.091419 [debug] [ThreadPool]: On list_my_database_myschemas: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database_myschemas"} */

    show terse objects in my_database.myschemas
12:36:43.091601 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:36:44.869041 [debug] [ThreadPool]: Snowflake adapter: Snowflake query id: 01a54574-0004-250c-0000-0014450790a1
12:36:44.869465 [debug] [ThreadPool]: Snowflake adapter: Snowflake error: 002043 (02000): SQL compilation error:
Object does not exist, or operation cannot be performed.
12:36:44.869952 [debug] [ThreadPool]: Snowflake adapter: Error running SQL: macro list_relations_without_caching
12:36:44.870207 [debug] [ThreadPool]: Snowflake adapter: Rolling back transaction.
12:36:44.870603 [debug] [ThreadPool]: On list_my_database_myschemas: Close
12:36:45.363973 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database_myschema"
12:36:45.366860 [debug] [ThreadPool]: Using snowflake connection "list_my_database_myschema"
12:36:45.367132 [debug] [ThreadPool]: On list_my_database_myschema: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database_myschema"} */

    show terse objects in my_database.myschema
12:36:45.367349 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:36:46.813516 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.45 seconds
12:36:46.816749 [debug] [ThreadPool]: On list_my_database_myschema: Close
12:36:47.288510 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:36:47.289020 [info ] [MainThread]: 
12:36:47.293256 [debug] [Thread-1  ]: Began running node snapshot.demo_dbt.customers_snapshot
12:36:47.293742 [info ] [Thread-1  ]: 1 of 1 START snapshot myschema.customers_snapshot .............................. [RUN]
12:36:47.294480 [debug] [Thread-1  ]: Acquiring new snowflake connection "snapshot.demo_dbt.customers_snapshot"
12:36:47.294770 [debug] [Thread-1  ]: Began compiling node snapshot.demo_dbt.customers_snapshot
12:36:47.295018 [debug] [Thread-1  ]: Compiling snapshot.demo_dbt.customers_snapshot
12:36:47.299290 [debug] [Thread-1  ]: finished collecting timing info
12:36:47.299612 [debug] [Thread-1  ]: Began executing node snapshot.demo_dbt.customers_snapshot
12:36:47.380005 [debug] [Thread-1  ]: Writing runtime SQL for node "snapshot.demo_dbt.customers_snapshot"
12:36:47.381498 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
12:36:47.381704 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

      

      create or replace transient table my_database.myschema.customers_snapshot  as
      (

    select *,
        md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(datetime_updated as varchar ), '')
        ) as dbt_scd_id,
        datetime_updated as dbt_updated_at,
        datetime_updated as dbt_valid_from,
        nullif(datetime_updated, datetime_updated) as dbt_valid_to
    from (
        



select * from my_database.warehouse.customers

    ) sbq



      );
12:36:47.381849 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:36:48.839709 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a54574-0004-250c-0000-0014450790a5
12:36:48.840037 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 002003 (02000): SQL compilation error:
Schema 'MY_DATABASE.WAREHOUSE' does not exist or not authorized.
12:36:48.840419 [debug] [Thread-1  ]: finished collecting timing info
12:36:48.840664 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: Close
12:36:49.333661 [debug] [Thread-1  ]: Database Error in snapshot customers_snapshot (snapshots/customers.sql)
  002003 (02000): SQL compilation error:
  Schema 'MY_DATABASE.WAREHOUSE' does not exist or not authorized.
  compiled SQL at target/run/demo_dbt/snapshots/customers.sql
12:36:49.334367 [error] [Thread-1  ]: 1 of 1 ERROR snapshotting myschema.customers_snapshot .......................... [[31mERROR[0m in 2.04s]
12:36:49.335083 [debug] [Thread-1  ]: Finished running node snapshot.demo_dbt.customers_snapshot
12:36:49.354422 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:36:49.355098 [info ] [MainThread]: 
12:36:49.355602 [info ] [MainThread]: Finished running 1 snapshot in 8.56s.
12:36:49.356085 [debug] [MainThread]: Connection 'master' was properly closed.
12:36:49.356354 [debug] [MainThread]: Connection 'snapshot.demo_dbt.customers_snapshot' was properly closed.
12:36:49.364430 [info ] [MainThread]: 
12:36:49.364824 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:36:49.365271 [info ] [MainThread]: 
12:36:49.365673 [error] [MainThread]: [33mDatabase Error in snapshot customers_snapshot (snapshots/customers.sql)[0m
12:36:49.366047 [error] [MainThread]:   002003 (02000): SQL compilation error:
12:36:49.366435 [error] [MainThread]:   Schema 'MY_DATABASE.WAREHOUSE' does not exist or not authorized.
12:36:49.366787 [error] [MainThread]:   compiled SQL at target/run/demo_dbt/snapshots/customers.sql
12:36:49.367188 [info ] [MainThread]: 
12:36:49.367561 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1


============================== 2022-06-29 12:37:14.184789 | 88afdd39-17ad-4995-b2bf-197a4299bb24 ==============================
12:37:14.184803 [info ] [MainThread]: Running with dbt=1.1.1
12:37:14.185440 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
12:37:14.185718 [debug] [MainThread]: Tracking: do not track
12:37:14.226857 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:37:14.227403 [debug] [MainThread]: Partial parsing: updated file: demo_dbt://snapshots/customers.sql


============================== 2022-06-29 12:47:45.789921 | 6965c2ed-0b4a-47b5-ada1-099140598632 ==============================
12:47:45.789945 [info ] [MainThread]: Running with dbt=1.1.1
12:47:45.790935 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
12:47:45.791317 [debug] [MainThread]: Tracking: do not track
12:47:45.825077 [info ] [MainThread]: Unable to do partial parsing because profile has changed
12:47:45.904745 [debug] [MainThread]: Parsing macros/catalog.sql
12:47:45.908134 [debug] [MainThread]: Parsing macros/adapters.sql
12:47:45.968426 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:47:45.974010 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:47:45.980581 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:47:45.982209 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:47:45.986219 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:47:45.997248 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:47:45.998615 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:47:46.003846 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:47:46.006999 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:47:46.009007 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:47:46.030405 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:47:46.046447 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:47:46.060320 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:47:46.065990 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:47:46.068440 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:47:46.071135 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:47:46.076830 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:47:46.096598 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:47:46.098538 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:47:46.112005 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:47:46.131791 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:47:46.141696 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:47:46.145558 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:47:46.154583 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:47:46.156225 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:47:46.159671 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:47:46.162774 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:47:46.171193 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:47:46.191962 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:47:46.193919 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:47:46.197236 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:47:46.199142 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:47:46.200176 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:47:46.201151 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:47:46.202311 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:47:46.204378 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:47:46.210311 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:47:46.220414 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:47:46.223145 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:47:46.226488 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:47:46.238070 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:47:46.241576 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:47:46.246897 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:47:46.256049 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:47:46.268453 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:47:46.542611 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
12:47:46.555872 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
12:47:46.558573 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
12:47:46.561283 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
12:47:46.564676 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql


============================== 2022-06-29 12:48:09.497987 | 53f817ad-2cc8-42f5-b49c-7211db1060d5 ==============================
12:48:09.498002 [info ] [MainThread]: Running with dbt=1.1.1
12:48:09.498589 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
12:48:09.498792 [debug] [MainThread]: Tracking: do not track
12:48:09.521800 [info ] [MainThread]: Unable to do partial parsing because profile has changed
12:48:09.543636 [debug] [MainThread]: Parsing macros/catalog.sql
12:48:09.546735 [debug] [MainThread]: Parsing macros/adapters.sql
12:48:09.594675 [debug] [MainThread]: Parsing macros/materializations/merge.sql
12:48:09.600350 [debug] [MainThread]: Parsing macros/materializations/seed.sql
12:48:09.607933 [debug] [MainThread]: Parsing macros/materializations/view.sql
12:48:09.610505 [debug] [MainThread]: Parsing macros/materializations/table.sql
12:48:09.615089 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
12:48:09.626052 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
12:48:09.627394 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
12:48:09.633128 [debug] [MainThread]: Parsing macros/materializations/configs.sql
12:48:09.637226 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
12:48:09.639286 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
12:48:09.661128 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
12:48:09.677672 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
12:48:09.691075 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
12:48:09.696569 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
12:48:09.698795 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
12:48:09.700953 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
12:48:09.706896 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
12:48:09.727092 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
12:48:09.729127 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
12:48:09.741755 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
12:48:09.760336 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
12:48:09.769835 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
12:48:09.773409 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
12:48:09.782546 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
12:48:09.784222 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
12:48:09.787587 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
12:48:09.790665 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
12:48:09.798295 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
12:48:09.819534 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
12:48:09.821449 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
12:48:09.824426 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
12:48:09.826317 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
12:48:09.827351 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
12:48:09.828404 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
12:48:09.829232 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
12:48:09.831080 [debug] [MainThread]: Parsing macros/etc/statement.sql
12:48:09.836383 [debug] [MainThread]: Parsing macros/etc/datetime.sql
12:48:09.847212 [debug] [MainThread]: Parsing macros/adapters/schema.sql
12:48:09.850129 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
12:48:09.853704 [debug] [MainThread]: Parsing macros/adapters/relation.sql
12:48:09.867865 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
12:48:09.872373 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
12:48:09.880167 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
12:48:09.890964 [debug] [MainThread]: Parsing macros/adapters/columns.sql
12:48:09.905922 [debug] [MainThread]: Parsing tests/generic/builtin.sql
12:48:10.183925 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
12:48:10.197153 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
12:48:10.199853 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
12:48:10.202542 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
12:48:10.205890 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
12:48:10.342933 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
12:48:10.345045 [info ] [MainThread]: 
12:48:10.345643 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:48:10.346435 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database"
12:48:10.361404 [debug] [ThreadPool]: Using snowflake connection "list_my_database"
12:48:10.361692 [debug] [ThreadPool]: On list_my_database: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database"} */

    show terse schemas in database my_database
    limit 10000
12:48:10.361863 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:48:12.285159 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1.92 seconds
12:48:12.287682 [debug] [ThreadPool]: On list_my_database: Close
12:48:12.763502 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database_warehouse"
12:48:12.773766 [debug] [ThreadPool]: Using snowflake connection "list_my_database_warehouse"
12:48:12.774086 [debug] [ThreadPool]: On list_my_database_warehouse: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database_warehouse"} */

    show terse objects in my_database.warehouse
12:48:12.774457 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:48:14.344416 [debug] [ThreadPool]: SQL status: SUCCESS 3 in 1.57 seconds
12:48:14.346843 [debug] [ThreadPool]: On list_my_database_warehouse: Close
12:48:14.816967 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:48:14.817808 [info ] [MainThread]: 
12:48:14.820689 [debug] [Thread-1  ]: Began running node snapshot.demo_dbt.customers_snapshot
12:48:14.821084 [info ] [Thread-1  ]: 1 of 1 START snapshot warehouse.customers_snapshot ............................. [RUN]
12:48:14.821690 [debug] [Thread-1  ]: Acquiring new snowflake connection "snapshot.demo_dbt.customers_snapshot"
12:48:14.821926 [debug] [Thread-1  ]: Began compiling node snapshot.demo_dbt.customers_snapshot
12:48:14.822121 [debug] [Thread-1  ]: Compiling snapshot.demo_dbt.customers_snapshot
12:48:14.826193 [debug] [Thread-1  ]: finished collecting timing info
12:48:14.826494 [debug] [Thread-1  ]: Began executing node snapshot.demo_dbt.customers_snapshot
12:48:14.902624 [debug] [Thread-1  ]: Writing runtime SQL for node "snapshot.demo_dbt.customers_snapshot"
12:48:14.904075 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
12:48:14.904362 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

      

      create or replace transient table my_database.warehouse.customers_snapshot  as
      (

    select *,
        md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(datetime_updated as varchar ), '')
        ) as dbt_scd_id,
        datetime_updated as dbt_updated_at,
        datetime_updated as dbt_valid_from,
        nullif(datetime_updated, datetime_updated) as dbt_valid_to
    from (
        



select * from my_database.warehouse.customers

    ) sbq



      );
12:48:14.904528 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:48:16.915034 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.01 seconds
12:48:16.934752 [debug] [Thread-1  ]: finished collecting timing info
12:48:16.935042 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: Close
12:48:17.408318 [info ] [Thread-1  ]: 1 of 1 OK snapshotted warehouse.customers_snapshot ............................. [[32mSUCCESS 1[0m in 2.59s]
12:48:17.409042 [debug] [Thread-1  ]: Finished running node snapshot.demo_dbt.customers_snapshot
12:48:17.486227 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:48:17.486825 [info ] [MainThread]: 
12:48:17.487310 [info ] [MainThread]: Finished running 1 snapshot in 7.14s.
12:48:17.487796 [debug] [MainThread]: Connection 'master' was properly closed.
12:48:17.488178 [debug] [MainThread]: Connection 'snapshot.demo_dbt.customers_snapshot' was properly closed.
12:48:17.498319 [info ] [MainThread]: 
12:48:17.498703 [info ] [MainThread]: [32mCompleted successfully[0m
12:48:17.499140 [info ] [MainThread]: 
12:48:17.499523 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1


============================== 2022-06-29 12:49:04.945880 | 28941949-d232-4e1d-a1ed-033cf26314b8 ==============================
12:49:04.945900 [info ] [MainThread]: Running with dbt=1.1.1
12:49:04.946875 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
12:49:04.947456 [debug] [MainThread]: Tracking: do not track
12:49:05.086259 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
12:49:05.086542 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
12:49:05.104603 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
12:49:05.106672 [info ] [MainThread]: 
12:49:05.107256 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:49:05.108459 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database"
12:49:05.124490 [debug] [ThreadPool]: Using snowflake connection "list_my_database"
12:49:05.124746 [debug] [ThreadPool]: On list_my_database: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database"} */

    show terse schemas in database my_database
    limit 10000
12:49:05.124911 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:49:06.991794 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1.87 seconds
12:49:06.994293 [debug] [ThreadPool]: On list_my_database: Close
12:49:07.470267 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database_warehouse"
12:49:07.478912 [debug] [ThreadPool]: Using snowflake connection "list_my_database_warehouse"
12:49:07.479170 [debug] [ThreadPool]: On list_my_database_warehouse: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database_warehouse"} */

    show terse objects in my_database.warehouse
12:49:07.479344 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:49:08.900358 [debug] [ThreadPool]: SQL status: SUCCESS 4 in 1.42 seconds
12:49:08.902789 [debug] [ThreadPool]: On list_my_database_warehouse: Close
12:49:09.394655 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:49:09.395170 [info ] [MainThread]: 
12:49:09.399282 [debug] [Thread-1  ]: Began running node model.demo_dbt.my_first_dbt_model
12:49:09.399753 [info ] [Thread-1  ]: 1 of 5 START table model warehouse.my_first_dbt_model .......................... [RUN]
12:49:09.400447 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.my_first_dbt_model"
12:49:09.400701 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.my_first_dbt_model
12:49:09.400953 [debug] [Thread-1  ]: Compiling model.demo_dbt.my_first_dbt_model
12:49:09.404953 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.my_first_dbt_model"
12:49:09.407182 [debug] [Thread-1  ]: finished collecting timing info
12:49:09.407797 [debug] [Thread-1  ]: Began executing node model.demo_dbt.my_first_dbt_model
12:49:09.441420 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.my_first_dbt_model"
12:49:09.442928 [debug] [Thread-1  ]: Using snowflake connection "model.demo_dbt.my_first_dbt_model"
12:49:09.443179 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_first_dbt_model"} */


      create or replace transient table my_database.warehouse.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:49:09.443335 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:11.318082 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.87 seconds
12:49:11.334133 [debug] [Thread-1  ]: finished collecting timing info
12:49:11.334433 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: Close
12:49:11.832045 [info ] [Thread-1  ]: 1 of 5 OK created table model warehouse.my_first_dbt_model ..................... [[32mSUCCESS 1[0m in 2.43s]
12:49:11.832875 [debug] [Thread-1  ]: Finished running node model.demo_dbt.my_first_dbt_model
12:49:11.833271 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__customers
12:49:11.833737 [info ] [Thread-1  ]: 2 of 5 START view model warehouse.stg_eltool__customers ........................ [RUN]
12:49:11.834806 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.stg_eltool__customers"
12:49:11.835073 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__customers
12:49:11.835303 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__customers
12:49:11.838643 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__customers"
12:49:11.841609 [debug] [Thread-1  ]: finished collecting timing info
12:49:11.842008 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__customers
12:49:11.865489 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.stg_eltool__customers"
12:49:11.867352 [debug] [Thread-1  ]: Using snowflake connection "model.demo_dbt.stg_eltool__customers"
12:49:11.867627 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__customers"} */

  create or replace  view my_database.warehouse.stg_eltool__customers
  
   as (
    with source as (
    select *
    from my_database.warehouse.customers_snapshot
), renamed as (
    select customer_id,
        zipcode,
        city,
        state_code,
        datetime_created::TIMESTAMP AS datetime_created,
        datetime_updated::TIMESTAMP AS datetime_updated,
        dbt_valid_from,
        dbt_valid_to
    from source
)
select *
from renamed
  );
12:49:11.867787 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:13.486157 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.62 seconds
12:49:13.488549 [debug] [Thread-1  ]: finished collecting timing info
12:49:13.488846 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: Close
12:49:13.941288 [info ] [Thread-1  ]: 2 of 5 OK created view model warehouse.stg_eltool__customers ................... [[32mSUCCESS 1[0m in 2.11s]
12:49:13.942112 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__customers
12:49:13.942464 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__orders
12:49:13.943038 [info ] [Thread-1  ]: 3 of 5 START view model warehouse.stg_eltool__orders ........................... [RUN]
12:49:13.943876 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.stg_eltool__orders"
12:49:13.944130 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__orders
12:49:13.944357 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__orders
12:49:13.947738 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__orders"
12:49:13.948320 [debug] [Thread-1  ]: finished collecting timing info
12:49:13.948606 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__orders
12:49:13.951450 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.stg_eltool__orders"
12:49:13.953208 [debug] [Thread-1  ]: Using snowflake connection "model.demo_dbt.stg_eltool__orders"
12:49:13.953447 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__orders"} */

  create or replace  view my_database.warehouse.stg_eltool__orders
  
   as (
    with source as (
    select *
    from my_database.warehouse.orders
),
renamed as (
    select order_id,
        cust_id AS customer_id,
        order_status,
        order_purchase_timestamp::TIMESTAMP,
        order_approved_at::TIMESTAMP,
        order_delivered_carrier_date::TIMESTAMP,
        order_delivered_customer_date::TIMESTAMP,
        order_estimated_delivery_date::TIMESTAMP
        from source
)
select *
from renamed
  );
12:49:13.953624 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:15.371435 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a54581-0004-250b-0000-00144507a209
12:49:15.371768 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 000904 (42000): SQL compilation error: error line 10 at position 8
invalid identifier 'CUST_ID'
12:49:15.372176 [debug] [Thread-1  ]: finished collecting timing info
12:49:15.372440 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: Close
12:49:15.844933 [debug] [Thread-1  ]: Database Error in model stg_eltool__orders (models/staging/stg_eltool__orders.sql)
  000904 (42000): SQL compilation error: error line 10 at position 8
  invalid identifier 'CUST_ID'
  compiled SQL at target/run/demo_dbt/models/staging/stg_eltool__orders.sql
12:49:15.845545 [error] [Thread-1  ]: 3 of 5 ERROR creating view model warehouse.stg_eltool__orders .................. [[31mERROR[0m in 1.90s]
12:49:15.846349 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__orders
12:49:15.846678 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__state
12:49:15.847005 [info ] [Thread-1  ]: 4 of 5 START view model warehouse.stg_eltool__state ............................ [RUN]
12:49:15.847824 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.stg_eltool__state"
12:49:15.848065 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__state
12:49:15.848286 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__state
12:49:15.851301 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__state"
12:49:15.851919 [debug] [Thread-1  ]: finished collecting timing info
12:49:15.852134 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__state
12:49:15.855204 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.stg_eltool__state"
12:49:15.856659 [debug] [Thread-1  ]: Using snowflake connection "model.demo_dbt.stg_eltool__state"
12:49:15.856999 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__state"} */

  create or replace  view my_database.warehouse.stg_eltool__state
  
   as (
    with source as (
    select *
    from my_database.warehouse.state
),
renamed as (
    select state_identifier::INT AS state_id,
        state_code::VARCHAR(2) AS state_code,
        st_name::VARCHAR(30) AS state_name
    from source
)
select *
from renamed
  );
12:49:15.857272 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:17.388462 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.53 seconds
12:49:17.391583 [debug] [Thread-1  ]: finished collecting timing info
12:49:17.391921 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: Close
12:49:17.869874 [info ] [Thread-1  ]: 4 of 5 OK created view model warehouse.stg_eltool__state ....................... [[32mSUCCESS 1[0m in 2.02s]
12:49:17.870568 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__state
12:49:17.870867 [debug] [Thread-1  ]: Began running node model.demo_dbt.my_second_dbt_model
12:49:17.871191 [info ] [Thread-1  ]: 5 of 5 START view model warehouse.my_second_dbt_model .......................... [RUN]
12:49:17.871838 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.my_second_dbt_model"
12:49:17.872191 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.my_second_dbt_model
12:49:17.872430 [debug] [Thread-1  ]: Compiling model.demo_dbt.my_second_dbt_model
12:49:17.875806 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.my_second_dbt_model"
12:49:17.876357 [debug] [Thread-1  ]: finished collecting timing info
12:49:17.876567 [debug] [Thread-1  ]: Began executing node model.demo_dbt.my_second_dbt_model
12:49:17.879338 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.my_second_dbt_model"
12:49:17.880262 [debug] [Thread-1  ]: Using snowflake connection "model.demo_dbt.my_second_dbt_model"
12:49:17.880454 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_second_dbt_model"} */

  create or replace  view my_database.warehouse.my_second_dbt_model
  
   as (
    -- Use the `ref` function to select from other models

select *
from my_database.warehouse.my_first_dbt_model
where id = 1
  );
12:49:17.880668 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:49:19.463392 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.58 seconds
12:49:19.465926 [debug] [Thread-1  ]: finished collecting timing info
12:49:19.466230 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: Close
12:49:19.923404 [info ] [Thread-1  ]: 5 of 5 OK created view model warehouse.my_second_dbt_model ..................... [[32mSUCCESS 1[0m in 2.05s]
12:49:19.924108 [debug] [Thread-1  ]: Finished running node model.demo_dbt.my_second_dbt_model
12:49:20.012340 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:49:20.012912 [info ] [MainThread]: 
12:49:20.013333 [info ] [MainThread]: Finished running 1 table model, 4 view models in 14.91s.
12:49:20.013790 [debug] [MainThread]: Connection 'master' was properly closed.
12:49:20.014035 [debug] [MainThread]: Connection 'model.demo_dbt.my_second_dbt_model' was properly closed.
12:49:20.021364 [info ] [MainThread]: 
12:49:20.021752 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:49:20.022122 [info ] [MainThread]: 
12:49:20.022438 [error] [MainThread]: [33mDatabase Error in model stg_eltool__orders (models/staging/stg_eltool__orders.sql)[0m
12:49:20.022744 [error] [MainThread]:   000904 (42000): SQL compilation error: error line 10 at position 8
12:49:20.023032 [error] [MainThread]:   invalid identifier 'CUST_ID'
12:49:20.023313 [error] [MainThread]:   compiled SQL at target/run/demo_dbt/models/staging/stg_eltool__orders.sql
12:49:20.023619 [info ] [MainThread]: 
12:49:20.023919 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5


============================== 2022-06-29 12:50:34.973847 | 67e0438a-bd9c-444d-9a7d-b87e0f78022d ==============================
12:50:34.973871 [info ] [MainThread]: Running with dbt=1.1.1
12:50:34.975239 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
12:50:34.975463 [debug] [MainThread]: Tracking: do not track
12:50:35.067397 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:50:35.067914 [debug] [MainThread]: Partial parsing: updated file: demo_dbt://snapshots/customers.sql
12:50:35.128075 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
12:50:35.129967 [info ] [MainThread]: 
12:50:35.130520 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:50:35.131276 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database"
12:50:35.148359 [debug] [ThreadPool]: Using snowflake connection "list_my_database"
12:50:35.148599 [debug] [ThreadPool]: On list_my_database: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database"} */

    show terse schemas in database my_database
    limit 10000
12:50:35.148761 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:50:36.882646 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1.73 seconds
12:50:36.884837 [debug] [ThreadPool]: On list_my_database: Close
12:50:37.343863 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database_snapshots"
12:50:37.351793 [debug] [ThreadPool]: Using snowflake connection "list_my_database_snapshots"
12:50:37.352031 [debug] [ThreadPool]: On list_my_database_snapshots: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database_snapshots"} */

    show terse objects in my_database.snapshots
12:50:37.352185 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:50:38.873699 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1.52 seconds
12:50:38.875681 [debug] [ThreadPool]: On list_my_database_snapshots: Close
12:50:39.339651 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database_warehouse"
12:50:39.342437 [debug] [ThreadPool]: Using snowflake connection "list_my_database_warehouse"
12:50:39.342719 [debug] [ThreadPool]: On list_my_database_warehouse: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database_warehouse"} */

    show terse objects in my_database.warehouse
12:50:39.342928 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:50:40.713564 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.37 seconds
12:50:40.716095 [debug] [ThreadPool]: On list_my_database_warehouse: Close
12:50:41.175718 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:50:41.176236 [info ] [MainThread]: 
12:50:41.180661 [debug] [Thread-1  ]: Began running node snapshot.demo_dbt.customers_snapshot
12:50:41.181284 [info ] [Thread-1  ]: 1 of 1 START snapshot snapshots.customers_snapshot ............................. [RUN]
12:50:41.182088 [debug] [Thread-1  ]: Acquiring new snowflake connection "snapshot.demo_dbt.customers_snapshot"
12:50:41.182358 [debug] [Thread-1  ]: Began compiling node snapshot.demo_dbt.customers_snapshot
12:50:41.182601 [debug] [Thread-1  ]: Compiling snapshot.demo_dbt.customers_snapshot
12:50:41.187283 [debug] [Thread-1  ]: finished collecting timing info
12:50:41.187681 [debug] [Thread-1  ]: Began executing node snapshot.demo_dbt.customers_snapshot
12:50:41.259034 [debug] [Thread-1  ]: Writing runtime SQL for node "snapshot.demo_dbt.customers_snapshot"
12:50:41.260432 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
12:50:41.260613 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

      

      create or replace transient table my_database.snapshots.customers_snapshot  as
      (

    select *,
        md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(datetime_updated as varchar ), '')
        ) as dbt_scd_id,
        datetime_updated as dbt_updated_at,
        datetime_updated as dbt_valid_from,
        nullif(datetime_updated, datetime_updated) as dbt_valid_to
    from (
        



select * from my_database.warehouse.customers

    ) sbq



      );
12:50:41.260759 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:50:43.218707 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.96 seconds
12:50:43.238418 [debug] [Thread-1  ]: finished collecting timing info
12:50:43.238712 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: Close
12:50:43.705780 [info ] [Thread-1  ]: 1 of 1 OK snapshotted snapshots.customers_snapshot ............................. [[32mSUCCESS 1[0m in 2.52s]
12:50:43.707097 [debug] [Thread-1  ]: Finished running node snapshot.demo_dbt.customers_snapshot
12:50:43.748189 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:50:43.748721 [info ] [MainThread]: 
12:50:43.749156 [info ] [MainThread]: Finished running 1 snapshot in 8.62s.
12:50:43.749722 [debug] [MainThread]: Connection 'master' was properly closed.
12:50:43.749951 [debug] [MainThread]: Connection 'snapshot.demo_dbt.customers_snapshot' was properly closed.
12:50:43.758476 [info ] [MainThread]: 
12:50:43.758900 [info ] [MainThread]: [32mCompleted successfully[0m
12:50:43.759386 [info ] [MainThread]: 
12:50:43.759773 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1


============================== 2022-06-29 12:51:41.009301 | e1e9f2d0-3e95-4984-b986-83640346d556 ==============================
12:51:41.009314 [info ] [MainThread]: Running with dbt=1.1.1
12:51:41.010264 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
12:51:41.010903 [debug] [MainThread]: Tracking: do not track
12:51:41.083960 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
12:51:41.084255 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
12:51:41.105865 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
12:51:41.107995 [info ] [MainThread]: 
12:51:41.108909 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:51:41.110222 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database"
12:51:41.138996 [debug] [ThreadPool]: Using snowflake connection "list_my_database"
12:51:41.139273 [debug] [ThreadPool]: On list_my_database: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database"} */

    show terse schemas in database my_database
    limit 10000
12:51:41.139478 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:51:42.930705 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1.79 seconds
12:51:42.933126 [debug] [ThreadPool]: On list_my_database: Close
12:51:43.406570 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database_snapshots"
12:51:43.414993 [debug] [ThreadPool]: Using snowflake connection "list_my_database_snapshots"
12:51:43.415235 [debug] [ThreadPool]: On list_my_database_snapshots: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database_snapshots"} */

    show terse objects in my_database.snapshots
12:51:43.415387 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:51:44.919512 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.5 seconds
12:51:44.921879 [debug] [ThreadPool]: On list_my_database_snapshots: Close
12:51:45.410015 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database_warehouse"
12:51:45.412461 [debug] [ThreadPool]: Using snowflake connection "list_my_database_warehouse"
12:51:45.412679 [debug] [ThreadPool]: On list_my_database_warehouse: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database_warehouse"} */

    show terse objects in my_database.warehouse
12:51:45.412845 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:51:47.049564 [debug] [ThreadPool]: SQL status: SUCCESS 6 in 1.64 seconds
12:51:47.051486 [debug] [ThreadPool]: On list_my_database_warehouse: Close
12:51:47.531845 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:51:47.532360 [info ] [MainThread]: 
12:51:47.535645 [debug] [Thread-1  ]: Began running node model.demo_dbt.my_first_dbt_model
12:51:47.536114 [info ] [Thread-1  ]: 1 of 5 START table model warehouse.my_first_dbt_model .......................... [RUN]
12:51:47.536837 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.my_first_dbt_model"
12:51:47.537104 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.my_first_dbt_model
12:51:47.537346 [debug] [Thread-1  ]: Compiling model.demo_dbt.my_first_dbt_model
12:51:47.540590 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.my_first_dbt_model"
12:51:47.541174 [debug] [Thread-1  ]: finished collecting timing info
12:51:47.541420 [debug] [Thread-1  ]: Began executing node model.demo_dbt.my_first_dbt_model
12:51:47.574801 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.my_first_dbt_model"
12:51:47.575953 [debug] [Thread-1  ]: Using snowflake connection "model.demo_dbt.my_first_dbt_model"
12:51:47.576176 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_first_dbt_model"} */


      create or replace transient table my_database.warehouse.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:51:47.576345 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:51:49.599017 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.02 seconds
12:51:49.614028 [debug] [Thread-1  ]: finished collecting timing info
12:51:49.614327 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: Close
12:51:50.081194 [info ] [Thread-1  ]: 1 of 5 OK created table model warehouse.my_first_dbt_model ..................... [[32mSUCCESS 1[0m in 2.54s]
12:51:50.081948 [debug] [Thread-1  ]: Finished running node model.demo_dbt.my_first_dbt_model
12:51:50.082271 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__customers
12:51:50.082596 [info ] [Thread-1  ]: 2 of 5 START view model warehouse.stg_eltool__customers ........................ [RUN]
12:51:50.083310 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.stg_eltool__customers"
12:51:50.083906 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__customers
12:51:50.084408 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__customers
12:51:50.087829 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__customers"
12:51:50.088382 [debug] [Thread-1  ]: finished collecting timing info
12:51:50.088609 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__customers
12:51:50.111052 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.stg_eltool__customers"
12:51:50.112359 [debug] [Thread-1  ]: Using snowflake connection "model.demo_dbt.stg_eltool__customers"
12:51:50.112538 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__customers"} */

  create or replace  view my_database.warehouse.stg_eltool__customers
  
   as (
    with source as (
    select *
    from my_database.snapshots.customers_snapshot
), renamed as (
    select customer_id,
        zipcode,
        city,
        state_code,
        datetime_created::TIMESTAMP AS datetime_created,
        datetime_updated::TIMESTAMP AS datetime_updated,
        dbt_valid_from,
        dbt_valid_to
    from source
)
select *
from renamed
  );
12:51:50.112685 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:51:51.589363 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.48 seconds
12:51:51.592108 [debug] [Thread-1  ]: finished collecting timing info
12:51:51.592399 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: Close
12:51:52.089744 [info ] [Thread-1  ]: 2 of 5 OK created view model warehouse.stg_eltool__customers ................... [[32mSUCCESS 1[0m in 2.01s]
12:51:52.090458 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__customers
12:51:52.090932 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__orders
12:51:52.091271 [info ] [Thread-1  ]: 3 of 5 START view model warehouse.stg_eltool__orders ........................... [RUN]
12:51:52.091889 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.stg_eltool__orders"
12:51:52.092229 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__orders
12:51:52.092485 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__orders
12:51:52.095660 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__orders"
12:51:52.096285 [debug] [Thread-1  ]: finished collecting timing info
12:51:52.096538 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__orders
12:51:52.099517 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.stg_eltool__orders"
12:51:52.100964 [debug] [Thread-1  ]: Using snowflake connection "model.demo_dbt.stg_eltool__orders"
12:51:52.101152 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__orders"} */

  create or replace  view my_database.warehouse.stg_eltool__orders
  
   as (
    with source as (
    select *
    from my_database.warehouse.orders
),
renamed as (
    select order_id,
        cust_id AS customer_id,
        order_status,
        order_purchase_timestamp::TIMESTAMP,
        order_approved_at::TIMESTAMP,
        order_delivered_carrier_date::TIMESTAMP,
        order_delivered_customer_date::TIMESTAMP,
        order_estimated_delivery_date::TIMESTAMP
        from source
)
select *
from renamed
  );
12:51:52.101318 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:51:53.559000 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a54583-0004-250b-0000-00144507a271
12:51:53.559369 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 000904 (42000): SQL compilation error: error line 10 at position 8
invalid identifier 'CUST_ID'
12:51:53.559833 [debug] [Thread-1  ]: finished collecting timing info
12:51:53.560088 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: Close
12:51:54.033560 [debug] [Thread-1  ]: Database Error in model stg_eltool__orders (models/staging/stg_eltool__orders.sql)
  000904 (42000): SQL compilation error: error line 10 at position 8
  invalid identifier 'CUST_ID'
  compiled SQL at target/run/demo_dbt/models/staging/stg_eltool__orders.sql
12:51:54.034167 [error] [Thread-1  ]: 3 of 5 ERROR creating view model warehouse.stg_eltool__orders .................. [[31mERROR[0m in 1.94s]
12:51:54.034766 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__orders
12:51:54.035088 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__state
12:51:54.035661 [info ] [Thread-1  ]: 4 of 5 START view model warehouse.stg_eltool__state ............................ [RUN]
12:51:54.036339 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.stg_eltool__state"
12:51:54.036575 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__state
12:51:54.036800 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__state
12:51:54.039640 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__state"
12:51:54.040244 [debug] [Thread-1  ]: finished collecting timing info
12:51:54.040470 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__state
12:51:54.043594 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.stg_eltool__state"
12:51:54.044821 [debug] [Thread-1  ]: Using snowflake connection "model.demo_dbt.stg_eltool__state"
12:51:54.045016 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__state"} */

  create or replace  view my_database.warehouse.stg_eltool__state
  
   as (
    with source as (
    select *
    from my_database.warehouse.state
),
renamed as (
    select state_identifier::INT AS state_id,
        state_code::VARCHAR(2) AS state_code,
        st_name::VARCHAR(30) AS state_name
    from source
)
select *
from renamed
  );
12:51:54.045183 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:51:55.500509 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.46 seconds
12:51:55.503039 [debug] [Thread-1  ]: finished collecting timing info
12:51:55.503331 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: Close
12:51:55.991375 [info ] [Thread-1  ]: 4 of 5 OK created view model warehouse.stg_eltool__state ....................... [[32mSUCCESS 1[0m in 1.96s]
12:51:55.992031 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__state
12:51:55.992361 [debug] [Thread-1  ]: Began running node model.demo_dbt.my_second_dbt_model
12:51:55.992846 [info ] [Thread-1  ]: 5 of 5 START view model warehouse.my_second_dbt_model .......................... [RUN]
12:51:55.993756 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.my_second_dbt_model"
12:51:55.994073 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.my_second_dbt_model
12:51:55.994344 [debug] [Thread-1  ]: Compiling model.demo_dbt.my_second_dbt_model
12:51:55.998472 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.my_second_dbt_model"
12:51:55.999099 [debug] [Thread-1  ]: finished collecting timing info
12:51:55.999324 [debug] [Thread-1  ]: Began executing node model.demo_dbt.my_second_dbt_model
12:51:56.002431 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.my_second_dbt_model"
12:51:56.003364 [debug] [Thread-1  ]: Using snowflake connection "model.demo_dbt.my_second_dbt_model"
12:51:56.003567 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_second_dbt_model"} */

  create or replace  view my_database.warehouse.my_second_dbt_model
  
   as (
    -- Use the `ref` function to select from other models

select *
from my_database.warehouse.my_first_dbt_model
where id = 1
  );
12:51:56.003715 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:51:57.527890 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.52 seconds
12:51:57.530491 [debug] [Thread-1  ]: finished collecting timing info
12:51:57.530779 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: Close
12:51:58.020807 [info ] [Thread-1  ]: 5 of 5 OK created view model warehouse.my_second_dbt_model ..................... [[32mSUCCESS 1[0m in 2.03s]
12:51:58.021533 [debug] [Thread-1  ]: Finished running node model.demo_dbt.my_second_dbt_model
12:51:58.059104 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:51:58.059801 [info ] [MainThread]: 
12:51:58.060322 [info ] [MainThread]: Finished running 1 table model, 4 view models in 16.95s.
12:51:58.060834 [debug] [MainThread]: Connection 'master' was properly closed.
12:51:58.061223 [debug] [MainThread]: Connection 'model.demo_dbt.my_second_dbt_model' was properly closed.
12:51:58.120557 [info ] [MainThread]: 
12:51:58.120945 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
12:51:58.121305 [info ] [MainThread]: 
12:51:58.121622 [error] [MainThread]: [33mDatabase Error in model stg_eltool__orders (models/staging/stg_eltool__orders.sql)[0m
12:51:58.121914 [error] [MainThread]:   000904 (42000): SQL compilation error: error line 10 at position 8
12:51:58.122189 [error] [MainThread]:   invalid identifier 'CUST_ID'
12:51:58.122467 [error] [MainThread]:   compiled SQL at target/run/demo_dbt/models/staging/stg_eltool__orders.sql
12:51:58.122759 [info ] [MainThread]: 
12:51:58.123048 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5


============================== 2022-06-29 12:54:18.748828 | 1ea9f3e6-dbfe-4392-ae4a-87a1f4d635ce ==============================
12:54:18.748844 [info ] [MainThread]: Running with dbt=1.1.1
12:54:18.749807 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
12:54:18.750154 [debug] [MainThread]: Tracking: do not track
12:54:18.826295 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
12:54:18.826893 [debug] [MainThread]: Partial parsing: updated file: demo_dbt://models/staging/stg_eltool__orders.sql
12:54:18.842481 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
12:54:18.888176 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
12:54:18.890148 [info ] [MainThread]: 
12:54:18.890669 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:54:18.891742 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database"
12:54:18.908817 [debug] [ThreadPool]: Using snowflake connection "list_my_database"
12:54:18.909117 [debug] [ThreadPool]: On list_my_database: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database"} */

    show terse schemas in database my_database
    limit 10000
12:54:18.909329 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:54:20.614101 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1.7 seconds
12:54:20.616632 [debug] [ThreadPool]: On list_my_database: Close
12:54:21.088280 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database_snapshots"
12:54:21.100034 [debug] [ThreadPool]: Using snowflake connection "list_my_database_snapshots"
12:54:21.100310 [debug] [ThreadPool]: On list_my_database_snapshots: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database_snapshots"} */

    show terse objects in my_database.snapshots
12:54:21.100558 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:54:22.451638 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.35 seconds
12:54:22.453666 [debug] [ThreadPool]: On list_my_database_snapshots: Close
12:54:22.928231 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database_warehouse"
12:54:22.931244 [debug] [ThreadPool]: Using snowflake connection "list_my_database_warehouse"
12:54:22.931568 [debug] [ThreadPool]: On list_my_database_warehouse: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database_warehouse"} */

    show terse objects in my_database.warehouse
12:54:22.931779 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:54:24.708515 [debug] [ThreadPool]: SQL status: SUCCESS 7 in 1.78 seconds
12:54:24.711719 [debug] [ThreadPool]: On list_my_database_warehouse: Close
12:54:25.191682 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:54:25.192198 [info ] [MainThread]: 
12:54:25.196839 [debug] [Thread-1  ]: Began running node model.demo_dbt.my_first_dbt_model
12:54:25.197653 [info ] [Thread-1  ]: 1 of 5 START table model warehouse.my_first_dbt_model .......................... [RUN]
12:54:25.198739 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.my_first_dbt_model"
12:54:25.199033 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.my_first_dbt_model
12:54:25.199363 [debug] [Thread-1  ]: Compiling model.demo_dbt.my_first_dbt_model
12:54:25.203569 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.my_first_dbt_model"
12:54:25.204199 [debug] [Thread-1  ]: finished collecting timing info
12:54:25.204433 [debug] [Thread-1  ]: Began executing node model.demo_dbt.my_first_dbt_model
12:54:25.235423 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.my_first_dbt_model"
12:54:25.236591 [debug] [Thread-1  ]: Using snowflake connection "model.demo_dbt.my_first_dbt_model"
12:54:25.236773 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_first_dbt_model"} */


      create or replace transient table my_database.warehouse.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
12:54:25.236924 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:54:27.278614 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.04 seconds
12:54:27.293062 [debug] [Thread-1  ]: finished collecting timing info
12:54:27.293389 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: Close
12:54:27.808955 [info ] [Thread-1  ]: 1 of 5 OK created table model warehouse.my_first_dbt_model ..................... [[32mSUCCESS 1[0m in 2.61s]
12:54:27.809694 [debug] [Thread-1  ]: Finished running node model.demo_dbt.my_first_dbt_model
12:54:27.810039 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__customers
12:54:27.810376 [info ] [Thread-1  ]: 2 of 5 START view model warehouse.stg_eltool__customers ........................ [RUN]
12:54:27.811082 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.stg_eltool__customers"
12:54:27.811596 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__customers
12:54:27.811894 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__customers
12:54:27.815326 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__customers"
12:54:27.815909 [debug] [Thread-1  ]: finished collecting timing info
12:54:27.816123 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__customers
12:54:27.839210 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.stg_eltool__customers"
12:54:27.840675 [debug] [Thread-1  ]: Using snowflake connection "model.demo_dbt.stg_eltool__customers"
12:54:27.840869 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__customers"} */

  create or replace  view my_database.warehouse.stg_eltool__customers
  
   as (
    with source as (
    select *
    from my_database.snapshots.customers_snapshot
), renamed as (
    select customer_id,
        zipcode,
        city,
        state_code,
        datetime_created::TIMESTAMP AS datetime_created,
        datetime_updated::TIMESTAMP AS datetime_updated,
        dbt_valid_from,
        dbt_valid_to
    from source
)
select *
from renamed
  );
12:54:27.841018 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:54:29.479091 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.64 seconds
12:54:29.481244 [debug] [Thread-1  ]: finished collecting timing info
12:54:29.481531 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: Close
12:54:29.984776 [info ] [Thread-1  ]: 2 of 5 OK created view model warehouse.stg_eltool__customers ................... [[32mSUCCESS 1[0m in 2.17s]
12:54:29.985605 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__customers
12:54:29.985952 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__orders
12:54:29.986507 [info ] [Thread-1  ]: 3 of 5 START view model warehouse.stg_eltool__orders ........................... [RUN]
12:54:29.987253 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.stg_eltool__orders"
12:54:29.987515 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__orders
12:54:29.987747 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__orders
12:54:29.991157 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__orders"
12:54:29.991730 [debug] [Thread-1  ]: finished collecting timing info
12:54:29.991946 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__orders
12:54:29.994979 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.stg_eltool__orders"
12:54:29.996454 [debug] [Thread-1  ]: Using snowflake connection "model.demo_dbt.stg_eltool__orders"
12:54:29.996654 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__orders"} */

  create or replace  view my_database.warehouse.stg_eltool__orders
  
   as (
    with source as (
    select *
    from my_database.warehouse.orders
),
renamed as (
    select order_id,
        customer_id,
        order_status,
        order_purchase_timestamp::TIMESTAMP,
        order_approved_at::TIMESTAMP,
        order_delivered_carrier_date::TIMESTAMP,
        order_delivered_customer_date::TIMESTAMP,
        order_estimated_delivery_date::TIMESTAMP
        from source
)
select *
from renamed
  );
12:54:29.996855 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:54:31.627648 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.63 seconds
12:54:31.630254 [debug] [Thread-1  ]: finished collecting timing info
12:54:31.630542 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: Close
12:54:32.159989 [info ] [Thread-1  ]: 3 of 5 OK created view model warehouse.stg_eltool__orders ...................... [[32mSUCCESS 1[0m in 2.17s]
12:54:32.160713 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__orders
12:54:32.161099 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__state
12:54:32.161423 [info ] [Thread-1  ]: 4 of 5 START view model warehouse.stg_eltool__state ............................ [RUN]
12:54:32.162281 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.stg_eltool__state"
12:54:32.162530 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__state
12:54:32.162752 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__state
12:54:32.166004 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__state"
12:54:32.166549 [debug] [Thread-1  ]: finished collecting timing info
12:54:32.166753 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__state
12:54:32.170136 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.stg_eltool__state"
12:54:32.171400 [debug] [Thread-1  ]: Using snowflake connection "model.demo_dbt.stg_eltool__state"
12:54:32.171593 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__state"} */

  create or replace  view my_database.warehouse.stg_eltool__state
  
   as (
    with source as (
    select *
    from my_database.warehouse.state
),
renamed as (
    select state_identifier::INT AS state_id,
        state_code::VARCHAR(2) AS state_code,
        st_name::VARCHAR(30) AS state_name
    from source
)
select *
from renamed
  );
12:54:32.171762 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:54:33.719094 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.55 seconds
12:54:33.721879 [debug] [Thread-1  ]: finished collecting timing info
12:54:33.722185 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: Close
12:54:34.246677 [info ] [Thread-1  ]: 4 of 5 OK created view model warehouse.stg_eltool__state ....................... [[32mSUCCESS 1[0m in 2.08s]
12:54:34.247674 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__state
12:54:34.248152 [debug] [Thread-1  ]: Began running node model.demo_dbt.my_second_dbt_model
12:54:34.248727 [info ] [Thread-1  ]: 5 of 5 START view model warehouse.my_second_dbt_model .......................... [RUN]
12:54:34.249678 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.my_second_dbt_model"
12:54:34.249950 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.my_second_dbt_model
12:54:34.250184 [debug] [Thread-1  ]: Compiling model.demo_dbt.my_second_dbt_model
12:54:34.253226 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.my_second_dbt_model"
12:54:34.253834 [debug] [Thread-1  ]: finished collecting timing info
12:54:34.254117 [debug] [Thread-1  ]: Began executing node model.demo_dbt.my_second_dbt_model
12:54:34.257152 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.my_second_dbt_model"
12:54:34.258153 [debug] [Thread-1  ]: Using snowflake connection "model.demo_dbt.my_second_dbt_model"
12:54:34.258366 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_second_dbt_model"} */

  create or replace  view my_database.warehouse.my_second_dbt_model
  
   as (
    -- Use the `ref` function to select from other models

select *
from my_database.warehouse.my_first_dbt_model
where id = 1
  );
12:54:34.258538 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:54:35.903206 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.64 seconds
12:54:35.905625 [debug] [Thread-1  ]: finished collecting timing info
12:54:35.905903 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: Close
12:54:36.381254 [info ] [Thread-1  ]: 5 of 5 OK created view model warehouse.my_second_dbt_model ..................... [[32mSUCCESS 1[0m in 2.13s]
12:54:36.382210 [debug] [Thread-1  ]: Finished running node model.demo_dbt.my_second_dbt_model
12:54:36.418787 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:54:36.419546 [info ] [MainThread]: 
12:54:36.419988 [info ] [MainThread]: Finished running 1 table model, 4 view models in 17.53s.
12:54:36.420380 [debug] [MainThread]: Connection 'master' was properly closed.
12:54:36.420597 [debug] [MainThread]: Connection 'model.demo_dbt.my_second_dbt_model' was properly closed.
12:54:36.428804 [info ] [MainThread]: 
12:54:36.429239 [info ] [MainThread]: [32mCompleted successfully[0m
12:54:36.429653 [info ] [MainThread]: 
12:54:36.429973 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5


============================== 2022-06-29 12:59:46.100462 | ee09fdd4-f3b0-428c-a531-813f0e74acbb ==============================
12:59:46.100478 [info ] [MainThread]: Running with dbt=1.1.1
12:59:46.113281 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'indirect_selection': 'eager', 'which': 'test', 'rpc_method': 'test'}
12:59:46.113661 [debug] [MainThread]: Tracking: do not track
12:59:46.195288 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
12:59:46.195671 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
12:59:46.215774 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
12:59:46.218477 [info ] [MainThread]: 
12:59:46.219551 [debug] [MainThread]: Acquiring new snowflake connection "master"
12:59:46.223518 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database_warehouse"
12:59:46.244721 [debug] [ThreadPool]: Using snowflake connection "list_my_database_warehouse"
12:59:46.245057 [debug] [ThreadPool]: On list_my_database_warehouse: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database_warehouse"} */

    show terse objects in my_database.warehouse
12:59:46.245288 [debug] [ThreadPool]: Opening a new connection, currently in state init
12:59:48.330011 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 2.08 seconds
12:59:48.333135 [debug] [ThreadPool]: On list_my_database_warehouse: Close
12:59:48.831657 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database_snapshots"
12:59:48.835127 [debug] [ThreadPool]: Using snowflake connection "list_my_database_snapshots"
12:59:48.835415 [debug] [ThreadPool]: On list_my_database_snapshots: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database_snapshots"} */

    show terse objects in my_database.snapshots
12:59:48.835597 [debug] [ThreadPool]: Opening a new connection, currently in state closed
12:59:50.378052 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.54 seconds
12:59:50.380296 [debug] [ThreadPool]: On list_my_database_snapshots: Close
12:59:50.842558 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
12:59:50.843083 [info ] [MainThread]: 
12:59:50.846569 [debug] [Thread-1  ]: Began running node test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:59:50.846938 [info ] [Thread-1  ]: 1 of 9 START test not_null_my_first_dbt_model_id ............................... [RUN]
12:59:50.847987 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
12:59:50.848279 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:59:50.848524 [debug] [Thread-1  ]: Compiling test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:59:50.867606 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
12:59:50.894003 [debug] [Thread-1  ]: finished collecting timing info
12:59:50.894492 [debug] [Thread-1  ]: Began executing node test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:59:50.917332 [debug] [Thread-1  ]: Writing runtime SQL for node "test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
12:59:50.918490 [debug] [Thread-1  ]: Using snowflake connection "test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
12:59:50.918718 [debug] [Thread-1  ]: On test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from my_database.warehouse.my_first_dbt_model
where id is null



      
    ) dbt_internal_test
12:59:50.918880 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:59:52.420165 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.5 seconds
12:59:52.424084 [debug] [Thread-1  ]: finished collecting timing info
12:59:52.424432 [debug] [Thread-1  ]: On test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710: Close
12:59:52.967705 [error] [Thread-1  ]: 1 of 9 FAIL 1 not_null_my_first_dbt_model_id ................................... [[31mFAIL 1[0m in 2.12s]
12:59:52.968845 [debug] [Thread-1  ]: Finished running node test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710
12:59:52.969447 [debug] [Thread-1  ]: Began running node test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778
12:59:52.970070 [info ] [Thread-1  ]: 2 of 9 START test not_null_my_second_dbt_model_id .............................. [RUN]
12:59:52.971237 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778"
12:59:52.971626 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778
12:59:52.971944 [debug] [Thread-1  ]: Compiling test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778
12:59:52.977897 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778"
12:59:52.978559 [debug] [Thread-1  ]: finished collecting timing info
12:59:52.978785 [debug] [Thread-1  ]: Began executing node test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778
12:59:52.980722 [debug] [Thread-1  ]: Writing runtime SQL for node "test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778"
12:59:52.981822 [debug] [Thread-1  ]: Using snowflake connection "test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778"
12:59:52.982005 [debug] [Thread-1  ]: On test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select id
from my_database.warehouse.my_second_dbt_model
where id is null



      
    ) dbt_internal_test
12:59:52.982155 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:59:54.468156 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.49 seconds
12:59:54.470882 [debug] [Thread-1  ]: finished collecting timing info
12:59:54.471251 [debug] [Thread-1  ]: On test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778: Close
12:59:54.949787 [info ] [Thread-1  ]: 2 of 9 PASS not_null_my_second_dbt_model_id .................................... [[32mPASS[0m in 1.98s]
12:59:54.950908 [debug] [Thread-1  ]: Finished running node test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778
12:59:54.951288 [debug] [Thread-1  ]: Began running node test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df
12:59:54.951683 [info ] [Thread-1  ]: 3 of 9 START test not_null_stg_eltool__customers_customer_id ................... [RUN]
12:59:54.952490 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df"
12:59:54.952775 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df
12:59:54.953018 [debug] [Thread-1  ]: Compiling test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df
12:59:54.960366 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df"
12:59:54.961912 [debug] [Thread-1  ]: finished collecting timing info
12:59:54.962393 [debug] [Thread-1  ]: Began executing node test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df
12:59:54.965971 [debug] [Thread-1  ]: Writing runtime SQL for node "test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df"
12:59:54.967191 [debug] [Thread-1  ]: Using snowflake connection "test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df"
12:59:54.967423 [debug] [Thread-1  ]: On test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customer_id
from my_database.warehouse.stg_eltool__customers
where customer_id is null



      
    ) dbt_internal_test
12:59:54.967618 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:59:56.455288 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.49 seconds
12:59:56.458271 [debug] [Thread-1  ]: finished collecting timing info
12:59:56.458619 [debug] [Thread-1  ]: On test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df: Close
12:59:56.941209 [info ] [Thread-1  ]: 3 of 9 PASS not_null_stg_eltool__customers_customer_id ......................... [[32mPASS[0m in 1.99s]
12:59:56.942121 [debug] [Thread-1  ]: Finished running node test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df
12:59:56.942550 [debug] [Thread-1  ]: Began running node test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6
12:59:56.943231 [info ] [Thread-1  ]: 4 of 9 START test source_not_null_warehouse_customers_customer_id .............. [RUN]
12:59:56.944181 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6"
12:59:56.944511 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6
12:59:56.944756 [debug] [Thread-1  ]: Compiling test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6
12:59:56.951034 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6"
12:59:56.951917 [debug] [Thread-1  ]: finished collecting timing info
12:59:56.952273 [debug] [Thread-1  ]: Began executing node test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6
12:59:56.955274 [debug] [Thread-1  ]: Writing runtime SQL for node "test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6"
12:59:56.956820 [debug] [Thread-1  ]: Using snowflake connection "test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6"
12:59:56.957219 [debug] [Thread-1  ]: On test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customer_id
from my_database.warehouse.customers
where customer_id is null



      
    ) dbt_internal_test
12:59:56.957503 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
12:59:58.464581 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.51 seconds
12:59:58.467306 [debug] [Thread-1  ]: finished collecting timing info
12:59:58.467582 [debug] [Thread-1  ]: On test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6: Close
12:59:58.957747 [info ] [Thread-1  ]: 4 of 9 PASS source_not_null_warehouse_customers_customer_id .................... [[32mPASS[0m in 2.01s]
12:59:58.958629 [debug] [Thread-1  ]: Finished running node test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6
12:59:58.959027 [debug] [Thread-1  ]: Began running node test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76
12:59:58.959372 [info ] [Thread-1  ]: 5 of 9 START test source_not_null_warehouse_orders_order_id .................... [RUN]
12:59:58.960246 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76"
12:59:58.960720 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76
12:59:58.961076 [debug] [Thread-1  ]: Compiling test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76
12:59:58.967438 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76"
12:59:58.968249 [debug] [Thread-1  ]: finished collecting timing info
12:59:58.968952 [debug] [Thread-1  ]: Began executing node test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76
12:59:58.971336 [debug] [Thread-1  ]: Writing runtime SQL for node "test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76"
12:59:58.972943 [debug] [Thread-1  ]: Using snowflake connection "test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76"
12:59:58.973219 [debug] [Thread-1  ]: On test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from my_database.warehouse.orders
where order_id is null



      
    ) dbt_internal_test
12:59:58.973373 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:00:00.875484 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.9 seconds
13:00:00.877853 [debug] [Thread-1  ]: finished collecting timing info
13:00:00.878175 [debug] [Thread-1  ]: On test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76: Close
13:00:01.354338 [info ] [Thread-1  ]: 5 of 9 PASS source_not_null_warehouse_orders_order_id .......................... [[32mPASS[0m in 2.39s]
13:00:01.355278 [debug] [Thread-1  ]: Finished running node test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76
13:00:01.355680 [debug] [Thread-1  ]: Began running node test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2
13:00:01.356094 [info ] [Thread-1  ]: 6 of 9 START test source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_  [RUN]
13:00:01.356919 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2"
13:00:01.357176 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2
13:00:01.357406 [debug] [Thread-1  ]: Compiling test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2
13:00:01.371849 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2"
13:00:01.373608 [debug] [Thread-1  ]: finished collecting timing info
13:00:01.374236 [debug] [Thread-1  ]: Began executing node test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2
13:00:01.376372 [debug] [Thread-1  ]: Writing runtime SQL for node "test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2"
13:00:01.377819 [debug] [Thread-1  ]: Using snowflake connection "test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2"
13:00:01.378024 [debug] [Thread-1  ]: On test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with child as (
    select cust_id as from_field
    from my_database.warehouse.orders
    where cust_id is not null
),

parent as (
    select customer_id as to_field
    from my_database.warehouse.customers
)

select
    from_field

from child
left join parent
    on child.from_field = parent.to_field

where parent.to_field is null



      
    ) dbt_internal_test
13:00:01.378173 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:00:02.931476 [debug] [Thread-1  ]: Snowflake adapter: Snowflake query id: 01a5458c-0004-250b-0000-00144507a2d9
13:00:02.931832 [debug] [Thread-1  ]: Snowflake adapter: Snowflake error: 000904 (42000): SQL compilation error: error line 11 at position 11
invalid identifier 'CUST_ID'
13:00:02.932267 [debug] [Thread-1  ]: finished collecting timing info
13:00:02.932542 [debug] [Thread-1  ]: On test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2: Close
13:00:03.414811 [debug] [Thread-1  ]: Database Error in test source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_ (models/staging/src_eltool.yml)
  000904 (42000): SQL compilation error: error line 11 at position 11
  invalid identifier 'CUST_ID'
  compiled SQL at target/run/demo_dbt/models/staging/src_eltool.yml/source_relationships_warehouse_46417174c201e9fe9fa0261bf38778e0.sql
13:00:03.415398 [error] [Thread-1  ]: 6 of 9 ERROR source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_  [[31mERROR[0m in 2.06s]
13:00:03.416322 [debug] [Thread-1  ]: Finished running node test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2
13:00:03.416721 [debug] [Thread-1  ]: Began running node test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f
13:00:03.417107 [info ] [Thread-1  ]: 7 of 9 START test source_unique_warehouse_orders_order_id ...................... [RUN]
13:00:03.417888 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f"
13:00:03.418093 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f
13:00:03.418279 [debug] [Thread-1  ]: Compiling test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f
13:00:03.482048 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f"
13:00:03.482688 [debug] [Thread-1  ]: finished collecting timing info
13:00:03.482893 [debug] [Thread-1  ]: Began executing node test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f
13:00:03.484777 [debug] [Thread-1  ]: Writing runtime SQL for node "test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f"
13:00:03.485777 [debug] [Thread-1  ]: Using snowflake connection "test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f"
13:00:03.485943 [debug] [Thread-1  ]: On test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    order_id as unique_field,
    count(*) as n_records

from my_database.warehouse.orders
where order_id is not null
group by order_id
having count(*) > 1



      
    ) dbt_internal_test
13:00:03.486087 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:00:05.215599 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.73 seconds
13:00:05.218076 [debug] [Thread-1  ]: finished collecting timing info
13:00:05.218441 [debug] [Thread-1  ]: On test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f: Close
13:00:05.748912 [info ] [Thread-1  ]: 7 of 9 PASS source_unique_warehouse_orders_order_id ............................ [[32mPASS[0m in 2.33s]
13:00:05.749942 [debug] [Thread-1  ]: Finished running node test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f
13:00:05.750353 [debug] [Thread-1  ]: Began running node test.demo_dbt.unique_my_first_dbt_model_id.16e066b321
13:00:05.750574 [info ] [Thread-1  ]: 8 of 9 START test unique_my_first_dbt_model_id ................................. [RUN]
13:00:05.751349 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.demo_dbt.unique_my_first_dbt_model_id.16e066b321"
13:00:05.751724 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.unique_my_first_dbt_model_id.16e066b321
13:00:05.751954 [debug] [Thread-1  ]: Compiling test.demo_dbt.unique_my_first_dbt_model_id.16e066b321
13:00:05.757493 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.unique_my_first_dbt_model_id.16e066b321"
13:00:05.758089 [debug] [Thread-1  ]: finished collecting timing info
13:00:05.758279 [debug] [Thread-1  ]: Began executing node test.demo_dbt.unique_my_first_dbt_model_id.16e066b321
13:00:05.759986 [debug] [Thread-1  ]: Writing runtime SQL for node "test.demo_dbt.unique_my_first_dbt_model_id.16e066b321"
13:00:05.760969 [debug] [Thread-1  ]: Using snowflake connection "test.demo_dbt.unique_my_first_dbt_model_id.16e066b321"
13:00:05.761141 [debug] [Thread-1  ]: On test.demo_dbt.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "test.demo_dbt.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from my_database.warehouse.my_first_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:00:05.761290 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:00:07.270044 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.51 seconds
13:00:07.272582 [debug] [Thread-1  ]: finished collecting timing info
13:00:07.272875 [debug] [Thread-1  ]: On test.demo_dbt.unique_my_first_dbt_model_id.16e066b321: Close
13:00:07.908810 [info ] [Thread-1  ]: 8 of 9 PASS unique_my_first_dbt_model_id ....................................... [[32mPASS[0m in 2.16s]
13:00:07.909656 [debug] [Thread-1  ]: Finished running node test.demo_dbt.unique_my_first_dbt_model_id.16e066b321
13:00:07.910172 [debug] [Thread-1  ]: Began running node test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:00:07.910860 [info ] [Thread-1  ]: 9 of 9 START test unique_my_second_dbt_model_id ................................ [RUN]
13:00:07.911804 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:00:07.912056 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:00:07.912285 [debug] [Thread-1  ]: Compiling test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:00:07.917682 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:00:07.918333 [debug] [Thread-1  ]: finished collecting timing info
13:00:07.918579 [debug] [Thread-1  ]: Began executing node test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:00:07.921015 [debug] [Thread-1  ]: Writing runtime SQL for node "test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:00:07.922251 [debug] [Thread-1  ]: Using snowflake connection "test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:00:07.922434 [debug] [Thread-1  ]: On test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from my_database.warehouse.my_second_dbt_model
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
13:00:07.922587 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:00:09.580610 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.66 seconds
13:00:09.583065 [debug] [Thread-1  ]: finished collecting timing info
13:00:09.583435 [debug] [Thread-1  ]: On test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493: Close
13:00:10.093889 [info ] [Thread-1  ]: 9 of 9 PASS unique_my_second_dbt_model_id ...................................... [[32mPASS[0m in 2.18s]
13:00:10.094637 [debug] [Thread-1  ]: Finished running node test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:00:10.109071 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:00:10.109777 [info ] [MainThread]: 
13:00:10.110282 [info ] [MainThread]: Finished running 9 tests in 23.89s.
13:00:10.110816 [debug] [MainThread]: Connection 'master' was properly closed.
13:00:10.111120 [debug] [MainThread]: Connection 'test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
13:00:10.121073 [info ] [MainThread]: 
13:00:10.121937 [info ] [MainThread]: [31mCompleted with 2 errors and 0 warnings:[0m
13:00:10.122623 [info ] [MainThread]: 
13:00:10.123088 [error] [MainThread]: [31mFailure in test not_null_my_first_dbt_model_id (models/example/schema.yml)[0m
13:00:10.123553 [error] [MainThread]:   Got 1 result, configured to fail if != 0
13:00:10.124123 [info ] [MainThread]: 
13:00:10.124713 [info ] [MainThread]:   compiled SQL at target/compiled/demo_dbt/models/example/schema.yml/not_null_my_first_dbt_model_id.sql
13:00:10.125318 [info ] [MainThread]: 
13:00:10.125908 [error] [MainThread]: [33mDatabase Error in test source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_ (models/staging/src_eltool.yml)[0m
13:00:10.126470 [error] [MainThread]:   000904 (42000): SQL compilation error: error line 11 at position 11
13:00:10.127026 [error] [MainThread]:   invalid identifier 'CUST_ID'
13:00:10.127565 [error] [MainThread]:   compiled SQL at target/run/demo_dbt/models/staging/src_eltool.yml/source_relationships_warehouse_46417174c201e9fe9fa0261bf38778e0.sql
13:00:10.127946 [info ] [MainThread]: 
13:00:10.128522 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=2 SKIP=0 TOTAL=9


============================== 2022-06-29 13:06:55.561650 | f901432b-5abd-4fc3-91ed-2fbf0a9028b3 ==============================
13:06:55.561666 [info ] [MainThread]: Running with dbt=1.1.1
13:06:55.562585 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
13:06:55.563083 [debug] [MainThread]: Tracking: do not track
13:06:55.637756 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
13:06:55.638040 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
13:06:55.655192 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
13:06:55.657542 [info ] [MainThread]: 
13:06:55.658561 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:06:55.659953 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database"
13:06:55.681779 [debug] [ThreadPool]: Using snowflake connection "list_my_database"
13:06:55.682356 [debug] [ThreadPool]: On list_my_database: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database"} */

    show terse schemas in database my_database
    limit 10000
13:06:55.682812 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:06:57.488317 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1.81 seconds
13:06:57.491753 [debug] [ThreadPool]: On list_my_database: Close
13:06:57.965897 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database_snapshots"
13:06:57.975539 [debug] [ThreadPool]: Using snowflake connection "list_my_database_snapshots"
13:06:57.975804 [debug] [ThreadPool]: On list_my_database_snapshots: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database_snapshots"} */

    show terse objects in my_database.snapshots
13:06:57.975978 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:06:59.384262 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.41 seconds
13:06:59.386550 [debug] [ThreadPool]: On list_my_database_snapshots: Close
13:06:59.879863 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database_warehouse"
13:06:59.882570 [debug] [ThreadPool]: Using snowflake connection "list_my_database_warehouse"
13:06:59.882835 [debug] [ThreadPool]: On list_my_database_warehouse: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database_warehouse"} */

    show terse objects in my_database.warehouse
13:06:59.883041 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:07:01.583519 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1.7 seconds
13:07:01.586148 [debug] [ThreadPool]: On list_my_database_warehouse: Close
13:07:02.048833 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:07:02.049341 [info ] [MainThread]: 
13:07:02.052602 [debug] [Thread-1  ]: Began running node snapshot.demo_dbt.customers_snapshot
13:07:02.053082 [info ] [Thread-1  ]: 1 of 1 START snapshot snapshots.customers_snapshot ............................. [RUN]
13:07:02.053768 [debug] [Thread-1  ]: Acquiring new snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:07:02.054011 [debug] [Thread-1  ]: Began compiling node snapshot.demo_dbt.customers_snapshot
13:07:02.054248 [debug] [Thread-1  ]: Compiling snapshot.demo_dbt.customers_snapshot
13:07:02.058496 [debug] [Thread-1  ]: finished collecting timing info
13:07:02.058763 [debug] [Thread-1  ]: Began executing node snapshot.demo_dbt.customers_snapshot
13:07:02.125040 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:07:02.125286 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

    describe table "MY_DATABASE"."SNAPSHOTS"."CUSTOMERS_SNAPSHOT"
13:07:02.125475 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:07:03.714126 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 1.59 seconds
13:07:03.756811 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:07:03.757059 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

        

      create or replace temporary table "MY_DATABASE"."SNAPSHOTS"."CUSTOMERS_SNAPSHOT__dbt_tmp"  as
      (with snapshot_query as (

        



select * from my_database.warehouse.customers


    ),

    snapshotted_data as (

        select *,
            customer_id as dbt_unique_key

        from "MY_DATABASE"."SNAPSHOTS"."CUSTOMERS_SNAPSHOT"
        where dbt_valid_to is null

    ),

    insertions_source_data as (

        select
            *,
            customer_id as dbt_unique_key,
            datetime_updated as dbt_updated_at,
            datetime_updated as dbt_valid_from,
            nullif(datetime_updated, datetime_updated) as dbt_valid_to,
            md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(datetime_updated as varchar ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select
            *,
            customer_id as dbt_unique_key,
            datetime_updated as dbt_updated_at,
            datetime_updated as dbt_valid_from,
            datetime_updated as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where snapshotted_data.dbt_unique_key is null
           or (
                snapshotted_data.dbt_unique_key is not null
            and (
                (snapshotted_data.dbt_valid_from < source_data.datetime_updated)
            )
        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where (
            (snapshotted_data.dbt_valid_from < source_data.datetime_updated)
        )
    )

    select * from insertions
    union all
    select * from updates

      );
13:07:04.756687 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.0 seconds
13:07:04.760838 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:07:04.761107 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

    describe table "MY_DATABASE"."SNAPSHOTS"."CUSTOMERS_SNAPSHOT__dbt_tmp"
13:07:05.055705 [debug] [Thread-1  ]: SQL status: SUCCESS 12 in 0.29 seconds
13:07:05.061222 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:07:05.061462 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

    describe table "MY_DATABASE"."SNAPSHOTS"."CUSTOMERS_SNAPSHOT"
13:07:05.313726 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.25 seconds
13:07:05.320608 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:07:05.321064 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

    describe table "MY_DATABASE"."SNAPSHOTS"."CUSTOMERS_SNAPSHOT__dbt_tmp"
13:07:05.577157 [debug] [Thread-1  ]: SQL status: SUCCESS 12 in 0.26 seconds
13:07:05.582799 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:07:05.583080 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

    describe table "MY_DATABASE"."SNAPSHOTS"."CUSTOMERS_SNAPSHOT"
13:07:05.840268 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.26 seconds
13:07:05.851591 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:07:05.851883 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

    describe table "MY_DATABASE"."SNAPSHOTS"."CUSTOMERS_SNAPSHOT__dbt_tmp"
13:07:06.103914 [debug] [Thread-1  ]: SQL status: SUCCESS 12 in 0.25 seconds
13:07:06.117084 [debug] [Thread-1  ]: Writing runtime SQL for node "snapshot.demo_dbt.customers_snapshot"
13:07:06.118532 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:07:06.118709 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

      begin;
13:07:06.400250 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.28 seconds
13:07:06.400750 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:07:06.401018 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: merge into "MY_DATABASE"."SNAPSHOTS"."CUSTOMERS_SNAPSHOT" as DBT_INTERNAL_DEST
    using "MY_DATABASE"."SNAPSHOTS"."CUSTOMERS_SNAPSHOT__dbt_tmp" as DBT_INTERNAL_SOURCE
    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id

    when matched
     and DBT_INTERNAL_DEST.dbt_valid_to is null
     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')
        then update
        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to

    when not matched
     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'
        then insert ("CUSTOMER_ID", "ZIPCODE", "CITY", "STATE_CODE", "DATETIME_CREATED", "DATETIME_UPDATED", "DBT_UPDATED_AT", "DBT_VALID_FROM", "DBT_VALID_TO", "DBT_SCD_ID")
        values ("CUSTOMER_ID", "ZIPCODE", "CITY", "STATE_CODE", "DATETIME_CREATED", "DATETIME_UPDATED", "DBT_UPDATED_AT", "DBT_VALID_FROM", "DBT_VALID_TO", "DBT_SCD_ID")

;
13:07:07.347317 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.95 seconds
13:07:07.347741 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:07:07.348011 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: commit;
13:07:07.742865 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.39 seconds
13:07:07.761000 [debug] [Thread-1  ]: finished collecting timing info
13:07:07.761316 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: Close
13:07:08.257387 [info ] [Thread-1  ]: 1 of 1 OK snapshotted snapshots.customers_snapshot ............................. [[32mSUCCESS 1[0m in 6.20s]
13:07:08.258216 [debug] [Thread-1  ]: Finished running node snapshot.demo_dbt.customers_snapshot
13:07:08.311185 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:07:08.311705 [info ] [MainThread]: 
13:07:08.312063 [info ] [MainThread]: Finished running 1 snapshot in 12.65s.
13:07:08.312346 [debug] [MainThread]: Connection 'master' was properly closed.
13:07:08.312493 [debug] [MainThread]: Connection 'snapshot.demo_dbt.customers_snapshot' was properly closed.
13:07:08.322291 [info ] [MainThread]: 
13:07:08.322866 [info ] [MainThread]: [32mCompleted successfully[0m
13:07:08.323383 [info ] [MainThread]: 
13:07:08.323960 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1


============================== 2022-06-29 13:07:49.982318 | b7997dc3-9724-4a0d-97f0-f8154f1e16f4 ==============================
13:07:49.982336 [info ] [MainThread]: Running with dbt=1.1.1
13:07:49.983313 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
13:07:49.983632 [debug] [MainThread]: Tracking: do not track
13:07:50.068723 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
13:07:50.068994 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
13:07:50.085491 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
13:07:50.088115 [info ] [MainThread]: 
13:07:50.088921 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:07:50.090820 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database"
13:07:50.109164 [debug] [ThreadPool]: Using snowflake connection "list_my_database"
13:07:50.109418 [debug] [ThreadPool]: On list_my_database: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database"} */

    show terse schemas in database my_database
    limit 10000
13:07:50.109577 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:07:51.850910 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 1.74 seconds
13:07:51.853662 [debug] [ThreadPool]: On list_my_database: Close
13:07:52.332682 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database_snapshots"
13:07:52.341468 [debug] [ThreadPool]: Using snowflake connection "list_my_database_snapshots"
13:07:52.341722 [debug] [ThreadPool]: On list_my_database_snapshots: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database_snapshots"} */

    show terse objects in my_database.snapshots
13:07:52.341894 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:07:53.901964 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.56 seconds
13:07:53.904230 [debug] [ThreadPool]: On list_my_database_snapshots: Close
13:07:54.457663 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database_warehouse"
13:07:54.461136 [debug] [ThreadPool]: Using snowflake connection "list_my_database_warehouse"
13:07:54.461446 [debug] [ThreadPool]: On list_my_database_warehouse: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database_warehouse"} */

    show terse objects in my_database.warehouse
13:07:54.461660 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:07:55.905787 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1.44 seconds
13:07:55.908405 [debug] [ThreadPool]: On list_my_database_warehouse: Close
13:07:56.402699 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:07:56.403208 [info ] [MainThread]: 
13:07:56.407123 [debug] [Thread-1  ]: Began running node model.demo_dbt.my_first_dbt_model
13:07:56.407588 [info ] [Thread-1  ]: 1 of 5 START table model warehouse.my_first_dbt_model .......................... [RUN]
13:07:56.408263 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.my_first_dbt_model"
13:07:56.408514 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.my_first_dbt_model
13:07:56.408755 [debug] [Thread-1  ]: Compiling model.demo_dbt.my_first_dbt_model
13:07:56.412204 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.my_first_dbt_model"
13:07:56.412780 [debug] [Thread-1  ]: finished collecting timing info
13:07:56.412995 [debug] [Thread-1  ]: Began executing node model.demo_dbt.my_first_dbt_model
13:07:56.443862 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.my_first_dbt_model"
13:07:56.445010 [debug] [Thread-1  ]: Using snowflake connection "model.demo_dbt.my_first_dbt_model"
13:07:56.445197 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_first_dbt_model"} */


      create or replace transient table my_database.warehouse.my_first_dbt_model  as
      (/*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
      );
13:07:56.445344 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:07:58.223022 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.78 seconds
13:07:58.238440 [debug] [Thread-1  ]: finished collecting timing info
13:07:58.238777 [debug] [Thread-1  ]: On model.demo_dbt.my_first_dbt_model: Close
13:07:58.710159 [info ] [Thread-1  ]: 1 of 5 OK created table model warehouse.my_first_dbt_model ..................... [[32mSUCCESS 1[0m in 2.30s]
13:07:58.710749 [debug] [Thread-1  ]: Finished running node model.demo_dbt.my_first_dbt_model
13:07:58.711094 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__customers
13:07:58.711347 [info ] [Thread-1  ]: 2 of 5 START view model warehouse.stg_eltool__customers ........................ [RUN]
13:07:58.711816 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.stg_eltool__customers"
13:07:58.711984 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__customers
13:07:58.712143 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__customers
13:07:58.714969 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__customers"
13:07:58.715646 [debug] [Thread-1  ]: finished collecting timing info
13:07:58.715839 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__customers
13:07:58.737175 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.stg_eltool__customers"
13:07:58.738559 [debug] [Thread-1  ]: Using snowflake connection "model.demo_dbt.stg_eltool__customers"
13:07:58.738765 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__customers"} */

  create or replace  view my_database.warehouse.stg_eltool__customers
  
   as (
    with source as (
    select *
    from my_database.snapshots.customers_snapshot
), renamed as (
    select customer_id,
        zipcode,
        city,
        state_code,
        datetime_created::TIMESTAMP AS datetime_created,
        datetime_updated::TIMESTAMP AS datetime_updated,
        dbt_valid_from,
        dbt_valid_to
    from source
)
select *
from renamed
  );
13:07:58.738916 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:08:00.173322 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.43 seconds
13:08:00.175860 [debug] [Thread-1  ]: finished collecting timing info
13:08:00.176140 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__customers: Close
13:08:00.653725 [info ] [Thread-1  ]: 2 of 5 OK created view model warehouse.stg_eltool__customers ................... [[32mSUCCESS 1[0m in 1.94s]
13:08:00.654446 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__customers
13:08:00.654751 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__orders
13:08:00.655076 [info ] [Thread-1  ]: 3 of 5 START view model warehouse.stg_eltool__orders ........................... [RUN]
13:08:00.655689 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.stg_eltool__orders"
13:08:00.656028 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__orders
13:08:00.656285 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__orders
13:08:00.659574 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__orders"
13:08:00.660168 [debug] [Thread-1  ]: finished collecting timing info
13:08:00.660379 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__orders
13:08:00.663382 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.stg_eltool__orders"
13:08:00.665253 [debug] [Thread-1  ]: Using snowflake connection "model.demo_dbt.stg_eltool__orders"
13:08:00.665486 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__orders"} */

  create or replace  view my_database.warehouse.stg_eltool__orders
  
   as (
    with source as (
    select *
    from my_database.warehouse.orders
),
renamed as (
    select order_id,
        customer_id,
        order_status,
        order_purchase_timestamp::TIMESTAMP,
        order_approved_at::TIMESTAMP,
        order_delivered_carrier_date::TIMESTAMP,
        order_delivered_customer_date::TIMESTAMP,
        order_estimated_delivery_date::TIMESTAMP
        from source
)
select *
from renamed
  );
13:08:00.665661 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:08:02.523388 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.86 seconds
13:08:02.527932 [debug] [Thread-1  ]: finished collecting timing info
13:08:02.528524 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__orders: Close
13:08:03.000897 [info ] [Thread-1  ]: 3 of 5 OK created view model warehouse.stg_eltool__orders ...................... [[32mSUCCESS 1[0m in 2.35s]
13:08:03.001621 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__orders
13:08:03.001962 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__state
13:08:03.002299 [info ] [Thread-1  ]: 4 of 5 START view model warehouse.stg_eltool__state ............................ [RUN]
13:08:03.002996 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.stg_eltool__state"
13:08:03.003329 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__state
13:08:03.003567 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__state
13:08:03.006243 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__state"
13:08:03.006777 [debug] [Thread-1  ]: finished collecting timing info
13:08:03.006982 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__state
13:08:03.010020 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.stg_eltool__state"
13:08:03.011216 [debug] [Thread-1  ]: Using snowflake connection "model.demo_dbt.stg_eltool__state"
13:08:03.011412 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.stg_eltool__state"} */

  create or replace  view my_database.warehouse.stg_eltool__state
  
   as (
    with source as (
    select *
    from my_database.warehouse.state
),
renamed as (
    select state_identifier::INT AS state_id,
        state_code::VARCHAR(2) AS state_code,
        st_name::VARCHAR(30) AS state_name
    from source
)
select *
from renamed
  );
13:08:03.011576 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:08:04.760893 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.75 seconds
13:08:04.763750 [debug] [Thread-1  ]: finished collecting timing info
13:08:04.764075 [debug] [Thread-1  ]: On model.demo_dbt.stg_eltool__state: Close
13:08:05.255768 [info ] [Thread-1  ]: 4 of 5 OK created view model warehouse.stg_eltool__state ....................... [[32mSUCCESS 1[0m in 2.25s]
13:08:05.256824 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__state
13:08:05.257198 [debug] [Thread-1  ]: Began running node model.demo_dbt.my_second_dbt_model
13:08:05.257852 [info ] [Thread-1  ]: 5 of 5 START view model warehouse.my_second_dbt_model .......................... [RUN]
13:08:05.258914 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.my_second_dbt_model"
13:08:05.259176 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.my_second_dbt_model
13:08:05.259426 [debug] [Thread-1  ]: Compiling model.demo_dbt.my_second_dbt_model
13:08:05.262912 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.my_second_dbt_model"
13:08:05.263501 [debug] [Thread-1  ]: finished collecting timing info
13:08:05.263709 [debug] [Thread-1  ]: Began executing node model.demo_dbt.my_second_dbt_model
13:08:05.266476 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt.my_second_dbt_model"
13:08:05.267301 [debug] [Thread-1  ]: Using snowflake connection "model.demo_dbt.my_second_dbt_model"
13:08:05.267474 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "model.demo_dbt.my_second_dbt_model"} */

  create or replace  view my_database.warehouse.my_second_dbt_model
  
   as (
    -- Use the `ref` function to select from other models

select *
from my_database.warehouse.my_first_dbt_model
where id = 1
  );
13:08:05.267617 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:08:06.968671 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.7 seconds
13:08:06.971267 [debug] [Thread-1  ]: finished collecting timing info
13:08:06.971544 [debug] [Thread-1  ]: On model.demo_dbt.my_second_dbt_model: Close
13:08:07.452235 [info ] [Thread-1  ]: 5 of 5 OK created view model warehouse.my_second_dbt_model ..................... [[32mSUCCESS 1[0m in 2.19s]
13:08:07.452975 [debug] [Thread-1  ]: Finished running node model.demo_dbt.my_second_dbt_model
13:08:07.552475 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:08:07.553058 [info ] [MainThread]: 
13:08:07.553539 [info ] [MainThread]: Finished running 1 table model, 4 view models in 17.46s.
13:08:07.554142 [debug] [MainThread]: Connection 'master' was properly closed.
13:08:07.554502 [debug] [MainThread]: Connection 'model.demo_dbt.my_second_dbt_model' was properly closed.
13:08:07.612175 [info ] [MainThread]: 
13:08:07.612560 [info ] [MainThread]: [32mCompleted successfully[0m
13:08:07.613069 [info ] [MainThread]: 
13:08:07.613467 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5


============================== 2022-06-29 13:11:55.945790 | b9ec6e37-4044-49cf-b521-fd80aadf27df ==============================
13:11:55.945805 [info ] [MainThread]: Running with dbt=1.1.1
13:11:55.959091 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
13:11:55.959551 [debug] [MainThread]: Tracking: do not track
13:11:56.058548 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
13:11:56.058813 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
13:11:56.077333 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
13:11:56.080022 [info ] [MainThread]: 
13:11:56.080779 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:11:56.082199 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database_snapshots"
13:11:56.100989 [debug] [ThreadPool]: Using snowflake connection "list_my_database_snapshots"
13:11:56.101236 [debug] [ThreadPool]: On list_my_database_snapshots: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database_snapshots"} */

    show terse objects in my_database.snapshots
13:11:56.101405 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:11:57.937783 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.84 seconds
13:11:57.940320 [debug] [ThreadPool]: On list_my_database_snapshots: Close
13:11:58.409528 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database_warehouse"
13:11:58.412503 [debug] [ThreadPool]: Using snowflake connection "list_my_database_warehouse"
13:11:58.412794 [debug] [ThreadPool]: On list_my_database_warehouse: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database_warehouse"} */

    show terse objects in my_database.warehouse
13:11:58.413003 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:11:59.833712 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1.42 seconds
13:11:59.836119 [debug] [ThreadPool]: On list_my_database_warehouse: Close
13:12:00.319582 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:12:00.320101 [info ] [MainThread]: 
13:12:00.323078 [debug] [Thread-1  ]: Began running node model.demo_dbt.my_first_dbt_model
13:12:00.323645 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.my_first_dbt_model"
13:12:00.323887 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.my_first_dbt_model
13:12:00.324123 [debug] [Thread-1  ]: Compiling model.demo_dbt.my_first_dbt_model
13:12:00.328350 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.my_first_dbt_model"
13:12:00.329058 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.329302 [debug] [Thread-1  ]: Began executing node model.demo_dbt.my_first_dbt_model
13:12:00.329508 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.330038 [debug] [Thread-1  ]: Finished running node model.demo_dbt.my_first_dbt_model
13:12:00.330284 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__orders
13:12:00.330897 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.stg_eltool__orders"
13:12:00.331098 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__orders
13:12:00.331280 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__orders
13:12:00.334130 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__orders"
13:12:00.335303 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.335662 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__orders
13:12:00.335886 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.336403 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__orders
13:12:00.336634 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__state
13:12:00.336961 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.stg_eltool__state"
13:12:00.337139 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__state
13:12:00.337295 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__state
13:12:00.339575 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__state"
13:12:00.340178 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.340393 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__state
13:12:00.340561 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.340980 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__state
13:12:00.341180 [debug] [Thread-1  ]: Began running node snapshot.demo_dbt.customers_snapshot
13:12:00.341469 [debug] [Thread-1  ]: Acquiring new snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:12:00.341627 [debug] [Thread-1  ]: Began compiling node snapshot.demo_dbt.customers_snapshot
13:12:00.341873 [debug] [Thread-1  ]: Compiling snapshot.demo_dbt.customers_snapshot
13:12:00.344987 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.345185 [debug] [Thread-1  ]: Began executing node snapshot.demo_dbt.customers_snapshot
13:12:00.345354 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.345749 [debug] [Thread-1  ]: Finished running node snapshot.demo_dbt.customers_snapshot
13:12:00.345949 [debug] [Thread-1  ]: Began running node test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6
13:12:00.346234 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6"
13:12:00.346390 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6
13:12:00.346542 [debug] [Thread-1  ]: Compiling test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6
13:12:00.361813 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6"
13:12:00.362898 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.363168 [debug] [Thread-1  ]: Began executing node test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6
13:12:00.363343 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.363836 [debug] [Thread-1  ]: Finished running node test.demo_dbt.source_not_null_warehouse_customers_customer_id.ae7452c4c6
13:12:00.364044 [debug] [Thread-1  ]: Began running node test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76
13:12:00.364520 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76"
13:12:00.364706 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76
13:12:00.364859 [debug] [Thread-1  ]: Compiling test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76
13:12:00.368982 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76"
13:12:00.369551 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.369815 [debug] [Thread-1  ]: Began executing node test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76
13:12:00.370053 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.370509 [debug] [Thread-1  ]: Finished running node test.demo_dbt.source_not_null_warehouse_orders_order_id.c85a1f0b76
13:12:00.370721 [debug] [Thread-1  ]: Began running node test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2
13:12:00.371146 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2"
13:12:00.371375 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2
13:12:00.371541 [debug] [Thread-1  ]: Compiling test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2
13:12:00.380568 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2"
13:12:00.381584 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.382055 [debug] [Thread-1  ]: Began executing node test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2
13:12:00.382260 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.382711 [debug] [Thread-1  ]: Finished running node test.demo_dbt.source_relationships_warehouse_orders_cust_id__customer_id__source_warehouse_customers_.d3f9188fc2
13:12:00.382917 [debug] [Thread-1  ]: Began running node test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f
13:12:00.383195 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f"
13:12:00.383357 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f
13:12:00.383505 [debug] [Thread-1  ]: Compiling test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f
13:12:00.390245 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f"
13:12:00.390767 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.390958 [debug] [Thread-1  ]: Began executing node test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f
13:12:00.391119 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.391535 [debug] [Thread-1  ]: Finished running node test.demo_dbt.source_unique_warehouse_orders_order_id.839fb43d0f
13:12:00.391737 [debug] [Thread-1  ]: Began running node model.demo_dbt.my_second_dbt_model
13:12:00.392095 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.my_second_dbt_model"
13:12:00.392258 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.my_second_dbt_model
13:12:00.392422 [debug] [Thread-1  ]: Compiling model.demo_dbt.my_second_dbt_model
13:12:00.394905 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.my_second_dbt_model"
13:12:00.395763 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.395979 [debug] [Thread-1  ]: Began executing node model.demo_dbt.my_second_dbt_model
13:12:00.396143 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.396597 [debug] [Thread-1  ]: Finished running node model.demo_dbt.my_second_dbt_model
13:12:00.396795 [debug] [Thread-1  ]: Began running node test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710
13:12:00.397073 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
13:12:00.397228 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710
13:12:00.397376 [debug] [Thread-1  ]: Compiling test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710
13:12:00.401367 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710"
13:12:00.402421 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.402636 [debug] [Thread-1  ]: Began executing node test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710
13:12:00.402801 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.403238 [debug] [Thread-1  ]: Finished running node test.demo_dbt.not_null_my_first_dbt_model_id.5fb22c2710
13:12:00.403435 [debug] [Thread-1  ]: Began running node test.demo_dbt.unique_my_first_dbt_model_id.16e066b321
13:12:00.403713 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.demo_dbt.unique_my_first_dbt_model_id.16e066b321"
13:12:00.403867 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.unique_my_first_dbt_model_id.16e066b321
13:12:00.404083 [debug] [Thread-1  ]: Compiling test.demo_dbt.unique_my_first_dbt_model_id.16e066b321
13:12:00.408000 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.unique_my_first_dbt_model_id.16e066b321"
13:12:00.408524 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.408721 [debug] [Thread-1  ]: Began executing node test.demo_dbt.unique_my_first_dbt_model_id.16e066b321
13:12:00.408882 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.409309 [debug] [Thread-1  ]: Finished running node test.demo_dbt.unique_my_first_dbt_model_id.16e066b321
13:12:00.409517 [debug] [Thread-1  ]: Began running node model.demo_dbt.stg_eltool__customers
13:12:00.409802 [debug] [Thread-1  ]: Acquiring new snowflake connection "model.demo_dbt.stg_eltool__customers"
13:12:00.409964 [debug] [Thread-1  ]: Began compiling node model.demo_dbt.stg_eltool__customers
13:12:00.410117 [debug] [Thread-1  ]: Compiling model.demo_dbt.stg_eltool__customers
13:12:00.412929 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt.stg_eltool__customers"
13:12:00.413567 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.413862 [debug] [Thread-1  ]: Began executing node model.demo_dbt.stg_eltool__customers
13:12:00.414040 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.414491 [debug] [Thread-1  ]: Finished running node model.demo_dbt.stg_eltool__customers
13:12:00.414688 [debug] [Thread-1  ]: Began running node test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778
13:12:00.414972 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:12:00.415129 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778
13:12:00.415276 [debug] [Thread-1  ]: Compiling test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778
13:12:00.420141 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778"
13:12:00.420828 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.421027 [debug] [Thread-1  ]: Began executing node test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778
13:12:00.421188 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.421602 [debug] [Thread-1  ]: Finished running node test.demo_dbt.not_null_my_second_dbt_model_id.151b76d778
13:12:00.421797 [debug] [Thread-1  ]: Began running node test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:12:00.422072 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:12:00.422225 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:12:00.422373 [debug] [Thread-1  ]: Compiling test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:12:00.425912 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493"
13:12:00.426417 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.426608 [debug] [Thread-1  ]: Began executing node test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:12:00.426768 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.427167 [debug] [Thread-1  ]: Finished running node test.demo_dbt.unique_my_second_dbt_model_id.57a0f8c493
13:12:00.427410 [debug] [Thread-1  ]: Began running node test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df
13:12:00.427849 [debug] [Thread-1  ]: Acquiring new snowflake connection "test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df"
13:12:00.428068 [debug] [Thread-1  ]: Began compiling node test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df
13:12:00.428283 [debug] [Thread-1  ]: Compiling test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df
13:12:00.432257 [debug] [Thread-1  ]: Writing injected SQL for node "test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df"
13:12:00.432750 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.432936 [debug] [Thread-1  ]: Began executing node test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df
13:12:00.433230 [debug] [Thread-1  ]: finished collecting timing info
13:12:00.433702 [debug] [Thread-1  ]: Finished running node test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df
13:12:00.530714 [debug] [MainThread]: Connection 'master' was properly closed.
13:12:00.531033 [debug] [MainThread]: Connection 'test.demo_dbt.not_null_stg_eltool__customers_customer_id.4bd58324df' was properly closed.
13:12:00.538439 [info ] [MainThread]: Done.
13:12:00.560766 [debug] [MainThread]: Acquiring new snowflake connection "generate_catalog"
13:12:00.561249 [info ] [MainThread]: Building catalog
13:12:00.565557 [debug] [ThreadPool]: Acquiring new snowflake connection "my_database.information_schema"
13:12:00.577227 [debug] [ThreadPool]: Using snowflake connection "my_database.information_schema"
13:12:00.577644 [debug] [ThreadPool]: On my_database.information_schema: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "my_database.information_schema"} */

    
      with tables as (

          select
              table_catalog as "table_database",
              table_schema as "table_schema",
              table_name as "table_name",
              table_type as "table_type",
              comment as "table_comment",

              -- note: this is the _role_ that owns the table
              table_owner as "table_owner",

              'Clustering Key' as "stats:clustering_key:label",
              clustering_key as "stats:clustering_key:value",
              'The key used to cluster this table' as "stats:clustering_key:description",
              (clustering_key is not null) as "stats:clustering_key:include",

              'Row Count' as "stats:row_count:label",
              row_count as "stats:row_count:value",
              'An approximate count of rows in this table' as "stats:row_count:description",
              (row_count is not null) as "stats:row_count:include",

              'Approximate Size' as "stats:bytes:label",
              bytes as "stats:bytes:value",
              'Approximate size of the table as reported by Snowflake' as "stats:bytes:description",
              (bytes is not null) as "stats:bytes:include",

              'Last Modified' as "stats:last_modified:label",
              to_varchar(convert_timezone('UTC', last_altered), 'yyyy-mm-dd HH24:MI'||'UTC') as "stats:last_modified:value",
              'The timestamp for last update/change' as "stats:last_modified:description",
              (last_altered is not null and table_type='BASE TABLE') as "stats:last_modified:include"

          from my_database.INFORMATION_SCHEMA.tables

      ),

      columns as (

          select
              table_catalog as "table_database",
              table_schema as "table_schema",
              table_name as "table_name",

              column_name as "column_name",
              ordinal_position as "column_index",
              data_type as "column_type",
              comment as "column_comment"

          from my_database.INFORMATION_SCHEMA.columns
      )

      select *
      from tables
      join columns using ("table_database", "table_schema", "table_name")
      where (upper("table_schema") = upper('snapshots') or upper("table_schema") = upper('warehouse'))
      order by "column_index"
13:12:00.577832 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:12:03.287938 [debug] [ThreadPool]: SQL status: SUCCESS 50 in 2.71 seconds
13:12:03.407227 [debug] [ThreadPool]: On my_database.information_schema: Close
13:12:03.894951 [info ] [MainThread]: Catalog written to /Users/amit/python/code/demo_dbt/target/catalog.json
13:12:03.895558 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
13:12:03.895716 [debug] [MainThread]: Connection 'my_database.information_schema' was properly closed.


============================== 2022-06-29 13:12:24.023590 | 84804552-66ad-4ec4-9466-a7495582fcc6 ==============================
13:12:24.023607 [info ] [MainThread]: Running with dbt=1.1.1
13:12:24.024984 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'port': 8080, 'open_browser': True, 'which': 'serve', 'indirect_selection': 'eager'}
13:12:24.025420 [debug] [MainThread]: Tracking: do not track
13:12:24.048392 [info ] [MainThread]: Serving docs at 0.0.0.0:8080
13:12:24.049071 [info ] [MainThread]: To access from your browser, navigate to:  http://localhost:8080
13:12:24.049633 [info ] [MainThread]: 
13:12:24.050024 [info ] [MainThread]: 
13:12:24.050440 [info ] [MainThread]: Press Ctrl+C to exit.


============================== 2022-06-29 15:31:39.406893 | d1f7cdbf-e802-4d6d-b403-3bfc7151db22 ==============================
15:31:39.406911 [info ] [MainThread]: Running with dbt=1.1.1
15:31:39.407955 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
15:31:39.408177 [debug] [MainThread]: Tracking: do not track
15:31:39.454138 [info ] [MainThread]: Unable to do partial parsing because profile has changed
15:31:39.454674 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
15:31:39.496749 [debug] [MainThread]: Parsing macros/catalog.sql
15:31:39.502756 [debug] [MainThread]: Parsing macros/relations.sql
15:31:39.504355 [debug] [MainThread]: Parsing macros/adapters.sql
15:31:39.537051 [debug] [MainThread]: Parsing macros/materializations/snapshot_merge.sql
15:31:39.539072 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
15:31:39.544480 [debug] [MainThread]: Parsing macros/materializations/configs.sql
15:31:39.548525 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
15:31:39.551144 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
15:31:39.571840 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
15:31:39.588544 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
15:31:39.602423 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
15:31:39.608336 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
15:31:39.610522 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
15:31:39.613303 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
15:31:39.619626 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
15:31:39.639731 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
15:31:39.641577 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
15:31:39.654581 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
15:31:39.673044 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
15:31:39.682641 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
15:31:39.686426 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
15:31:39.695089 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
15:31:39.696785 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
15:31:39.699993 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
15:31:39.703363 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
15:31:39.711533 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
15:31:39.734907 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
15:31:39.737029 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
15:31:39.740164 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
15:31:39.742069 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
15:31:39.743129 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
15:31:39.744195 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
15:31:39.745109 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
15:31:39.746961 [debug] [MainThread]: Parsing macros/etc/statement.sql
15:31:39.752373 [debug] [MainThread]: Parsing macros/etc/datetime.sql
15:31:39.762789 [debug] [MainThread]: Parsing macros/adapters/schema.sql
15:31:39.765785 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
15:31:39.769399 [debug] [MainThread]: Parsing macros/adapters/relation.sql
15:31:39.781926 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
15:31:39.785452 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
15:31:39.791246 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
15:31:39.801002 [debug] [MainThread]: Parsing macros/adapters/columns.sql
15:31:39.814879 [debug] [MainThread]: Parsing tests/generic/builtin.sql
15:31:40.064425 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
15:31:40.078644 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
15:31:40.081923 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
15:31:40.085190 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
15:31:40.088141 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
15:31:40.220568 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.demo_dbt.example

15:31:40.238029 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 167 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
15:31:40.240276 [info ] [MainThread]: 
15:31:40.240955 [debug] [MainThread]: Acquiring new postgres connection "master"
15:31:40.242046 [debug] [ThreadPool]: Acquiring new postgres connection "list_postgres"
15:31:40.248368 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro list_schemas
15:31:40.248604 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
15:31:40.248807 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:31:41.861932 [debug] [ThreadPool]: On list_postgres: Close
15:31:41.863436 [debug] [MainThread]: Connection 'master' was properly closed.
15:31:41.863706 [debug] [MainThread]: Connection 'list_postgres' was properly closed.


============================== 2022-06-29 15:32:16.599278 | 38759211-830e-4de7-92ee-90bc43410139 ==============================
15:32:16.599339 [info ] [MainThread]: Running with dbt=1.1.1
15:32:16.600561 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
15:32:16.600892 [debug] [MainThread]: Tracking: do not track
15:32:16.824846 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
15:32:16.825558 [debug] [MainThread]: Partial parsing: updated file: demo_dbt_postgres://snapshots/customers.sql
15:32:16.880302 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.demo_dbt.example

15:32:16.894045 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 167 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
15:32:16.895853 [info ] [MainThread]: 
15:32:16.896377 [debug] [MainThread]: Acquiring new postgres connection "master"
15:32:16.897134 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb"
15:32:16.908315 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb"
15:32:16.908535 [debug] [ThreadPool]: On list_brightacciondb: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "connection_name": "list_brightacciondb"} */

    select distinct nspname from pg_namespace
  
15:32:16.908697 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:32:18.781225 [debug] [ThreadPool]: SQL status: SELECT 10 in 1.87 seconds
15:32:18.784249 [debug] [ThreadPool]: On list_brightacciondb: Close
15:32:18.786045 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb_snapshots"
15:32:18.793698 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_snapshots"
15:32:18.793947 [debug] [ThreadPool]: On list_brightacciondb_snapshots: BEGIN
15:32:18.794118 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:32:20.577937 [debug] [ThreadPool]: SQL status: BEGIN in 1.78 seconds
15:32:20.578450 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_snapshots"
15:32:20.578772 [debug] [ThreadPool]: On list_brightacciondb_snapshots: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "connection_name": "list_brightacciondb_snapshots"} */
select
      'brightacciondb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'brightacciondb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
  
15:32:20.816204 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.24 seconds
15:32:20.818926 [debug] [ThreadPool]: On list_brightacciondb_snapshots: ROLLBACK
15:32:21.038855 [debug] [ThreadPool]: On list_brightacciondb_snapshots: Close
15:32:21.040037 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb_warehouse"
15:32:21.043288 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_warehouse"
15:32:21.043600 [debug] [ThreadPool]: On list_brightacciondb_warehouse: BEGIN
15:32:21.043809 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:32:22.821146 [debug] [ThreadPool]: SQL status: BEGIN in 1.78 seconds
15:32:22.821511 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_warehouse"
15:32:22.821751 [debug] [ThreadPool]: On list_brightacciondb_warehouse: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "connection_name": "list_brightacciondb_warehouse"} */
select
      'brightacciondb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'brightacciondb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
15:32:23.038611 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.22 seconds
15:32:23.041512 [debug] [ThreadPool]: On list_brightacciondb_warehouse: ROLLBACK
15:32:23.256113 [debug] [ThreadPool]: On list_brightacciondb_warehouse: Close
15:32:23.263453 [debug] [MainThread]: Using postgres connection "master"
15:32:23.263724 [debug] [MainThread]: On master: BEGIN
15:32:23.263941 [debug] [MainThread]: Opening a new connection, currently in state init
15:32:25.086693 [debug] [MainThread]: SQL status: BEGIN in 1.82 seconds
15:32:25.087417 [debug] [MainThread]: Using postgres connection "master"
15:32:25.087644 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
15:32:25.331918 [debug] [MainThread]: SQL status: SELECT 4 in 0.24 seconds
15:32:25.334500 [debug] [MainThread]: On master: ROLLBACK
15:32:25.546227 [debug] [MainThread]: Using postgres connection "master"
15:32:25.546676 [debug] [MainThread]: On master: BEGIN
15:32:25.971782 [debug] [MainThread]: SQL status: BEGIN in 0.42 seconds
15:32:25.972410 [debug] [MainThread]: On master: COMMIT
15:32:25.972654 [debug] [MainThread]: Using postgres connection "master"
15:32:25.972860 [debug] [MainThread]: On master: COMMIT
15:32:26.197440 [debug] [MainThread]: SQL status: COMMIT in 0.22 seconds
15:32:26.198037 [debug] [MainThread]: On master: Close
15:32:26.198848 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:32:26.199265 [info ] [MainThread]: 
15:32:26.202531 [debug] [Thread-1  ]: Began running node snapshot.demo_dbt_postgres.customers_snapshot
15:32:26.202992 [info ] [Thread-1  ]: 1 of 1 START snapshot snapshots.customers_snapshot ............................. [RUN]
15:32:26.203947 [debug] [Thread-1  ]: Acquiring new postgres connection "snapshot.demo_dbt_postgres.customers_snapshot"
15:32:26.204343 [debug] [Thread-1  ]: Began compiling node snapshot.demo_dbt_postgres.customers_snapshot
15:32:26.204655 [debug] [Thread-1  ]: Compiling snapshot.demo_dbt_postgres.customers_snapshot
15:32:26.208743 [debug] [Thread-1  ]: finished collecting timing info
15:32:26.209034 [debug] [Thread-1  ]: Began executing node snapshot.demo_dbt_postgres.customers_snapshot
15:32:26.266086 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt_postgres.customers_snapshot"
15:32:26.266396 [debug] [Thread-1  ]: On snapshot.demo_dbt_postgres.customers_snapshot: BEGIN
15:32:26.266553 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:32:27.992329 [debug] [Thread-1  ]: SQL status: BEGIN in 1.73 seconds
15:32:27.992928 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt_postgres.customers_snapshot"
15:32:27.993203 [debug] [Thread-1  ]: On snapshot.demo_dbt_postgres.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "snapshot.demo_dbt_postgres.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "brightacciondb".INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot'
        
        and table_schema = 'snapshots'
        
      order by ordinal_position

  
15:32:28.219233 [debug] [Thread-1  ]: SQL status: SELECT 10 in 0.23 seconds
15:32:28.253100 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt_postgres.customers_snapshot"
15:32:28.253340 [debug] [Thread-1  ]: On snapshot.demo_dbt_postgres.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "snapshot.demo_dbt_postgres.customers_snapshot"} */

        

  create temporary table "customers_snapshot__dbt_tmp210228240160"
  as (
    with snapshot_query as (

        



select * from "brightacciondb"."warehouse"."customers"


    ),

    snapshotted_data as (

        select *,
            customer_id as dbt_unique_key

        from "brightacciondb"."snapshots"."customers_snapshot"
        where dbt_valid_to is null

    ),

    insertions_source_data as (

        select
            *,
            customer_id as dbt_unique_key,
            datetime_updated as dbt_updated_at,
            datetime_updated as dbt_valid_from,
            nullif(datetime_updated, datetime_updated) as dbt_valid_to,
            md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(datetime_updated as varchar ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select
            *,
            customer_id as dbt_unique_key,
            datetime_updated as dbt_updated_at,
            datetime_updated as dbt_valid_from,
            datetime_updated as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where snapshotted_data.dbt_unique_key is null
           or (
                snapshotted_data.dbt_unique_key is not null
            and (
                (snapshotted_data.dbt_valid_from < source_data.datetime_updated)
            )
        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where (
            (snapshotted_data.dbt_valid_from < source_data.datetime_updated)
        )
    )

    select * from insertions
    union all
    select * from updates

  );
    
15:32:28.515455 [debug] [Thread-1  ]: SQL status: SELECT 0 in 0.26 seconds
15:32:28.519404 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt_postgres.customers_snapshot"
15:32:28.519686 [debug] [Thread-1  ]: On snapshot.demo_dbt_postgres.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "snapshot.demo_dbt_postgres.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot__dbt_tmp210228240160'
        
      order by ordinal_position

  
15:32:28.733410 [debug] [Thread-1  ]: SQL status: SELECT 12 in 0.21 seconds
15:32:28.740291 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt_postgres.customers_snapshot"
15:32:28.740596 [debug] [Thread-1  ]: On snapshot.demo_dbt_postgres.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "snapshot.demo_dbt_postgres.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "brightacciondb".INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot'
        
        and table_schema = 'snapshots'
        
      order by ordinal_position

  
15:32:28.952794 [debug] [Thread-1  ]: SQL status: SELECT 10 in 0.21 seconds
15:32:28.958335 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt_postgres.customers_snapshot"
15:32:28.958637 [debug] [Thread-1  ]: On snapshot.demo_dbt_postgres.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "snapshot.demo_dbt_postgres.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot__dbt_tmp210228240160'
        
      order by ordinal_position

  
15:32:29.171116 [debug] [Thread-1  ]: SQL status: SELECT 12 in 0.21 seconds
15:32:29.175919 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt_postgres.customers_snapshot"
15:32:29.176225 [debug] [Thread-1  ]: On snapshot.demo_dbt_postgres.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "snapshot.demo_dbt_postgres.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "brightacciondb".INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot'
        
        and table_schema = 'snapshots'
        
      order by ordinal_position

  
15:32:29.389518 [debug] [Thread-1  ]: SQL status: SELECT 10 in 0.21 seconds
15:32:29.404404 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt_postgres.customers_snapshot"
15:32:29.404882 [debug] [Thread-1  ]: On snapshot.demo_dbt_postgres.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "snapshot.demo_dbt_postgres.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot__dbt_tmp210228240160'
        
      order by ordinal_position

  
15:32:29.616680 [debug] [Thread-1  ]: SQL status: SELECT 12 in 0.21 seconds
15:32:29.626410 [debug] [Thread-1  ]: Writing runtime SQL for node "snapshot.demo_dbt_postgres.customers_snapshot"
15:32:29.627459 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt_postgres.customers_snapshot"
15:32:29.627760 [debug] [Thread-1  ]: On snapshot.demo_dbt_postgres.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "snapshot.demo_dbt_postgres.customers_snapshot"} */

      update "brightacciondb"."snapshots"."customers_snapshot"
    set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to
    from "customers_snapshot__dbt_tmp210228240160" as DBT_INTERNAL_SOURCE
    where DBT_INTERNAL_SOURCE.dbt_scd_id::text = "brightacciondb"."snapshots"."customers_snapshot".dbt_scd_id::text
      and DBT_INTERNAL_SOURCE.dbt_change_type::text in ('update'::text, 'delete'::text)
      and "brightacciondb"."snapshots"."customers_snapshot".dbt_valid_to is null;

    insert into "brightacciondb"."snapshots"."customers_snapshot" ("customer_id", "zipcode", "city", "state_code", "datetime_created", "datetime_updated", "dbt_updated_at", "dbt_valid_from", "dbt_valid_to", "dbt_scd_id")
    select DBT_INTERNAL_SOURCE."customer_id",DBT_INTERNAL_SOURCE."zipcode",DBT_INTERNAL_SOURCE."city",DBT_INTERNAL_SOURCE."state_code",DBT_INTERNAL_SOURCE."datetime_created",DBT_INTERNAL_SOURCE."datetime_updated",DBT_INTERNAL_SOURCE."dbt_updated_at",DBT_INTERNAL_SOURCE."dbt_valid_from",DBT_INTERNAL_SOURCE."dbt_valid_to",DBT_INTERNAL_SOURCE."dbt_scd_id"
    from "customers_snapshot__dbt_tmp210228240160" as DBT_INTERNAL_SOURCE
    where DBT_INTERNAL_SOURCE.dbt_change_type::text = 'insert'::text;

  
15:32:29.875040 [debug] [Thread-1  ]: SQL status: INSERT 0 0 in 0.25 seconds
15:32:29.885445 [debug] [Thread-1  ]: On snapshot.demo_dbt_postgres.customers_snapshot: COMMIT
15:32:29.885713 [debug] [Thread-1  ]: Using postgres connection "snapshot.demo_dbt_postgres.customers_snapshot"
15:32:29.885894 [debug] [Thread-1  ]: On snapshot.demo_dbt_postgres.customers_snapshot: COMMIT
15:32:30.101788 [debug] [Thread-1  ]: SQL status: COMMIT in 0.22 seconds
15:32:30.108203 [debug] [Thread-1  ]: finished collecting timing info
15:32:30.108572 [debug] [Thread-1  ]: On snapshot.demo_dbt_postgres.customers_snapshot: Close
15:32:30.109567 [info ] [Thread-1  ]: 1 of 1 OK snapshotted snapshots.customers_snapshot ............................. [[32mINSERT 0 0[0m in 3.91s]
15:32:30.110276 [debug] [Thread-1  ]: Finished running node snapshot.demo_dbt_postgres.customers_snapshot
15:32:30.181911 [debug] [MainThread]: Acquiring new postgres connection "master"
15:32:30.182359 [debug] [MainThread]: Using postgres connection "master"
15:32:30.182630 [debug] [MainThread]: On master: BEGIN
15:32:30.182880 [debug] [MainThread]: Opening a new connection, currently in state closed
15:32:31.969452 [debug] [MainThread]: SQL status: BEGIN in 1.79 seconds
15:32:31.970132 [debug] [MainThread]: On master: COMMIT
15:32:31.970780 [debug] [MainThread]: Using postgres connection "master"
15:32:31.971080 [debug] [MainThread]: On master: COMMIT
15:32:32.215267 [debug] [MainThread]: SQL status: COMMIT in 0.24 seconds
15:32:32.215919 [debug] [MainThread]: On master: Close
15:32:32.216720 [info ] [MainThread]: 
15:32:32.217138 [info ] [MainThread]: Finished running 1 snapshot in 15.32s.
15:32:32.217616 [debug] [MainThread]: Connection 'master' was properly closed.
15:32:32.217976 [debug] [MainThread]: Connection 'snapshot.demo_dbt_postgres.customers_snapshot' was properly closed.
15:32:32.226497 [info ] [MainThread]: 
15:32:32.226977 [info ] [MainThread]: [32mCompleted successfully[0m
15:32:32.227497 [info ] [MainThread]: 
15:32:32.227933 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1


============================== 2022-06-29 15:35:32.215722 | c44f4b6b-bec4-4c3c-9e5a-a23c45e7981d ==============================
15:35:32.215743 [info ] [MainThread]: Running with dbt=1.1.1
15:35:32.223295 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
15:35:32.223549 [debug] [MainThread]: Tracking: do not track
15:35:32.340810 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
15:35:32.341114 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
15:35:32.341671 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.demo_dbt.example

15:35:32.363491 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 167 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
15:35:32.365689 [info ] [MainThread]: 
15:35:32.366337 [debug] [MainThread]: Acquiring new postgres connection "master"
15:35:32.367357 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb"
15:35:32.380906 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb"
15:35:32.381171 [debug] [ThreadPool]: On list_brightacciondb: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "connection_name": "list_brightacciondb"} */

    select distinct nspname from pg_namespace
  
15:35:32.381353 [debug] [ThreadPool]: Opening a new connection, currently in state init
15:35:34.479078 [debug] [ThreadPool]: SQL status: SELECT 12 in 2.1 seconds
15:35:34.481669 [debug] [ThreadPool]: On list_brightacciondb: Close
15:35:34.483489 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb_warehouse"
15:35:34.490696 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_warehouse"
15:35:34.490940 [debug] [ThreadPool]: On list_brightacciondb_warehouse: BEGIN
15:35:34.491098 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:35:36.257378 [debug] [ThreadPool]: SQL status: BEGIN in 1.77 seconds
15:35:36.257849 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_warehouse"
15:35:36.258208 [debug] [ThreadPool]: On list_brightacciondb_warehouse: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "connection_name": "list_brightacciondb_warehouse"} */
select
      'brightacciondb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'warehouse'
    union all
    select
      'brightacciondb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'warehouse'
  
15:35:36.484074 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.23 seconds
15:35:36.486757 [debug] [ThreadPool]: On list_brightacciondb_warehouse: ROLLBACK
15:35:36.709966 [debug] [ThreadPool]: On list_brightacciondb_warehouse: Close
15:35:36.711319 [debug] [ThreadPool]: Acquiring new postgres connection "list_brightacciondb_snapshots"
15:35:36.714078 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_snapshots"
15:35:36.714349 [debug] [ThreadPool]: On list_brightacciondb_snapshots: BEGIN
15:35:36.714816 [debug] [ThreadPool]: Opening a new connection, currently in state closed
15:35:38.423058 [debug] [ThreadPool]: SQL status: BEGIN in 1.71 seconds
15:35:38.423478 [debug] [ThreadPool]: Using postgres connection "list_brightacciondb_snapshots"
15:35:38.423758 [debug] [ThreadPool]: On list_brightacciondb_snapshots: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "connection_name": "list_brightacciondb_snapshots"} */
select
      'brightacciondb' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'brightacciondb' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
  
15:35:38.637659 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.21 seconds
15:35:38.639892 [debug] [ThreadPool]: On list_brightacciondb_snapshots: ROLLBACK
15:35:38.851539 [debug] [ThreadPool]: On list_brightacciondb_snapshots: Close
15:35:38.859126 [debug] [MainThread]: Using postgres connection "master"
15:35:38.859455 [debug] [MainThread]: On master: BEGIN
15:35:38.859682 [debug] [MainThread]: Opening a new connection, currently in state init
15:35:40.623022 [debug] [MainThread]: SQL status: BEGIN in 1.76 seconds
15:35:40.623452 [debug] [MainThread]: Using postgres connection "master"
15:35:40.623761 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
15:35:40.858169 [debug] [MainThread]: SQL status: SELECT 4 in 0.23 seconds
15:35:40.860610 [debug] [MainThread]: On master: ROLLBACK
15:35:41.078323 [debug] [MainThread]: Using postgres connection "master"
15:35:41.078961 [debug] [MainThread]: On master: BEGIN
15:35:41.518065 [debug] [MainThread]: SQL status: BEGIN in 0.44 seconds
15:35:41.518526 [debug] [MainThread]: On master: COMMIT
15:35:41.519005 [debug] [MainThread]: Using postgres connection "master"
15:35:41.519298 [debug] [MainThread]: On master: COMMIT
15:35:41.737760 [debug] [MainThread]: SQL status: COMMIT in 0.22 seconds
15:35:41.738226 [debug] [MainThread]: On master: Close
15:35:41.739059 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
15:35:41.739465 [info ] [MainThread]: 
15:35:41.742062 [debug] [Thread-1  ]: Began running node model.demo_dbt_postgres.my_first_dbt_model
15:35:41.742443 [info ] [Thread-1  ]: 1 of 5 START table model warehouse.my_first_dbt_model .......................... [RUN]
15:35:41.743071 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_dbt_postgres.my_first_dbt_model"
15:35:41.743331 [debug] [Thread-1  ]: Began compiling node model.demo_dbt_postgres.my_first_dbt_model
15:35:41.743546 [debug] [Thread-1  ]: Compiling model.demo_dbt_postgres.my_first_dbt_model
15:35:41.746374 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt_postgres.my_first_dbt_model"
15:35:41.747101 [debug] [Thread-1  ]: finished collecting timing info
15:35:41.747305 [debug] [Thread-1  ]: Began executing node model.demo_dbt_postgres.my_first_dbt_model
15:35:41.782515 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt_postgres.my_first_dbt_model"
15:35:41.783569 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.my_first_dbt_model"
15:35:41.783868 [debug] [Thread-1  ]: On model.demo_dbt_postgres.my_first_dbt_model: BEGIN
15:35:41.784036 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:35:43.556497 [debug] [Thread-1  ]: SQL status: BEGIN in 1.77 seconds
15:35:43.558709 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.my_first_dbt_model"
15:35:43.559207 [debug] [Thread-1  ]: On model.demo_dbt_postgres.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "model.demo_dbt_postgres.my_first_dbt_model"} */


  create  table "brightacciondb"."warehouse"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
15:35:43.780547 [debug] [Thread-1  ]: SQL status: SELECT 2 in 0.22 seconds
15:35:43.789994 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.my_first_dbt_model"
15:35:43.790272 [debug] [Thread-1  ]: On model.demo_dbt_postgres.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "model.demo_dbt_postgres.my_first_dbt_model"} */
alter table "brightacciondb"."warehouse"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
15:35:44.024404 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.23 seconds
15:35:44.028225 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.my_first_dbt_model"
15:35:44.028597 [debug] [Thread-1  ]: On model.demo_dbt_postgres.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "model.demo_dbt_postgres.my_first_dbt_model"} */
alter table "brightacciondb"."warehouse"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
15:35:44.248547 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.22 seconds
15:35:44.265994 [debug] [Thread-1  ]: On model.demo_dbt_postgres.my_first_dbt_model: COMMIT
15:35:44.266249 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.my_first_dbt_model"
15:35:44.266412 [debug] [Thread-1  ]: On model.demo_dbt_postgres.my_first_dbt_model: COMMIT
15:35:44.728977 [debug] [Thread-1  ]: SQL status: COMMIT in 0.46 seconds
15:35:44.735867 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.my_first_dbt_model"
15:35:44.736104 [debug] [Thread-1  ]: On model.demo_dbt_postgres.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "model.demo_dbt_postgres.my_first_dbt_model"} */
drop table if exists "brightacciondb"."warehouse"."my_first_dbt_model__dbt_backup" cascade
15:35:44.960213 [debug] [Thread-1  ]: SQL status: DROP TABLE in 0.22 seconds
15:35:44.962585 [debug] [Thread-1  ]: finished collecting timing info
15:35:44.962959 [debug] [Thread-1  ]: On model.demo_dbt_postgres.my_first_dbt_model: Close
15:35:44.964017 [info ] [Thread-1  ]: 1 of 5 OK created table model warehouse.my_first_dbt_model ..................... [[32mSELECT 2[0m in 3.22s]
15:35:44.964813 [debug] [Thread-1  ]: Finished running node model.demo_dbt_postgres.my_first_dbt_model
15:35:44.965200 [debug] [Thread-1  ]: Began running node model.demo_dbt_postgres.stg_eltool__customers
15:35:44.965852 [info ] [Thread-1  ]: 2 of 5 START view model warehouse.stg_eltool__customers ........................ [RUN]
15:35:44.966700 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_dbt_postgres.stg_eltool__customers"
15:35:44.967022 [debug] [Thread-1  ]: Began compiling node model.demo_dbt_postgres.stg_eltool__customers
15:35:44.967276 [debug] [Thread-1  ]: Compiling model.demo_dbt_postgres.stg_eltool__customers
15:35:44.970561 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt_postgres.stg_eltool__customers"
15:35:44.971241 [debug] [Thread-1  ]: finished collecting timing info
15:35:44.971467 [debug] [Thread-1  ]: Began executing node model.demo_dbt_postgres.stg_eltool__customers
15:35:44.993334 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt_postgres.stg_eltool__customers"
15:35:44.993990 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.stg_eltool__customers"
15:35:44.994173 [debug] [Thread-1  ]: On model.demo_dbt_postgres.stg_eltool__customers: BEGIN
15:35:44.994371 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:35:46.749886 [debug] [Thread-1  ]: SQL status: BEGIN in 1.76 seconds
15:35:46.750646 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.stg_eltool__customers"
15:35:46.751020 [debug] [Thread-1  ]: On model.demo_dbt_postgres.stg_eltool__customers: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "model.demo_dbt_postgres.stg_eltool__customers"} */

  create view "brightacciondb"."warehouse"."stg_eltool__customers__dbt_tmp" as (
    with source as (
    select *
    from "brightacciondb"."snapshots"."customers_snapshot"
), renamed as (
    select customer_id,
        zipcode,
        city,
        state_code,
        datetime_created::TIMESTAMP AS datetime_created,
        datetime_updated::TIMESTAMP AS datetime_updated,
        dbt_valid_from,
        dbt_valid_to
    from source
)
select *
from renamed
  );
15:35:46.975186 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.22 seconds
15:35:46.981133 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.stg_eltool__customers"
15:35:46.981451 [debug] [Thread-1  ]: On model.demo_dbt_postgres.stg_eltool__customers: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "model.demo_dbt_postgres.stg_eltool__customers"} */
alter table "brightacciondb"."warehouse"."stg_eltool__customers" rename to "stg_eltool__customers__dbt_backup"
15:35:47.197511 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.22 seconds
15:35:47.201910 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.stg_eltool__customers"
15:35:47.202221 [debug] [Thread-1  ]: On model.demo_dbt_postgres.stg_eltool__customers: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "model.demo_dbt_postgres.stg_eltool__customers"} */
alter table "brightacciondb"."warehouse"."stg_eltool__customers__dbt_tmp" rename to "stg_eltool__customers"
15:35:47.417149 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.21 seconds
15:35:47.419976 [debug] [Thread-1  ]: On model.demo_dbt_postgres.stg_eltool__customers: COMMIT
15:35:47.420238 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.stg_eltool__customers"
15:35:47.420426 [debug] [Thread-1  ]: On model.demo_dbt_postgres.stg_eltool__customers: COMMIT
15:35:47.636452 [debug] [Thread-1  ]: SQL status: COMMIT in 0.22 seconds
15:35:47.640149 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.stg_eltool__customers"
15:35:47.640602 [debug] [Thread-1  ]: On model.demo_dbt_postgres.stg_eltool__customers: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "model.demo_dbt_postgres.stg_eltool__customers"} */
drop view if exists "brightacciondb"."warehouse"."stg_eltool__customers__dbt_backup" cascade
15:35:47.857141 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.22 seconds
15:35:47.859643 [debug] [Thread-1  ]: finished collecting timing info
15:35:47.859998 [debug] [Thread-1  ]: On model.demo_dbt_postgres.stg_eltool__customers: Close
15:35:47.861252 [info ] [Thread-1  ]: 2 of 5 OK created view model warehouse.stg_eltool__customers ................... [[32mCREATE VIEW[0m in 2.89s]
15:35:47.861957 [debug] [Thread-1  ]: Finished running node model.demo_dbt_postgres.stg_eltool__customers
15:35:47.862303 [debug] [Thread-1  ]: Began running node model.demo_dbt_postgres.stg_eltool__orders
15:35:47.862858 [info ] [Thread-1  ]: 3 of 5 START view model warehouse.stg_eltool__orders ........................... [RUN]
15:35:47.863598 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_dbt_postgres.stg_eltool__orders"
15:35:47.863870 [debug] [Thread-1  ]: Began compiling node model.demo_dbt_postgres.stg_eltool__orders
15:35:47.864107 [debug] [Thread-1  ]: Compiling model.demo_dbt_postgres.stg_eltool__orders
15:35:47.866868 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt_postgres.stg_eltool__orders"
15:35:47.867445 [debug] [Thread-1  ]: finished collecting timing info
15:35:47.867875 [debug] [Thread-1  ]: Began executing node model.demo_dbt_postgres.stg_eltool__orders
15:35:47.870907 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt_postgres.stg_eltool__orders"
15:35:47.871509 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.stg_eltool__orders"
15:35:47.871713 [debug] [Thread-1  ]: On model.demo_dbt_postgres.stg_eltool__orders: BEGIN
15:35:47.871886 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:35:49.597945 [debug] [Thread-1  ]: SQL status: BEGIN in 1.73 seconds
15:35:49.598901 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.stg_eltool__orders"
15:35:49.599517 [debug] [Thread-1  ]: On model.demo_dbt_postgres.stg_eltool__orders: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "model.demo_dbt_postgres.stg_eltool__orders"} */

  create view "brightacciondb"."warehouse"."stg_eltool__orders__dbt_tmp" as (
    with source as (
    select *
    from "brightacciondb"."warehouse"."orders"
),
renamed as (
    select order_id,
        customer_id,
        order_status,
        order_purchase_timestamp::TIMESTAMP,
        order_approved_at::TIMESTAMP,
        order_delivered_carrier_date::TIMESTAMP,
        order_delivered_customer_date::TIMESTAMP,
        order_estimated_delivery_date::TIMESTAMP
        from source
)
select *
from renamed
  );
15:35:49.813952 [debug] [Thread-1  ]: Postgres adapter: Postgres error: column "customer_id" does not exist
LINE 10:         customer_id,
                 ^

15:35:49.814378 [debug] [Thread-1  ]: On model.demo_dbt_postgres.stg_eltool__orders: ROLLBACK
15:35:50.031770 [debug] [Thread-1  ]: finished collecting timing info
15:35:50.032129 [debug] [Thread-1  ]: On model.demo_dbt_postgres.stg_eltool__orders: Close
15:35:50.032852 [debug] [Thread-1  ]: Database Error in model stg_eltool__orders (models/staging/stg_eltool__orders.sql)
  column "customer_id" does not exist
  LINE 10:         customer_id,
                   ^
  compiled SQL at target/run/demo_dbt_postgres/models/staging/stg_eltool__orders.sql
15:35:50.033360 [error] [Thread-1  ]: 3 of 5 ERROR creating view model warehouse.stg_eltool__orders .................. [[31mERROR[0m in 2.17s]
15:35:50.033876 [debug] [Thread-1  ]: Finished running node model.demo_dbt_postgres.stg_eltool__orders
15:35:50.034297 [debug] [Thread-1  ]: Began running node model.demo_dbt_postgres.stg_eltool__state
15:35:50.034820 [info ] [Thread-1  ]: 4 of 5 START view model warehouse.stg_eltool__state ............................ [RUN]
15:35:50.035744 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_dbt_postgres.stg_eltool__state"
15:35:50.036003 [debug] [Thread-1  ]: Began compiling node model.demo_dbt_postgres.stg_eltool__state
15:35:50.036206 [debug] [Thread-1  ]: Compiling model.demo_dbt_postgres.stg_eltool__state
15:35:50.039298 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt_postgres.stg_eltool__state"
15:35:50.039975 [debug] [Thread-1  ]: finished collecting timing info
15:35:50.040266 [debug] [Thread-1  ]: Began executing node model.demo_dbt_postgres.stg_eltool__state
15:35:50.045262 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt_postgres.stg_eltool__state"
15:35:50.045890 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.stg_eltool__state"
15:35:50.046077 [debug] [Thread-1  ]: On model.demo_dbt_postgres.stg_eltool__state: BEGIN
15:35:50.046228 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:35:51.753196 [debug] [Thread-1  ]: SQL status: BEGIN in 1.71 seconds
15:35:51.753663 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.stg_eltool__state"
15:35:51.754145 [debug] [Thread-1  ]: On model.demo_dbt_postgres.stg_eltool__state: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "model.demo_dbt_postgres.stg_eltool__state"} */

  create view "brightacciondb"."warehouse"."stg_eltool__state__dbt_tmp" as (
    with source as (
    select *
    from "brightacciondb"."warehouse"."state"
),
renamed as (
    select state_identifier::INT AS state_id,
        state_code::VARCHAR(2) AS state_code,
        st_name::VARCHAR(30) AS state_name
    from source
)
select *
from renamed
  );
15:35:52.096709 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.34 seconds
15:35:52.102594 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.stg_eltool__state"
15:35:52.103136 [debug] [Thread-1  ]: On model.demo_dbt_postgres.stg_eltool__state: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "model.demo_dbt_postgres.stg_eltool__state"} */
alter table "brightacciondb"."warehouse"."stg_eltool__state" rename to "stg_eltool__state__dbt_backup"
15:35:52.322081 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.22 seconds
15:35:52.325885 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.stg_eltool__state"
15:35:52.326170 [debug] [Thread-1  ]: On model.demo_dbt_postgres.stg_eltool__state: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "model.demo_dbt_postgres.stg_eltool__state"} */
alter table "brightacciondb"."warehouse"."stg_eltool__state__dbt_tmp" rename to "stg_eltool__state"
15:35:52.539942 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.21 seconds
15:35:52.542105 [debug] [Thread-1  ]: On model.demo_dbt_postgres.stg_eltool__state: COMMIT
15:35:52.542370 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.stg_eltool__state"
15:35:52.542584 [debug] [Thread-1  ]: On model.demo_dbt_postgres.stg_eltool__state: COMMIT
15:35:52.754409 [debug] [Thread-1  ]: SQL status: COMMIT in 0.21 seconds
15:35:52.760014 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.stg_eltool__state"
15:35:52.760406 [debug] [Thread-1  ]: On model.demo_dbt_postgres.stg_eltool__state: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "model.demo_dbt_postgres.stg_eltool__state"} */
drop view if exists "brightacciondb"."warehouse"."stg_eltool__state__dbt_backup" cascade
15:35:52.972562 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.21 seconds
15:35:52.974779 [debug] [Thread-1  ]: finished collecting timing info
15:35:52.975337 [debug] [Thread-1  ]: On model.demo_dbt_postgres.stg_eltool__state: Close
15:35:52.976478 [info ] [Thread-1  ]: 4 of 5 OK created view model warehouse.stg_eltool__state ....................... [[32mCREATE VIEW[0m in 2.94s]
15:35:52.977244 [debug] [Thread-1  ]: Finished running node model.demo_dbt_postgres.stg_eltool__state
15:35:52.977741 [debug] [Thread-1  ]: Began running node model.demo_dbt_postgres.my_second_dbt_model
15:35:52.978326 [info ] [Thread-1  ]: 5 of 5 START view model warehouse.my_second_dbt_model .......................... [RUN]
15:35:52.979320 [debug] [Thread-1  ]: Acquiring new postgres connection "model.demo_dbt_postgres.my_second_dbt_model"
15:35:52.979780 [debug] [Thread-1  ]: Began compiling node model.demo_dbt_postgres.my_second_dbt_model
15:35:52.980038 [debug] [Thread-1  ]: Compiling model.demo_dbt_postgres.my_second_dbt_model
15:35:52.983101 [debug] [Thread-1  ]: Writing injected SQL for node "model.demo_dbt_postgres.my_second_dbt_model"
15:35:52.983758 [debug] [Thread-1  ]: finished collecting timing info
15:35:52.983992 [debug] [Thread-1  ]: Began executing node model.demo_dbt_postgres.my_second_dbt_model
15:35:52.986753 [debug] [Thread-1  ]: Writing runtime SQL for node "model.demo_dbt_postgres.my_second_dbt_model"
15:35:52.987360 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.my_second_dbt_model"
15:35:52.987617 [debug] [Thread-1  ]: On model.demo_dbt_postgres.my_second_dbt_model: BEGIN
15:35:52.987795 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
15:35:54.896808 [debug] [Thread-1  ]: SQL status: BEGIN in 1.91 seconds
15:35:54.897565 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.my_second_dbt_model"
15:35:54.897975 [debug] [Thread-1  ]: On model.demo_dbt_postgres.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "model.demo_dbt_postgres.my_second_dbt_model"} */

  create view "brightacciondb"."warehouse"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "brightacciondb"."warehouse"."my_first_dbt_model"
where id = 1
  );
15:35:55.113780 [debug] [Thread-1  ]: SQL status: CREATE VIEW in 0.22 seconds
15:35:55.118009 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.my_second_dbt_model"
15:35:55.118433 [debug] [Thread-1  ]: On model.demo_dbt_postgres.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "model.demo_dbt_postgres.my_second_dbt_model"} */
alter table "brightacciondb"."warehouse"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
15:35:55.330630 [debug] [Thread-1  ]: SQL status: ALTER TABLE in 0.21 seconds
15:35:55.333512 [debug] [Thread-1  ]: On model.demo_dbt_postgres.my_second_dbt_model: COMMIT
15:35:55.333777 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.my_second_dbt_model"
15:35:55.333990 [debug] [Thread-1  ]: On model.demo_dbt_postgres.my_second_dbt_model: COMMIT
15:35:55.547020 [debug] [Thread-1  ]: SQL status: COMMIT in 0.21 seconds
15:35:55.551059 [debug] [Thread-1  ]: Using postgres connection "model.demo_dbt_postgres.my_second_dbt_model"
15:35:55.551367 [debug] [Thread-1  ]: On model.demo_dbt_postgres.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt_postgres", "target_name": "dev", "node_id": "model.demo_dbt_postgres.my_second_dbt_model"} */
drop view if exists "brightacciondb"."warehouse"."my_second_dbt_model__dbt_backup" cascade
15:35:55.990797 [debug] [Thread-1  ]: SQL status: DROP VIEW in 0.44 seconds
15:35:55.993090 [debug] [Thread-1  ]: finished collecting timing info
15:35:55.993614 [debug] [Thread-1  ]: On model.demo_dbt_postgres.my_second_dbt_model: Close
15:35:55.994979 [info ] [Thread-1  ]: 5 of 5 OK created view model warehouse.my_second_dbt_model ..................... [[32mCREATE VIEW[0m in 3.02s]
15:35:55.995735 [debug] [Thread-1  ]: Finished running node model.demo_dbt_postgres.my_second_dbt_model
15:35:56.025724 [debug] [MainThread]: Acquiring new postgres connection "master"
15:35:56.026175 [debug] [MainThread]: Using postgres connection "master"
15:35:56.026451 [debug] [MainThread]: On master: BEGIN
15:35:56.026702 [debug] [MainThread]: Opening a new connection, currently in state closed
15:35:57.881282 [debug] [MainThread]: SQL status: BEGIN in 1.85 seconds
15:35:57.881651 [debug] [MainThread]: On master: COMMIT
15:35:57.881934 [debug] [MainThread]: Using postgres connection "master"
15:35:57.882203 [debug] [MainThread]: On master: COMMIT
15:35:58.094621 [debug] [MainThread]: SQL status: COMMIT in 0.21 seconds
15:35:58.095110 [debug] [MainThread]: On master: Close
15:35:58.095989 [info ] [MainThread]: 
15:35:58.096830 [info ] [MainThread]: Finished running 1 table model, 4 view models in 25.73s.
15:35:58.097958 [debug] [MainThread]: Connection 'master' was properly closed.
15:35:58.098552 [debug] [MainThread]: Connection 'model.demo_dbt_postgres.my_second_dbt_model' was properly closed.
15:35:58.109043 [info ] [MainThread]: 
15:35:58.109507 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
15:35:58.110437 [info ] [MainThread]: 
15:35:58.110848 [error] [MainThread]: [33mDatabase Error in model stg_eltool__orders (models/staging/stg_eltool__orders.sql)[0m
15:35:58.111304 [error] [MainThread]:   column "customer_id" does not exist
15:35:58.111769 [error] [MainThread]:   LINE 10:         customer_id,
15:35:58.112303 [error] [MainThread]:                    ^
15:35:58.112758 [error] [MainThread]:   compiled SQL at target/run/demo_dbt_postgres/models/staging/stg_eltool__orders.sql
15:35:58.113289 [info ] [MainThread]: 
15:35:58.113750 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5


============================== 2022-06-30 13:02:39.189833 | 39bcb8e5-1bf6-4f4d-9ec7-dfe9d8cbc861 ==============================
13:02:39.189855 [info ] [MainThread]: Running with dbt=1.1.1
13:02:39.190849 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
13:02:39.191170 [debug] [MainThread]: Tracking: do not track
13:02:39.220906 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
13:02:39.406260 [debug] [MainThread]: Parsing macros/catalog.sql
13:02:39.409812 [debug] [MainThread]: Parsing macros/adapters.sql
13:02:39.473314 [debug] [MainThread]: Parsing macros/materializations/merge.sql
13:02:39.478891 [debug] [MainThread]: Parsing macros/materializations/seed.sql
13:02:39.486770 [debug] [MainThread]: Parsing macros/materializations/view.sql
13:02:39.488695 [debug] [MainThread]: Parsing macros/materializations/table.sql
13:02:39.492926 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
13:02:39.504965 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
13:02:39.506119 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
13:02:39.511172 [debug] [MainThread]: Parsing macros/materializations/configs.sql
13:02:39.514358 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
13:02:39.516624 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
13:02:39.540655 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
13:02:39.560075 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
13:02:39.575726 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
13:02:39.582860 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
13:02:39.585639 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
13:02:39.588236 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
13:02:39.595051 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
13:02:39.618170 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
13:02:39.620480 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
13:02:39.635412 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
13:02:39.657368 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
13:02:39.667975 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
13:02:39.671992 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
13:02:39.681054 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
13:02:39.682616 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
13:02:39.685595 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
13:02:39.688310 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
13:02:39.695794 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
13:02:39.719175 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
13:02:39.720901 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
13:02:39.723657 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
13:02:39.725451 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
13:02:39.727146 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
13:02:39.728553 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
13:02:39.729368 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
13:02:39.731226 [debug] [MainThread]: Parsing macros/etc/statement.sql
13:02:39.736246 [debug] [MainThread]: Parsing macros/etc/datetime.sql
13:02:39.745880 [debug] [MainThread]: Parsing macros/adapters/schema.sql
13:02:39.748390 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
13:02:39.751592 [debug] [MainThread]: Parsing macros/adapters/relation.sql
13:02:39.763532 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
13:02:39.766975 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
13:02:39.771943 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
13:02:39.784007 [debug] [MainThread]: Parsing macros/adapters/columns.sql
13:02:39.795617 [debug] [MainThread]: Parsing tests/generic/builtin.sql
13:02:40.036527 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__customers.sql
13:02:40.049385 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__orders.sql
13:02:40.052119 [debug] [MainThread]: 1699: static parser successfully parsed staging/stg_eltool__state.sql
13:02:40.055146 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
13:02:40.058208 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
13:02:40.189747 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
13:02:40.191739 [info ] [MainThread]: 
13:02:40.192324 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:02:40.193172 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database"
13:02:40.211774 [debug] [ThreadPool]: Using snowflake connection "list_my_database"
13:02:40.212015 [debug] [ThreadPool]: On list_my_database: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database"} */

    show terse schemas in database my_database
    limit 10000
13:02:40.212175 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:02:44.895867 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 4.68 seconds
13:02:44.898760 [debug] [ThreadPool]: On list_my_database: Close
13:02:45.387669 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database_warehouse"
13:02:45.397414 [debug] [ThreadPool]: Using snowflake connection "list_my_database_warehouse"
13:02:45.397677 [debug] [ThreadPool]: On list_my_database_warehouse: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database_warehouse"} */

    show terse objects in my_database.warehouse
13:02:45.397849 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:02:46.951448 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1.55 seconds
13:02:46.954622 [debug] [ThreadPool]: On list_my_database_warehouse: Close
13:02:47.442871 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database_snapshots"
13:02:47.445421 [debug] [ThreadPool]: Using snowflake connection "list_my_database_snapshots"
13:02:47.445622 [debug] [ThreadPool]: On list_my_database_snapshots: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database_snapshots"} */

    show terse objects in my_database.snapshots
13:02:47.445781 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:02:48.802658 [debug] [ThreadPool]: SQL status: SUCCESS 1 in 1.36 seconds
13:02:48.806228 [debug] [ThreadPool]: On list_my_database_snapshots: Close
13:02:49.274561 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:02:49.275036 [info ] [MainThread]: 
13:02:49.281658 [debug] [Thread-1  ]: Began running node snapshot.demo_dbt.customers_snapshot
13:02:49.282102 [info ] [Thread-1  ]: 1 of 1 START snapshot snapshots.customers_snapshot ............................. [RUN]
13:02:49.282769 [debug] [Thread-1  ]: Acquiring new snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:02:49.283001 [debug] [Thread-1  ]: Began compiling node snapshot.demo_dbt.customers_snapshot
13:02:49.283177 [debug] [Thread-1  ]: Compiling snapshot.demo_dbt.customers_snapshot
13:02:49.288212 [debug] [Thread-1  ]: finished collecting timing info
13:02:49.288497 [debug] [Thread-1  ]: Began executing node snapshot.demo_dbt.customers_snapshot
13:02:49.360203 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:02:49.360498 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

    describe table "MY_DATABASE"."SNAPSHOTS"."CUSTOMERS_SNAPSHOT"
13:02:49.360668 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
13:02:50.908075 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 1.55 seconds
13:02:50.947101 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:02:50.947340 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

        

      create or replace temporary table "MY_DATABASE"."SNAPSHOTS"."CUSTOMERS_SNAPSHOT__dbt_tmp"  as
      (with snapshot_query as (

        



select * from my_database.warehouse.customers


    ),

    snapshotted_data as (

        select *,
            customer_id as dbt_unique_key

        from "MY_DATABASE"."SNAPSHOTS"."CUSTOMERS_SNAPSHOT"
        where dbt_valid_to is null

    ),

    insertions_source_data as (

        select
            *,
            customer_id as dbt_unique_key,
            datetime_updated as dbt_updated_at,
            datetime_updated as dbt_valid_from,
            nullif(datetime_updated, datetime_updated) as dbt_valid_to,
            md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(datetime_updated as varchar ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select
            *,
            customer_id as dbt_unique_key,
            datetime_updated as dbt_updated_at,
            datetime_updated as dbt_valid_from,
            datetime_updated as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where snapshotted_data.dbt_unique_key is null
           or (
                snapshotted_data.dbt_unique_key is not null
            and (
                (snapshotted_data.dbt_valid_from < source_data.datetime_updated)
            )
        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where (
            (snapshotted_data.dbt_valid_from < source_data.datetime_updated)
        )
    )

    select * from insertions
    union all
    select * from updates

      );
13:02:52.752663 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 1.81 seconds
13:02:52.756584 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:02:52.756868 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

    describe table "MY_DATABASE"."SNAPSHOTS"."CUSTOMERS_SNAPSHOT__dbt_tmp"
13:02:53.048466 [debug] [Thread-1  ]: SQL status: SUCCESS 12 in 0.29 seconds
13:02:53.053843 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:02:53.054214 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

    describe table "MY_DATABASE"."SNAPSHOTS"."CUSTOMERS_SNAPSHOT"
13:02:53.325818 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.27 seconds
13:02:53.330767 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:02:53.331030 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

    describe table "MY_DATABASE"."SNAPSHOTS"."CUSTOMERS_SNAPSHOT__dbt_tmp"
13:02:53.591528 [debug] [Thread-1  ]: SQL status: SUCCESS 12 in 0.26 seconds
13:02:53.597369 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:02:53.597655 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

    describe table "MY_DATABASE"."SNAPSHOTS"."CUSTOMERS_SNAPSHOT"
13:02:53.856771 [debug] [Thread-1  ]: SQL status: SUCCESS 10 in 0.26 seconds
13:02:53.867634 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:02:53.867879 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

    describe table "MY_DATABASE"."SNAPSHOTS"."CUSTOMERS_SNAPSHOT__dbt_tmp"
13:02:54.133867 [debug] [Thread-1  ]: SQL status: SUCCESS 12 in 0.27 seconds
13:02:54.147015 [debug] [Thread-1  ]: Writing runtime SQL for node "snapshot.demo_dbt.customers_snapshot"
13:02:54.148708 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:02:54.148913 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

      begin;
13:02:54.413518 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.26 seconds
13:02:54.413897 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:02:54.414106 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: merge into "MY_DATABASE"."SNAPSHOTS"."CUSTOMERS_SNAPSHOT" as DBT_INTERNAL_DEST
    using "MY_DATABASE"."SNAPSHOTS"."CUSTOMERS_SNAPSHOT__dbt_tmp" as DBT_INTERNAL_SOURCE
    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id

    when matched
     and DBT_INTERNAL_DEST.dbt_valid_to is null
     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')
        then update
        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to

    when not matched
     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'
        then insert ("CUSTOMER_ID", "ZIPCODE", "CITY", "STATE_CODE", "DATETIME_CREATED", "DATETIME_UPDATED", "DBT_UPDATED_AT", "DBT_VALID_FROM", "DBT_VALID_TO", "DBT_SCD_ID")
        values ("CUSTOMER_ID", "ZIPCODE", "CITY", "STATE_CODE", "DATETIME_CREATED", "DATETIME_UPDATED", "DBT_UPDATED_AT", "DBT_VALID_FROM", "DBT_VALID_TO", "DBT_SCD_ID")

;
13:02:54.820635 [debug] [Thread-1  ]: SQL status: SUCCESS 0 in 0.41 seconds
13:02:54.821031 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
13:02:54.821286 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: commit;
13:02:55.162598 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 0.34 seconds
13:02:55.179865 [debug] [Thread-1  ]: finished collecting timing info
13:02:55.180133 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: Close
13:02:55.661217 [info ] [Thread-1  ]: 1 of 1 OK snapshotted snapshots.customers_snapshot ............................. [[32mSUCCESS 1[0m in 6.38s]
13:02:55.661896 [debug] [Thread-1  ]: Finished running node snapshot.demo_dbt.customers_snapshot
13:02:55.663240 [debug] [MainThread]: Acquiring new snowflake connection "master"
13:02:55.663669 [info ] [MainThread]: 
13:02:55.664179 [info ] [MainThread]: Finished running 1 snapshot in 15.47s.
13:02:55.664604 [debug] [MainThread]: Connection 'master' was properly closed.
13:02:55.664945 [debug] [MainThread]: Connection 'snapshot.demo_dbt.customers_snapshot' was properly closed.
13:02:55.671781 [info ] [MainThread]: 
13:02:55.672121 [info ] [MainThread]: [32mCompleted successfully[0m
13:02:55.672516 [info ] [MainThread]: 
13:02:55.672782 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1


============================== 2022-07-01 05:14:51.037554 | f9c1a1bd-2c9d-4680-a91b-75dcfc6b9bac ==============================
05:14:51.037574 [info ] [MainThread]: Running with dbt=1.1.1
05:14:51.038575 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/amit/.dbt', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'snapshot', 'rpc_method': 'snapshot', 'indirect_selection': 'eager'}
05:14:51.038807 [debug] [MainThread]: Tracking: do not track
05:14:51.118061 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
05:14:51.118304 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
05:14:51.134949 [info ] [MainThread]: Found 5 models, 9 tests, 1 snapshot, 0 analyses, 181 macros, 0 operations, 0 seed files, 3 sources, 0 exposures, 0 metrics
05:14:51.137198 [info ] [MainThread]: 
05:14:51.137862 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:14:51.139041 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database"
05:14:51.157039 [debug] [ThreadPool]: Using snowflake connection "list_my_database"
05:14:51.158756 [debug] [ThreadPool]: On list_my_database: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database"} */

    show terse schemas in database my_database
    limit 10000
05:14:51.159280 [debug] [ThreadPool]: Opening a new connection, currently in state init
05:14:53.446390 [debug] [ThreadPool]: SQL status: SUCCESS 5 in 2.29 seconds
05:14:53.450063 [debug] [ThreadPool]: On list_my_database: Close
05:14:54.036541 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database_snapshots"
05:14:54.044961 [debug] [ThreadPool]: Using snowflake connection "list_my_database_snapshots"
05:14:54.045212 [debug] [ThreadPool]: On list_my_database_snapshots: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database_snapshots"} */

    show terse objects in my_database.snapshots
05:14:54.045380 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:14:55.450096 [debug] [ThreadPool]: SQL status: SUCCESS 0 in 1.4 seconds
05:14:55.452242 [debug] [ThreadPool]: On list_my_database_snapshots: Close
05:14:55.928972 [debug] [ThreadPool]: Acquiring new snowflake connection "list_my_database_warehouse"
05:14:55.931432 [debug] [ThreadPool]: Using snowflake connection "list_my_database_warehouse"
05:14:55.931648 [debug] [ThreadPool]: On list_my_database_warehouse: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "connection_name": "list_my_database_warehouse"} */

    show terse objects in my_database.warehouse
05:14:55.931812 [debug] [ThreadPool]: Opening a new connection, currently in state closed
05:14:57.557985 [debug] [ThreadPool]: SQL status: SUCCESS 8 in 1.63 seconds
05:14:57.560477 [debug] [ThreadPool]: On list_my_database_warehouse: Close
05:14:58.037027 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
05:14:58.037517 [info ] [MainThread]: 
05:14:58.044709 [debug] [Thread-1  ]: Began running node snapshot.demo_dbt.customers_snapshot
05:14:58.045161 [info ] [Thread-1  ]: 1 of 1 START snapshot snapshots.customers_snapshot ............................. [RUN]
05:14:58.046416 [debug] [Thread-1  ]: Acquiring new snowflake connection "snapshot.demo_dbt.customers_snapshot"
05:14:58.046681 [debug] [Thread-1  ]: Began compiling node snapshot.demo_dbt.customers_snapshot
05:14:58.046917 [debug] [Thread-1  ]: Compiling snapshot.demo_dbt.customers_snapshot
05:14:58.050613 [debug] [Thread-1  ]: finished collecting timing info
05:14:58.050848 [debug] [Thread-1  ]: Began executing node snapshot.demo_dbt.customers_snapshot
05:14:58.119711 [debug] [Thread-1  ]: Writing runtime SQL for node "snapshot.demo_dbt.customers_snapshot"
05:14:58.121905 [debug] [Thread-1  ]: Using snowflake connection "snapshot.demo_dbt.customers_snapshot"
05:14:58.122151 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.1.1", "profile_name": "demo_dbt", "target_name": "dev", "node_id": "snapshot.demo_dbt.customers_snapshot"} */

      

      create or replace transient table my_database.snapshots.customers_snapshot  as
      (

    select *,
        md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(datetime_updated as varchar ), '')
        ) as dbt_scd_id,
        datetime_updated as dbt_updated_at,
        datetime_updated as dbt_valid_from,
        nullif(datetime_updated, datetime_updated) as dbt_valid_to
    from (
        



select * from my_database.warehouse.customers

    ) sbq



      );
05:14:58.122349 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
05:15:00.888481 [debug] [Thread-1  ]: SQL status: SUCCESS 1 in 2.77 seconds
05:15:00.908168 [debug] [Thread-1  ]: finished collecting timing info
05:15:00.908434 [debug] [Thread-1  ]: On snapshot.demo_dbt.customers_snapshot: Close
05:15:01.389584 [info ] [Thread-1  ]: 1 of 1 OK snapshotted snapshots.customers_snapshot ............................. [[32mSUCCESS 1[0m in 3.34s]
05:15:01.390303 [debug] [Thread-1  ]: Finished running node snapshot.demo_dbt.customers_snapshot
05:15:01.391919 [debug] [MainThread]: Acquiring new snowflake connection "master"
05:15:01.392463 [info ] [MainThread]: 
05:15:01.392869 [info ] [MainThread]: Finished running 1 snapshot in 10.25s.
05:15:01.393324 [debug] [MainThread]: Connection 'master' was properly closed.
05:15:01.393530 [debug] [MainThread]: Connection 'snapshot.demo_dbt.customers_snapshot' was properly closed.
05:15:01.401421 [info ] [MainThread]: 
05:15:01.402021 [info ] [MainThread]: [32mCompleted successfully[0m
05:15:01.402423 [info ] [MainThread]: 
05:15:01.402724 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
